{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c85047a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from scipy import sparse\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest,\n",
    "    f_classif,\n",
    "    mutual_info_classif,\n",
    "    SelectFromModel,\n",
    "    RFE\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c99e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "402f50a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(npz_paths: str, data_type: str, threshold=0.5, center=0):\n",
    "    upper_threshold = threshold + center\n",
    "    lower_threshold = -threshold + center\n",
    "    if data_type not in [\"X_mean\", \"X_max\", \"X_concat\"]:\n",
    "        raise Exception(\"data type in valid\")\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for npz_path in npz_paths:\n",
    "    \n",
    "        base = os.path.splitext(os.path.basename(npz_path))[0]      \n",
    "        csv_path = os.path.join(\n",
    "            os.path.dirname(npz_path),\n",
    "            base + \"_meta.csv\"                                       \n",
    "        )\n",
    "\n",
    "\n",
    "        data = np.load(npz_path, allow_pickle=True)\n",
    "        X = data[data_type]      # (N_docs, 2*D)\n",
    "        # X_concat = data[\"X_mean\"]\n",
    "        tids = data[\"transcriptids\"]    \n",
    "\n",
    "\n",
    "        meta = pd.read_csv(csv_path)\n",
    "\n",
    "        meta_unique = (\n",
    "            meta[[\"transcriptid\", \"SUESCORE\", \"label\"]]\n",
    "            .drop_duplicates(subset=\"transcriptid\", keep=\"first\")\n",
    "            .set_index(\"transcriptid\")\n",
    "        )\n",
    "\n",
    "        mask_ids = np.isin(tids, meta_unique.index)\n",
    "        X_filt = X[mask_ids]\n",
    "        tids_filt = np.array(tids)[mask_ids]\n",
    "\n",
    "\n",
    "        lab_df = meta.assign(\n",
    "            label=lambda df: df.SUESCORE.map(\n",
    "                lambda s: 1 if s >= upper_threshold else (0 if s <= lower_threshold else np.nan)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # meta['label'] = np.nan\n",
    "\n",
    "        # set label = 1 where SUESCORE > threshold\n",
    "        meta.loc[meta['SUESCORE'] >= upper_threshold, 'label'] = 1\n",
    "\n",
    "        # set label = 0 where SUESCORE < -threshold\n",
    "        meta.loc[meta['SUESCORE'] <= lower_threshold, 'label'] = 0\n",
    "\n",
    "        mask_label = lab_df.label.notna().values\n",
    "        # apply the same mask in the same order as the CSV, so we use .loc on lab_df\n",
    "        # but first filter lab_df to only those transcriptids in tids_filt\n",
    "        Xc, y = X_filt[mask_label], meta.loc[mask_label, \"label\"].astype(int).values\n",
    "        \n",
    "        # now align X and y\n",
    "        # X_final = X_filt[lab_sub.label.notna()]\n",
    "        # y_final = lab_sub.label.astype(int).values\n",
    "\n",
    "        # collect\n",
    "        X_list.append(Xc)\n",
    "        y_list.append(y)\n",
    "\n",
    "    # 2. concatenate all files together\n",
    "    Xc = np.vstack(X_list)   # shape: (sum_i N_i, 2*D)\n",
    "    y  = np.concatenate(y_list)  # shape: (sum_i N_i,)\n",
    "\n",
    "    print(\"Combined Xc shape:\", Xc.shape)\n",
    "    print(\"Combined y shape: \", y.shape)\n",
    "\n",
    "    return Xc, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d593fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_balance(Xc_unbalanced, y_unbalanced):\n",
    "    # forced resampling\n",
    "    idx0 = np.where(y_unbalanced == 0)[0]\n",
    "    idx1 = np.where(y_unbalanced == 1)[0]\n",
    "\n",
    "    n = min(len(idx0), len(idx1))\n",
    "\n",
    "    sel0 = np.random.choice(idx0, size=n, replace=False)\n",
    "    sel1 = np.random.choice(idx1, size=n, replace=False)\n",
    "\n",
    "    sel = np.concatenate([sel0, sel1])\n",
    "    np.random.shuffle(sel)\n",
    "\n",
    "    # slice out your balanced subset\n",
    "    Xc_out = Xc_unbalanced[sel]\n",
    "    y_out = y_unbalanced[sel]\n",
    "\n",
    "    print(\"Balanced X shape:\", Xc_out.shape)\n",
    "    print(\"Balanced y counts:\", np.bincount(y_out))\n",
    "    return Xc_out, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "421cd270",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_npz_paths = [\n",
    "    \"./data/doc_features/transcript_componenttext_2012_1_features.npz\",    \n",
    "    \"./data/doc_features/transcript_componenttext_2012_2_features.npz\",\n",
    "    \"./data/doc_features/transcript_componenttext_2013_1_features.npz\",    \n",
    "    \"./data/doc_features/transcript_componenttext_2013_2_features.npz\",\n",
    "]\n",
    "\n",
    "val_npz_paths = [\n",
    "    \"./data/doc_features/transcript_componenttext_2014_1_features.npz\",\n",
    "    \"./data/doc_features/transcript_componenttext_2014_2_features.npz\",\n",
    "]\n",
    "\n",
    "# test_npz_paths = [\n",
    "\n",
    "#     \"./data/doc_features/transcript_componenttext_2014_1_features.npz\",\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5936f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Xc shape: (4821, 16384)\n",
      "Combined y shape:  (4821,)\n",
      "Combined Xc shape: (2508, 16384)\n",
      "Combined y shape:  (2508,)\n",
      "Combined Xc shape: (4821, 16384)\n",
      "Combined y shape:  (4821,)\n",
      "Combined Xc shape: (2508, 16384)\n",
      "Combined y shape:  (2508,)\n"
     ]
    }
   ],
   "source": [
    "Xc, y = load_data(train_npz_paths, \"X_max\", threshold=0.5)\n",
    "X_val_all_feat, y_val = load_data(val_npz_paths, \"X_max\", threshold=0.5)\n",
    "Xc2, y2 = load_data(train_npz_paths, \"X_mean\", threshold=0.5)\n",
    "X_val_all_feat2, y_val2 = load_data(val_npz_paths, \"X_mean\", threshold=0.5)\n",
    "\n",
    "Xc = np.concatenate([Xc, Xc2], axis=1)\n",
    "X_val_all_feat = np.concatenate([X_val_all_feat, X_val_all_feat2], axis=1)\n",
    "\n",
    "X_val_all_feat, X_test_all_feat, y_val, y_test = train_test_split(\n",
    "    X_val_all_feat, \n",
    "    y_val, \n",
    "    test_size=0.5,       # puts half into X_test/y_test\n",
    "    random_state=42,     # for reproducibility\n",
    "    # stratify=y_val       # if you want to preserve class proportions\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a18b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4821, 32768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([Xc, Xc2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4214b4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Xc shape: (4821, 16384)\n",
      "Combined y shape:  (4821,)\n",
      "Combined Xc shape: (2508, 16384)\n",
      "Combined y shape:  (2508,)\n"
     ]
    }
   ],
   "source": [
    "Xc, y = load_data(train_npz_paths, \"X_mean\", threshold=0.5)\n",
    "X_val_all_feat, y_val = load_data(val_npz_paths, \"X_mean\", threshold=0.5)\n",
    "\n",
    "# Xc, y = load_data(train_npz_paths, \"X_concat\", threshold=0.1)\n",
    "# X_val_all_feat, y_val = load_data(val_npz_paths, \"X_concat\", threshold=0.1)\n",
    "# X_test_all_feat, y_test = load_data(test_npz_paths, \"X_mean\")\n",
    "# Split X_val_all_feat, y_val into two equal parts:\n",
    "X_val_all_feat, X_test_all_feat, y_val, y_test = train_test_split(\n",
    "    X_val_all_feat, \n",
    "    y_val, \n",
    "    test_size=0.5,       # puts half into X_test/y_test\n",
    "    random_state=42,     # for reproducibility\n",
    "    # stratify=y_val       # if you want to preserve class proportions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fbe5d684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 16384)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_all_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0edc81c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422,)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "bd158266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced X shape: (2170, 16384)\n",
      "Balanced y counts: [1085 1085]\n",
      "Balanced X shape: (574, 16384)\n",
      "Balanced y counts: [287 287]\n",
      "Balanced X shape: (498, 16384)\n",
      "Balanced y counts: [249 249]\n"
     ]
    }
   ],
   "source": [
    "# optional downsampling for balancing data\n",
    "Xc, y = downsample_balance(Xc, y)\n",
    "X_val_all_feat, y_val = downsample_balance(X_val_all_feat, y_val)\n",
    "X_test_all_feat, y_test = downsample_balance(X_test_all_feat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e826e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rank_and_print(scores: np.ndarray, D: int, method_name: str, top_k: int = 1000):\n",
    "    \"\"\"\n",
    "    Print the top_k features by score, separating features into 'mean' and 'max' halves.\n",
    "    \"\"\"\n",
    "    ranked = np.argsort(-scores)\n",
    "    print(f\"\\n=== {method_name} top {top_k} features ===\")\n",
    "    for rank, idx in enumerate(ranked[:top_k], start=1):\n",
    "        part = 'mean' if idx < D else 'max'\n",
    "        feat_id = idx if idx < D else idx - D\n",
    "        score = scores[idx]\n",
    "        print(f\"Rank {rank:4d}: {part} feature #{feat_id} (score = {score:.6f})\")\n",
    "\n",
    "    return ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4573a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== T-test top 1000 features ===\n",
      "Rank    1: mean feature #4600 (score = 8.956881)\n",
      "Rank    2: mean feature #15085 (score = 8.613231)\n",
      "Rank    3: mean feature #15621 (score = 8.577414)\n",
      "Rank    4: mean feature #1541 (score = 8.481013)\n",
      "Rank    5: max feature #10424 (score = 8.281642)\n",
      "Rank    6: max feature #12865 (score = 8.211435)\n",
      "Rank    7: mean feature #10010 (score = 8.118495)\n",
      "Rank    8: mean feature #12299 (score = 8.091381)\n",
      "Rank    9: max feature #14370 (score = 8.071714)\n",
      "Rank   10: max feature #15621 (score = 7.978019)\n",
      "Rank   11: mean feature #10560 (score = 7.972969)\n",
      "Rank   12: max feature #10560 (score = 7.924379)\n",
      "Rank   13: max feature #10040 (score = 7.894786)\n",
      "Rank   14: max feature #6615 (score = 7.783951)\n",
      "Rank   15: max feature #8430 (score = 7.782514)\n",
      "Rank   16: mean feature #15681 (score = 7.754803)\n",
      "Rank   17: max feature #16278 (score = 7.738749)\n",
      "Rank   18: max feature #1541 (score = 7.637256)\n",
      "Rank   19: max feature #12299 (score = 7.611466)\n",
      "Rank   20: max feature #1712 (score = 7.605909)\n",
      "Rank   21: max feature #13877 (score = 7.596629)\n",
      "Rank   22: max feature #12282 (score = 7.565508)\n",
      "Rank   23: mean feature #12865 (score = 7.529702)\n",
      "Rank   24: max feature #15085 (score = 7.523353)\n",
      "Rank   25: max feature #2415 (score = 7.505720)\n",
      "Rank   26: max feature #7357 (score = 7.472701)\n",
      "Rank   27: max feature #9813 (score = 7.460392)\n",
      "Rank   28: max feature #15632 (score = 7.440146)\n",
      "Rank   29: max feature #14277 (score = 7.417245)\n",
      "Rank   30: max feature #10515 (score = 7.374254)\n",
      "Rank   31: mean feature #14349 (score = 7.346844)\n",
      "Rank   32: max feature #8823 (score = 7.321307)\n",
      "Rank   33: max feature #6703 (score = 7.303451)\n",
      "Rank   34: mean feature #635 (score = 7.260237)\n",
      "Rank   35: max feature #1381 (score = 7.254673)\n",
      "Rank   36: mean feature #14370 (score = 7.205901)\n",
      "Rank   37: max feature #1520 (score = 7.157271)\n",
      "Rank   38: max feature #5612 (score = 7.136242)\n",
      "Rank   39: max feature #8380 (score = 7.096848)\n",
      "Rank   40: mean feature #14892 (score = 7.072867)\n",
      "Rank   41: mean feature #9502 (score = 7.063711)\n",
      "Rank   42: mean feature #4983 (score = 7.053096)\n",
      "Rank   43: max feature #11637 (score = 7.037107)\n",
      "Rank   44: mean feature #2845 (score = 6.973817)\n",
      "Rank   45: max feature #12637 (score = 6.965384)\n",
      "Rank   46: max feature #8275 (score = 6.915369)\n",
      "Rank   47: mean feature #7516 (score = 6.914494)\n",
      "Rank   48: max feature #8413 (score = 6.912146)\n",
      "Rank   49: max feature #2488 (score = 6.909009)\n",
      "Rank   50: mean feature #3609 (score = 6.835937)\n",
      "Rank   51: max feature #8333 (score = 6.809652)\n",
      "Rank   52: mean feature #8543 (score = 6.802258)\n",
      "Rank   53: max feature #4838 (score = 6.777073)\n",
      "Rank   54: mean feature #5078 (score = 6.776501)\n",
      "Rank   55: mean feature #2415 (score = 6.769018)\n",
      "Rank   56: mean feature #6770 (score = 6.739436)\n",
      "Rank   57: max feature #12663 (score = 6.733967)\n",
      "Rank   58: max feature #10460 (score = 6.733841)\n",
      "Rank   59: mean feature #1712 (score = 6.719320)\n",
      "Rank   60: max feature #10010 (score = 6.699547)\n",
      "Rank   61: max feature #10769 (score = 6.680879)\n",
      "Rank   62: max feature #11064 (score = 6.674476)\n",
      "Rank   63: mean feature #14040 (score = 6.660450)\n",
      "Rank   64: mean feature #523 (score = 6.646080)\n",
      "Rank   65: max feature #11926 (score = 6.622594)\n",
      "Rank   66: max feature #10656 (score = 6.581176)\n",
      "Rank   67: mean feature #8380 (score = 6.552995)\n",
      "Rank   68: max feature #6290 (score = 6.549699)\n",
      "Rank   69: mean feature #4408 (score = 6.543903)\n",
      "Rank   70: mean feature #7357 (score = 6.541422)\n",
      "Rank   71: mean feature #9095 (score = 6.522682)\n",
      "Rank   72: max feature #9095 (score = 6.513751)\n",
      "Rank   73: max feature #7452 (score = 6.501540)\n",
      "Rank   74: mean feature #6703 (score = 6.498774)\n",
      "Rank   75: max feature #255 (score = 6.465517)\n",
      "Rank   76: max feature #15681 (score = 6.443925)\n",
      "Rank   77: max feature #3471 (score = 6.427171)\n",
      "Rank   78: mean feature #7456 (score = 6.419825)\n",
      "Rank   79: max feature #7589 (score = 6.408111)\n",
      "Rank   80: max feature #2352 (score = 6.394161)\n",
      "Rank   81: max feature #1174 (score = 6.382631)\n",
      "Rank   82: max feature #7804 (score = 6.379660)\n",
      "Rank   83: max feature #14622 (score = 6.373932)\n",
      "Rank   84: mean feature #13241 (score = 6.364737)\n",
      "Rank   85: max feature #9502 (score = 6.359124)\n",
      "Rank   86: mean feature #13555 (score = 6.341307)\n",
      "Rank   87: mean feature #9245 (score = 6.326713)\n",
      "Rank   88: max feature #2310 (score = 6.325090)\n",
      "Rank   89: max feature #2182 (score = 6.312821)\n",
      "Rank   90: max feature #1405 (score = 6.302803)\n",
      "Rank   91: mean feature #4177 (score = 6.299888)\n",
      "Rank   92: max feature #5315 (score = 6.279234)\n",
      "Rank   93: mean feature #10637 (score = 6.270354)\n",
      "Rank   94: max feature #12484 (score = 6.245788)\n",
      "Rank   95: mean feature #9149 (score = 6.236295)\n",
      "Rank   96: mean feature #8413 (score = 6.234361)\n",
      "Rank   97: max feature #10354 (score = 6.217538)\n",
      "Rank   98: mean feature #15762 (score = 6.205197)\n",
      "Rank   99: max feature #5817 (score = 6.200896)\n",
      "Rank  100: max feature #12515 (score = 6.196938)\n",
      "Rank  101: max feature #635 (score = 6.161919)\n",
      "Rank  102: max feature #110 (score = 6.158234)\n",
      "Rank  103: max feature #523 (score = 6.124352)\n",
      "Rank  104: max feature #7517 (score = 6.120432)\n",
      "Rank  105: mean feature #3878 (score = 6.119776)\n",
      "Rank  106: max feature #11397 (score = 6.097190)\n",
      "Rank  107: max feature #16290 (score = 6.091679)\n",
      "Rank  108: max feature #15232 (score = 6.084623)\n",
      "Rank  109: max feature #4558 (score = 6.081244)\n",
      "Rank  110: max feature #4600 (score = 6.063730)\n",
      "Rank  111: mean feature #720 (score = 6.061794)\n",
      "Rank  112: mean feature #255 (score = 6.055176)\n",
      "Rank  113: max feature #14892 (score = 6.045185)\n",
      "Rank  114: mean feature #207 (score = 6.045117)\n",
      "Rank  115: mean feature #12647 (score = 6.031102)\n",
      "Rank  116: max feature #8817 (score = 6.030636)\n",
      "Rank  117: max feature #8989 (score = 6.003356)\n",
      "Rank  118: max feature #8665 (score = 5.995177)\n",
      "Rank  119: mean feature #12663 (score = 5.991895)\n",
      "Rank  120: mean feature #13000 (score = 5.983989)\n",
      "Rank  121: mean feature #1547 (score = 5.983372)\n",
      "Rank  122: mean feature #10720 (score = 5.965867)\n",
      "Rank  123: max feature #7462 (score = 5.965557)\n",
      "Rank  124: mean feature #9493 (score = 5.962033)\n",
      "Rank  125: mean feature #12951 (score = 5.961805)\n",
      "Rank  126: mean feature #3494 (score = 5.958136)\n",
      "Rank  127: max feature #939 (score = 5.949535)\n",
      "Rank  128: max feature #15185 (score = 5.948768)\n",
      "Rank  129: mean feature #5103 (score = 5.926971)\n",
      "Rank  130: max feature #9945 (score = 5.914818)\n",
      "Rank  131: max feature #10421 (score = 5.908666)\n",
      "Rank  132: max feature #3990 (score = 5.908032)\n",
      "Rank  133: max feature #5256 (score = 5.899175)\n",
      "Rank  134: max feature #10637 (score = 5.898908)\n",
      "Rank  135: max feature #13882 (score = 5.888087)\n",
      "Rank  136: max feature #3147 (score = 5.888023)\n",
      "Rank  137: mean feature #15738 (score = 5.881995)\n",
      "Rank  138: max feature #8776 (score = 5.875595)\n",
      "Rank  139: max feature #12149 (score = 5.870931)\n",
      "Rank  140: max feature #8543 (score = 5.866030)\n",
      "Rank  141: mean feature #7589 (score = 5.862661)\n",
      "Rank  142: max feature #6770 (score = 5.856356)\n",
      "Rank  143: max feature #2505 (score = 5.852747)\n",
      "Rank  144: max feature #8617 (score = 5.844260)\n",
      "Rank  145: max feature #667 (score = 5.831988)\n",
      "Rank  146: max feature #11400 (score = 5.829991)\n",
      "Rank  147: mean feature #8333 (score = 5.822604)\n",
      "Rank  148: mean feature #6902 (score = 5.820533)\n",
      "Rank  149: max feature #7456 (score = 5.814041)\n",
      "Rank  150: max feature #1547 (score = 5.809750)\n",
      "Rank  151: max feature #6281 (score = 5.808482)\n",
      "Rank  152: max feature #6470 (score = 5.802480)\n",
      "Rank  153: mean feature #14622 (score = 5.797054)\n",
      "Rank  154: mean feature #15796 (score = 5.787266)\n",
      "Rank  155: max feature #5144 (score = 5.783617)\n",
      "Rank  156: mean feature #9112 (score = 5.780945)\n",
      "Rank  157: max feature #13471 (score = 5.780884)\n",
      "Rank  158: mean feature #11637 (score = 5.777629)\n",
      "Rank  159: max feature #9088 (score = 5.776157)\n",
      "Rank  160: max feature #15348 (score = 5.771251)\n",
      "Rank  161: max feature #15572 (score = 5.751044)\n",
      "Rank  162: max feature #2152 (score = 5.742600)\n",
      "Rank  163: mean feature #13882 (score = 5.741063)\n",
      "Rank  164: max feature #1363 (score = 5.740927)\n",
      "Rank  165: mean feature #13011 (score = 5.735551)\n",
      "Rank  166: max feature #6038 (score = 5.713553)\n",
      "Rank  167: mean feature #1704 (score = 5.712688)\n",
      "Rank  168: max feature #7054 (score = 5.709585)\n",
      "Rank  169: mean feature #1390 (score = 5.692968)\n",
      "Rank  170: max feature #6070 (score = 5.683551)\n",
      "Rank  171: mean feature #12484 (score = 5.680186)\n",
      "Rank  172: max feature #931 (score = 5.678624)\n",
      "Rank  173: max feature #12211 (score = 5.677248)\n",
      "Rank  174: max feature #8667 (score = 5.675816)\n",
      "Rank  175: mean feature #1881 (score = 5.675352)\n",
      "Rank  176: mean feature #5317 (score = 5.673065)\n",
      "Rank  177: max feature #14745 (score = 5.671113)\n",
      "Rank  178: mean feature #2488 (score = 5.660884)\n",
      "Rank  179: max feature #3609 (score = 5.654068)\n",
      "Rank  180: mean feature #1446 (score = 5.653793)\n",
      "Rank  181: max feature #6254 (score = 5.651078)\n",
      "Rank  182: mean feature #16116 (score = 5.650928)\n",
      "Rank  183: max feature #8080 (score = 5.639020)\n",
      "Rank  184: max feature #15796 (score = 5.635429)\n",
      "Rank  185: max feature #3962 (score = 5.632986)\n",
      "Rank  186: max feature #11843 (score = 5.628544)\n",
      "Rank  187: max feature #13000 (score = 5.623732)\n",
      "Rank  188: mean feature #2077 (score = 5.623129)\n",
      "Rank  189: max feature #8424 (score = 5.619319)\n",
      "Rank  190: max feature #8225 (score = 5.616672)\n",
      "Rank  191: max feature #10618 (score = 5.614157)\n",
      "Rank  192: max feature #9164 (score = 5.611102)\n",
      "Rank  193: max feature #8732 (score = 5.601274)\n",
      "Rank  194: max feature #14772 (score = 5.596527)\n",
      "Rank  195: max feature #5652 (score = 5.596324)\n",
      "Rank  196: max feature #5273 (score = 5.595403)\n",
      "Rank  197: mean feature #10266 (score = 5.594830)\n",
      "Rank  198: max feature #13646 (score = 5.591834)\n",
      "Rank  199: max feature #12595 (score = 5.573685)\n",
      "Rank  200: mean feature #12627 (score = 5.571405)\n",
      "Rank  201: max feature #12015 (score = 5.566017)\n",
      "Rank  202: mean feature #10515 (score = 5.565734)\n",
      "Rank  203: max feature #13670 (score = 5.564502)\n",
      "Rank  204: mean feature #11397 (score = 5.564393)\n",
      "Rank  205: max feature #12576 (score = 5.552750)\n",
      "Rank  206: mean feature #12058 (score = 5.548853)\n",
      "Rank  207: mean feature #13545 (score = 5.529172)\n",
      "Rank  208: mean feature #15185 (score = 5.528581)\n",
      "Rank  209: mean feature #3471 (score = 5.527158)\n",
      "Rank  210: max feature #1143 (score = 5.526359)\n",
      "Rank  211: mean feature #5817 (score = 5.513732)\n",
      "Rank  212: max feature #5078 (score = 5.507049)\n",
      "Rank  213: max feature #10719 (score = 5.502029)\n",
      "Rank  214: mean feature #13334 (score = 5.490011)\n",
      "Rank  215: mean feature #1224 (score = 5.486496)\n",
      "Rank  216: max feature #15762 (score = 5.476220)\n",
      "Rank  217: max feature #9149 (score = 5.474245)\n",
      "Rank  218: mean feature #5076 (score = 5.470038)\n",
      "Rank  219: max feature #4983 (score = 5.469299)\n",
      "Rank  220: max feature #12219 (score = 5.468176)\n",
      "Rank  221: max feature #14447 (score = 5.461539)\n",
      "Rank  222: mean feature #12013 (score = 5.459707)\n",
      "Rank  223: mean feature #4502 (score = 5.452273)\n",
      "Rank  224: mean feature #2059 (score = 5.441116)\n",
      "Rank  225: mean feature #5013 (score = 5.440984)\n",
      "Rank  226: max feature #15128 (score = 5.440509)\n",
      "Rank  227: max feature #1412 (score = 5.437133)\n",
      "Rank  228: max feature #1390 (score = 5.432422)\n",
      "Rank  229: max feature #2203 (score = 5.429883)\n",
      "Rank  230: mean feature #1381 (score = 5.427304)\n",
      "Rank  231: max feature #11235 (score = 5.420398)\n",
      "Rank  232: max feature #5041 (score = 5.415137)\n",
      "Rank  233: mean feature #2505 (score = 5.403614)\n",
      "Rank  234: mean feature #12133 (score = 5.402083)\n",
      "Rank  235: max feature #2012 (score = 5.399973)\n",
      "Rank  236: mean feature #4838 (score = 5.394880)\n",
      "Rank  237: mean feature #3604 (score = 5.380478)\n",
      "Rank  238: max feature #15557 (score = 5.375732)\n",
      "Rank  239: mean feature #1090 (score = 5.375304)\n",
      "Rank  240: mean feature #3590 (score = 5.374576)\n",
      "Rank  241: mean feature #8732 (score = 5.374007)\n",
      "Rank  242: max feature #16179 (score = 5.369762)\n",
      "Rank  243: mean feature #1174 (score = 5.359585)\n",
      "Rank  244: mean feature #5520 (score = 5.352085)\n",
      "Rank  245: mean feature #12314 (score = 5.351995)\n",
      "Rank  246: mean feature #5240 (score = 5.349388)\n",
      "Rank  247: max feature #7067 (score = 5.348191)\n",
      "Rank  248: mean feature #3585 (score = 5.345376)\n",
      "Rank  249: mean feature #940 (score = 5.342889)\n",
      "Rank  250: max feature #5317 (score = 5.342401)\n",
      "Rank  251: mean feature #12500 (score = 5.335950)\n",
      "Rank  252: max feature #15738 (score = 5.335924)\n",
      "Rank  253: mean feature #16089 (score = 5.330150)\n",
      "Rank  254: max feature #11103 (score = 5.329173)\n",
      "Rank  255: mean feature #11324 (score = 5.326336)\n",
      "Rank  256: mean feature #11773 (score = 5.324409)\n",
      "Rank  257: max feature #12647 (score = 5.323444)\n",
      "Rank  258: mean feature #11059 (score = 5.317977)\n",
      "Rank  259: max feature #14349 (score = 5.313817)\n",
      "Rank  260: max feature #10720 (score = 5.307414)\n",
      "Rank  261: max feature #3342 (score = 5.301509)\n",
      "Rank  262: max feature #9122 (score = 5.296745)\n",
      "Rank  263: max feature #9930 (score = 5.294434)\n",
      "Rank  264: mean feature #10769 (score = 5.293340)\n",
      "Rank  265: mean feature #14277 (score = 5.293194)\n",
      "Rank  266: max feature #9230 (score = 5.288427)\n",
      "Rank  267: max feature #9717 (score = 5.288041)\n",
      "Rank  268: mean feature #939 (score = 5.287455)\n",
      "Rank  269: mean feature #15398 (score = 5.286815)\n",
      "Rank  270: max feature #15169 (score = 5.286212)\n",
      "Rank  271: max feature #14080 (score = 5.284662)\n",
      "Rank  272: mean feature #6802 (score = 5.278912)\n",
      "Rank  273: max feature #3375 (score = 5.276008)\n",
      "Rank  274: max feature #9882 (score = 5.265996)\n",
      "Rank  275: max feature #493 (score = 5.257926)\n",
      "Rank  276: mean feature #12576 (score = 5.257141)\n",
      "Rank  277: mean feature #15165 (score = 5.254878)\n",
      "Rank  278: mean feature #7459 (score = 5.254014)\n",
      "Rank  279: max feature #7459 (score = 5.252757)\n",
      "Rank  280: max feature #28 (score = 5.245865)\n",
      "Rank  281: max feature #1891 (score = 5.238481)\n",
      "Rank  282: mean feature #5523 (score = 5.237501)\n",
      "Rank  283: max feature #8097 (score = 5.236560)\n",
      "Rank  284: max feature #856 (score = 5.233773)\n",
      "Rank  285: mean feature #5409 (score = 5.223933)\n",
      "Rank  286: max feature #1819 (score = 5.215677)\n",
      "Rank  287: mean feature #14527 (score = 5.206918)\n",
      "Rank  288: max feature #5375 (score = 5.206739)\n",
      "Rank  289: max feature #2133 (score = 5.204252)\n",
      "Rank  290: mean feature #10354 (score = 5.202913)\n",
      "Rank  291: max feature #12352 (score = 5.202743)\n",
      "Rank  292: max feature #4084 (score = 5.201128)\n",
      "Rank  293: mean feature #10460 (score = 5.197354)\n",
      "Rank  294: mean feature #5375 (score = 5.196610)\n",
      "Rank  295: max feature #15482 (score = 5.195298)\n",
      "Rank  296: mean feature #110 (score = 5.194609)\n",
      "Rank  297: max feature #10238 (score = 5.186275)\n",
      "Rank  298: mean feature #12942 (score = 5.177350)\n",
      "Rank  299: max feature #8679 (score = 5.172818)\n",
      "Rank  300: max feature #8947 (score = 5.167198)\n",
      "Rank  301: mean feature #2021 (score = 5.164068)\n",
      "Rank  302: max feature #10697 (score = 5.161039)\n",
      "Rank  303: max feature #11414 (score = 5.149445)\n",
      "Rank  304: mean feature #4192 (score = 5.148813)\n",
      "Rank  305: mean feature #3990 (score = 5.143070)\n",
      "Rank  306: mean feature #1462 (score = 5.140846)\n",
      "Rank  307: max feature #11149 (score = 5.138197)\n",
      "Rank  308: mean feature #1254 (score = 5.136414)\n",
      "Rank  309: mean feature #15239 (score = 5.135442)\n",
      "Rank  310: max feature #8639 (score = 5.129099)\n",
      "Rank  311: mean feature #7899 (score = 5.125645)\n",
      "Rank  312: max feature #585 (score = 5.125202)\n",
      "Rank  313: mean feature #5776 (score = 5.124317)\n",
      "Rank  314: max feature #11461 (score = 5.123484)\n",
      "Rank  315: max feature #13526 (score = 5.116755)\n",
      "Rank  316: max feature #10929 (score = 5.116388)\n",
      "Rank  317: max feature #4206 (score = 5.114366)\n",
      "Rank  318: mean feature #8268 (score = 5.109837)\n",
      "Rank  319: max feature #8171 (score = 5.106005)\n",
      "Rank  320: max feature #11552 (score = 5.105090)\n",
      "Rank  321: max feature #12951 (score = 5.102236)\n",
      "Rank  322: max feature #2998 (score = 5.101912)\n",
      "Rank  323: max feature #3059 (score = 5.101770)\n",
      "Rank  324: mean feature #10719 (score = 5.098747)\n",
      "Rank  325: max feature #2692 (score = 5.096279)\n",
      "Rank  326: max feature #9245 (score = 5.093306)\n",
      "Rank  327: mean feature #4564 (score = 5.088072)\n",
      "Rank  328: max feature #2453 (score = 5.086803)\n",
      "Rank  329: max feature #6122 (score = 5.084321)\n",
      "Rank  330: max feature #284 (score = 5.080411)\n",
      "Rank  331: max feature #3585 (score = 5.075951)\n",
      "Rank  332: max feature #3957 (score = 5.073589)\n",
      "Rank  333: mean feature #14199 (score = 5.068928)\n",
      "Rank  334: max feature #7302 (score = 5.067739)\n",
      "Rank  335: mean feature #7797 (score = 5.067421)\n",
      "Rank  336: max feature #14614 (score = 5.066952)\n",
      "Rank  337: max feature #14609 (score = 5.060311)\n",
      "Rank  338: max feature #3500 (score = 5.058683)\n",
      "Rank  339: max feature #8618 (score = 5.057022)\n",
      "Rank  340: mean feature #4660 (score = 5.051191)\n",
      "Rank  341: max feature #2021 (score = 5.049664)\n",
      "Rank  342: max feature #1664 (score = 5.049321)\n",
      "Rank  343: max feature #3564 (score = 5.048914)\n",
      "Rank  344: max feature #1327 (score = 5.048410)\n",
      "Rank  345: mean feature #12899 (score = 5.045957)\n",
      "Rank  346: max feature #9121 (score = 5.042655)\n",
      "Rank  347: max feature #10526 (score = 5.042340)\n",
      "Rank  348: max feature #280 (score = 5.038003)\n",
      "Rank  349: max feature #10050 (score = 5.037451)\n",
      "Rank  350: max feature #9622 (score = 5.034861)\n",
      "Rank  351: max feature #9437 (score = 5.033069)\n",
      "Rank  352: max feature #3998 (score = 5.031595)\n",
      "Rank  353: mean feature #10618 (score = 5.025691)\n",
      "Rank  354: mean feature #8486 (score = 5.022372)\n",
      "Rank  355: mean feature #10390 (score = 5.018120)\n",
      "Rank  356: max feature #9649 (score = 5.017361)\n",
      "Rank  357: max feature #2357 (score = 5.013947)\n",
      "Rank  358: max feature #16097 (score = 5.012540)\n",
      "Rank  359: max feature #2281 (score = 5.009440)\n",
      "Rank  360: max feature #12381 (score = 5.007571)\n",
      "Rank  361: mean feature #11259 (score = 5.007396)\n",
      "Rank  362: max feature #216 (score = 5.005874)\n",
      "Rank  363: max feature #11136 (score = 5.005554)\n",
      "Rank  364: mean feature #1519 (score = 5.003085)\n",
      "Rank  365: max feature #10459 (score = 4.997108)\n",
      "Rank  366: max feature #269 (score = 4.994761)\n",
      "Rank  367: mean feature #1899 (score = 4.994582)\n",
      "Rank  368: max feature #6964 (score = 4.991187)\n",
      "Rank  369: max feature #4660 (score = 4.985879)\n",
      "Rank  370: max feature #13500 (score = 4.982840)\n",
      "Rank  371: mean feature #12938 (score = 4.980941)\n",
      "Rank  372: max feature #12209 (score = 4.980163)\n",
      "Rank  373: mean feature #10982 (score = 4.972924)\n",
      "Rank  374: max feature #6275 (score = 4.971518)\n",
      "Rank  375: mean feature #15632 (score = 4.969836)\n",
      "Rank  376: mean feature #9205 (score = 4.968763)\n",
      "Rank  377: max feature #14363 (score = 4.967341)\n",
      "Rank  378: max feature #5776 (score = 4.960204)\n",
      "Rank  379: max feature #9974 (score = 4.958978)\n",
      "Rank  380: max feature #14079 (score = 4.958839)\n",
      "Rank  381: mean feature #6122 (score = 4.958391)\n",
      "Rank  382: max feature #4502 (score = 4.955788)\n",
      "Rank  383: mean feature #4789 (score = 4.951205)\n",
      "Rank  384: max feature #12192 (score = 4.949815)\n",
      "Rank  385: max feature #6126 (score = 4.946683)\n",
      "Rank  386: mean feature #12799 (score = 4.941939)\n",
      "Rank  387: max feature #5297 (score = 4.939628)\n",
      "Rank  388: max feature #14255 (score = 4.938409)\n",
      "Rank  389: max feature #1813 (score = 4.937377)\n",
      "Rank  390: max feature #8229 (score = 4.935735)\n",
      "Rank  391: mean feature #12021 (score = 4.935397)\n",
      "Rank  392: max feature #482 (score = 4.932043)\n",
      "Rank  393: mean feature #8667 (score = 4.929678)\n",
      "Rank  394: max feature #12899 (score = 4.929264)\n",
      "Rank  395: max feature #5103 (score = 4.929141)\n",
      "Rank  396: max feature #10792 (score = 4.928886)\n",
      "Rank  397: max feature #10113 (score = 4.925683)\n",
      "Rank  398: max feature #11342 (score = 4.922551)\n",
      "Rank  399: max feature #13727 (score = 4.921923)\n",
      "Rank  400: max feature #6289 (score = 4.915002)\n",
      "Rank  401: max feature #13545 (score = 4.912159)\n",
      "Rank  402: max feature #6332 (score = 4.909150)\n",
      "Rank  403: max feature #15396 (score = 4.908771)\n",
      "Rank  404: mean feature #10002 (score = 4.907525)\n",
      "Rank  405: mean feature #11552 (score = 4.905907)\n",
      "Rank  406: max feature #14816 (score = 4.904696)\n",
      "Rank  407: mean feature #14012 (score = 4.903140)\n",
      "Rank  408: mean feature #10656 (score = 4.901016)\n",
      "Rank  409: mean feature #587 (score = 4.895517)\n",
      "Rank  410: max feature #12121 (score = 4.891262)\n",
      "Rank  411: mean feature #13215 (score = 4.886014)\n",
      "Rank  412: max feature #15251 (score = 4.884767)\n",
      "Rank  413: max feature #3549 (score = 4.881477)\n",
      "Rank  414: max feature #1051 (score = 4.875888)\n",
      "Rank  415: max feature #5301 (score = 4.873820)\n",
      "Rank  416: mean feature #14080 (score = 4.872600)\n",
      "Rank  417: max feature #14123 (score = 4.872176)\n",
      "Rank  418: mean feature #5343 (score = 4.870719)\n",
      "Rank  419: mean feature #12434 (score = 4.870366)\n",
      "Rank  420: mean feature #2428 (score = 4.867411)\n",
      "Rank  421: max feature #10172 (score = 4.863123)\n",
      "Rank  422: max feature #4329 (score = 4.862005)\n",
      "Rank  423: mean feature #5612 (score = 4.859716)\n",
      "Rank  424: mean feature #3484 (score = 4.856890)\n",
      "Rank  425: max feature #10561 (score = 4.851643)\n",
      "Rank  426: mean feature #1604 (score = 4.849742)\n",
      "Rank  427: max feature #1112 (score = 4.846235)\n",
      "Rank  428: max feature #662 (score = 4.841536)\n",
      "Rank  429: max feature #4110 (score = 4.834782)\n",
      "Rank  430: max feature #696 (score = 4.833196)\n",
      "Rank  431: max feature #4385 (score = 4.833035)\n",
      "Rank  432: max feature #14910 (score = 4.833019)\n",
      "Rank  433: max feature #13252 (score = 4.830009)\n",
      "Rank  434: mean feature #3820 (score = 4.828207)\n",
      "Rank  435: mean feature #11273 (score = 4.826566)\n",
      "Rank  436: mean feature #15453 (score = 4.824562)\n",
      "Rank  437: mean feature #9163 (score = 4.822673)\n",
      "Rank  438: mean feature #11400 (score = 4.819685)\n",
      "Rank  439: mean feature #257 (score = 4.818125)\n",
      "Rank  440: mean feature #133 (score = 4.817092)\n",
      "Rank  441: mean feature #4558 (score = 4.816375)\n",
      "Rank  442: max feature #3174 (score = 4.809319)\n",
      "Rank  443: max feature #4408 (score = 4.807889)\n",
      "Rank  444: max feature #1090 (score = 4.802795)\n",
      "Rank  445: max feature #7654 (score = 4.801765)\n",
      "Rank  446: max feature #7516 (score = 4.801113)\n",
      "Rank  447: max feature #13076 (score = 4.800953)\n",
      "Rank  448: max feature #13132 (score = 4.798548)\n",
      "Rank  449: mean feature #1405 (score = 4.792901)\n",
      "Rank  450: max feature #15453 (score = 4.792578)\n",
      "Rank  451: mean feature #6470 (score = 4.790725)\n",
      "Rank  452: max feature #14175 (score = 4.787633)\n",
      "Rank  453: mean feature #11461 (score = 4.782151)\n",
      "Rank  454: mean feature #8300 (score = 4.781018)\n",
      "Rank  455: max feature #8832 (score = 4.776712)\n",
      "Rank  456: max feature #12799 (score = 4.776406)\n",
      "Rank  457: mean feature #13617 (score = 4.776262)\n",
      "Rank  458: mean feature #4113 (score = 4.776232)\n",
      "Rank  459: max feature #9700 (score = 4.775682)\n",
      "Rank  460: mean feature #14162 (score = 4.775197)\n",
      "Rank  461: max feature #10235 (score = 4.771995)\n",
      "Rank  462: max feature #5841 (score = 4.769658)\n",
      "Rank  463: mean feature #16021 (score = 4.769526)\n",
      "Rank  464: max feature #11728 (score = 4.765643)\n",
      "Rank  465: max feature #10418 (score = 4.764613)\n",
      "Rank  466: mean feature #11103 (score = 4.761458)\n",
      "Rank  467: max feature #6694 (score = 4.759336)\n",
      "Rank  468: max feature #4651 (score = 4.758565)\n",
      "Rank  469: max feature #5409 (score = 4.752594)\n",
      "Rank  470: max feature #14134 (score = 4.752285)\n",
      "Rank  471: max feature #4019 (score = 4.752196)\n",
      "Rank  472: max feature #13378 (score = 4.751604)\n",
      "Rank  473: max feature #8022 (score = 4.748382)\n",
      "Rank  474: max feature #14077 (score = 4.743294)\n",
      "Rank  475: max feature #13011 (score = 4.739106)\n",
      "Rank  476: mean feature #10113 (score = 4.737880)\n",
      "Rank  477: max feature #2625 (score = 4.737716)\n",
      "Rank  478: max feature #1156 (score = 4.737219)\n",
      "Rank  479: max feature #12133 (score = 4.736847)\n",
      "Rank  480: mean feature #14742 (score = 4.736457)\n",
      "Rank  481: max feature #1508 (score = 4.734419)\n",
      "Rank  482: max feature #3412 (score = 4.732318)\n",
      "Rank  483: mean feature #631 (score = 4.731212)\n",
      "Rank  484: mean feature #5273 (score = 4.720737)\n",
      "Rank  485: mean feature #12298 (score = 4.720698)\n",
      "Rank  486: mean feature #1525 (score = 4.720458)\n",
      "Rank  487: max feature #16250 (score = 4.719444)\n",
      "Rank  488: max feature #4263 (score = 4.717243)\n",
      "Rank  489: mean feature #2285 (score = 4.716079)\n",
      "Rank  490: mean feature #11353 (score = 4.712942)\n",
      "Rank  491: max feature #6674 (score = 4.712575)\n",
      "Rank  492: mean feature #12515 (score = 4.707765)\n",
      "Rank  493: max feature #1637 (score = 4.706624)\n",
      "Rank  494: mean feature #10827 (score = 4.705246)\n",
      "Rank  495: mean feature #9813 (score = 4.696045)\n",
      "Rank  496: mean feature #13549 (score = 4.693803)\n",
      "Rank  497: max feature #12497 (score = 4.692186)\n",
      "Rank  498: mean feature #15435 (score = 4.691353)\n",
      "Rank  499: max feature #13976 (score = 4.691264)\n",
      "Rank  500: mean feature #9437 (score = 4.689367)\n",
      "Rank  501: mean feature #2325 (score = 4.688203)\n",
      "Rank  502: max feature #4890 (score = 4.683331)\n",
      "Rank  503: max feature #10710 (score = 4.679630)\n",
      "Rank  504: max feature #9289 (score = 4.677333)\n",
      "Rank  505: mean feature #14595 (score = 4.677263)\n",
      "Rank  506: mean feature #11240 (score = 4.675042)\n",
      "Rank  507: max feature #6100 (score = 4.673643)\n",
      "Rank  508: max feature #10613 (score = 4.670275)\n",
      "Rank  509: mean feature #7654 (score = 4.668942)\n",
      "Rank  510: max feature #15154 (score = 4.666627)\n",
      "Rank  511: mean feature #11218 (score = 4.659742)\n",
      "Rank  512: max feature #3249 (score = 4.659443)\n",
      "Rank  513: max feature #9538 (score = 4.658845)\n",
      "Rank  514: max feature #12469 (score = 4.657195)\n",
      "Rank  515: max feature #6083 (score = 4.657042)\n",
      "Rank  516: mean feature #16278 (score = 4.653369)\n",
      "Rank  517: max feature #3484 (score = 4.650120)\n",
      "Rank  518: mean feature #5006 (score = 4.648853)\n",
      "Rank  519: mean feature #2133 (score = 4.647032)\n",
      "Rank  520: max feature #11125 (score = 4.643585)\n",
      "Rank  521: max feature #558 (score = 4.634421)\n",
      "Rank  522: mean feature #9974 (score = 4.633447)\n",
      "Rank  523: max feature #151 (score = 4.633135)\n",
      "Rank  524: mean feature #7418 (score = 4.628688)\n",
      "Rank  525: max feature #1988 (score = 4.628112)\n",
      "Rank  526: max feature #5523 (score = 4.625543)\n",
      "Rank  527: mean feature #5489 (score = 4.624424)\n",
      "Rank  528: mean feature #5002 (score = 4.624387)\n",
      "Rank  529: mean feature #1156 (score = 4.623781)\n",
      "Rank  530: max feature #3604 (score = 4.623385)\n",
      "Rank  531: max feature #9735 (score = 4.622981)\n",
      "Rank  532: max feature #13497 (score = 4.620938)\n",
      "Rank  533: max feature #6806 (score = 4.620775)\n",
      "Rank  534: max feature #7620 (score = 4.619317)\n",
      "Rank  535: max feature #13549 (score = 4.613919)\n",
      "Rank  536: mean feature #4126 (score = 4.613388)\n",
      "Rank  537: max feature #14442 (score = 4.611102)\n",
      "Rank  538: mean feature #9948 (score = 4.610479)\n",
      "Rank  539: max feature #15288 (score = 4.608986)\n",
      "Rank  540: max feature #14919 (score = 4.607094)\n",
      "Rank  541: max feature #12041 (score = 4.603445)\n",
      "Rank  542: mean feature #14543 (score = 4.601047)\n",
      "Rank  543: max feature #10756 (score = 4.600650)\n",
      "Rank  544: mean feature #9930 (score = 4.598680)\n",
      "Rank  545: max feature #10740 (score = 4.597989)\n",
      "Rank  546: max feature #257 (score = 4.596277)\n",
      "Rank  547: mean feature #3549 (score = 4.595660)\n",
      "Rank  548: max feature #14608 (score = 4.594760)\n",
      "Rank  549: mean feature #8310 (score = 4.594188)\n",
      "Rank  550: max feature #11777 (score = 4.593827)\n",
      "Rank  551: mean feature #10405 (score = 4.590904)\n",
      "Rank  552: max feature #13118 (score = 4.590835)\n",
      "Rank  553: mean feature #15176 (score = 4.589992)\n",
      "Rank  554: max feature #1092 (score = 4.586864)\n",
      "Rank  555: max feature #2617 (score = 4.586450)\n",
      "Rank  556: max feature #6486 (score = 4.585878)\n",
      "Rank  557: max feature #13395 (score = 4.585766)\n",
      "Rank  558: mean feature #4605 (score = 4.581474)\n",
      "Rank  559: mean feature #14844 (score = 4.579668)\n",
      "Rank  560: mean feature #6448 (score = 4.579289)\n",
      "Rank  561: max feature #13989 (score = 4.575852)\n",
      "Rank  562: mean feature #14663 (score = 4.574041)\n",
      "Rank  563: mean feature #13473 (score = 4.573306)\n",
      "Rank  564: max feature #1082 (score = 4.565560)\n",
      "Rank  565: mean feature #9118 (score = 4.564185)\n",
      "Rank  566: max feature #11273 (score = 4.563766)\n",
      "Rank  567: max feature #9604 (score = 4.561375)\n",
      "Rank  568: max feature #3265 (score = 4.559658)\n",
      "Rank  569: mean feature #8275 (score = 4.557124)\n",
      "Rank  570: max feature #827 (score = 4.553179)\n",
      "Rank  571: max feature #13912 (score = 4.551260)\n",
      "Rank  572: max feature #11324 (score = 4.550140)\n",
      "Rank  573: mean feature #7735 (score = 4.550098)\n",
      "Rank  574: max feature #5343 (score = 4.548828)\n",
      "Rank  575: max feature #9795 (score = 4.545939)\n",
      "Rank  576: max feature #7418 (score = 4.542601)\n",
      "Rank  577: max feature #15804 (score = 4.540057)\n",
      "Rank  578: max feature #8978 (score = 4.539929)\n",
      "Rank  579: max feature #15145 (score = 4.535720)\n",
      "Rank  580: max feature #13241 (score = 4.535680)\n",
      "Rank  581: max feature #2966 (score = 4.534114)\n",
      "Rank  582: mean feature #14745 (score = 4.530396)\n",
      "Rank  583: max feature #5618 (score = 4.529368)\n",
      "Rank  584: max feature #4177 (score = 4.526931)\n",
      "Rank  585: mean feature #6139 (score = 4.526831)\n",
      "Rank  586: mean feature #10050 (score = 4.520215)\n",
      "Rank  587: mean feature #8097 (score = 4.519936)\n",
      "Rank  588: max feature #6238 (score = 4.517071)\n",
      "Rank  589: max feature #12042 (score = 4.515230)\n",
      "Rank  590: max feature #14136 (score = 4.514614)\n",
      "Rank  591: max feature #6429 (score = 4.512178)\n",
      "Rank  592: max feature #4098 (score = 4.511952)\n",
      "Rank  593: max feature #13169 (score = 4.511553)\n",
      "Rank  594: max feature #7861 (score = 4.510927)\n",
      "Rank  595: mean feature #8518 (score = 4.509076)\n",
      "Rank  596: mean feature #13727 (score = 4.507942)\n",
      "Rank  597: max feature #8714 (score = 4.506272)\n",
      "Rank  598: max feature #3982 (score = 4.506060)\n",
      "Rank  599: max feature #13321 (score = 4.500546)\n",
      "Rank  600: mean feature #7172 (score = 4.498715)\n",
      "Rank  601: max feature #9908 (score = 4.498342)\n",
      "Rank  602: mean feature #14650 (score = 4.496294)\n",
      "Rank  603: max feature #9686 (score = 4.496219)\n",
      "Rank  604: mean feature #13877 (score = 4.495629)\n",
      "Rank  605: max feature #8268 (score = 4.494038)\n",
      "Rank  606: max feature #9691 (score = 4.491502)\n",
      "Rank  607: mean feature #4206 (score = 4.491228)\n",
      "Rank  608: max feature #9849 (score = 4.490339)\n",
      "Rank  609: max feature #5595 (score = 4.489331)\n",
      "Rank  610: max feature #3126 (score = 4.488600)\n",
      "Rank  611: mean feature #11235 (score = 4.488222)\n",
      "Rank  612: mean feature #14253 (score = 4.488018)\n",
      "Rank  613: mean feature #3534 (score = 4.487508)\n",
      "Rank  614: mean feature #8714 (score = 4.484074)\n",
      "Rank  615: mean feature #7294 (score = 4.481255)\n",
      "Rank  616: max feature #10043 (score = 4.480554)\n",
      "Rank  617: mean feature #8225 (score = 4.480432)\n",
      "Rank  618: max feature #16271 (score = 4.479306)\n",
      "Rank  619: mean feature #12196 (score = 4.479192)\n",
      "Rank  620: max feature #491 (score = 4.477146)\n",
      "Rank  621: mean feature #11125 (score = 4.474755)\n",
      "Rank  622: mean feature #9311 (score = 4.473224)\n",
      "Rank  623: mean feature #14429 (score = 4.472498)\n",
      "Rank  624: max feature #6423 (score = 4.472321)\n",
      "Rank  625: mean feature #1635 (score = 4.470863)\n",
      "Rank  626: max feature #2752 (score = 4.467868)\n",
      "Rank  627: mean feature #4007 (score = 4.467669)\n",
      "Rank  628: max feature #14666 (score = 4.466922)\n",
      "Rank  629: max feature #12058 (score = 4.466099)\n",
      "Rank  630: max feature #5002 (score = 4.462409)\n",
      "Rank  631: max feature #555 (score = 4.462052)\n",
      "Rank  632: max feature #4075 (score = 4.461109)\n",
      "Rank  633: mean feature #7067 (score = 4.460963)\n",
      "Rank  634: mean feature #4013 (score = 4.460324)\n",
      "Rank  635: max feature #14844 (score = 4.457955)\n",
      "Rank  636: mean feature #1443 (score = 4.455388)\n",
      "Rank  637: max feature #1704 (score = 4.454475)\n",
      "Rank  638: max feature #1863 (score = 4.451532)\n",
      "Rank  639: max feature #15815 (score = 4.450624)\n",
      "Rank  640: max feature #9118 (score = 4.448774)\n",
      "Rank  641: max feature #13156 (score = 4.447963)\n",
      "Rank  642: mean feature #12320 (score = 4.445289)\n",
      "Rank  643: max feature #13473 (score = 4.444807)\n",
      "Rank  644: max feature #9407 (score = 4.443122)\n",
      "Rank  645: max feature #13338 (score = 4.441266)\n",
      "Rank  646: max feature #1789 (score = 4.440323)\n",
      "Rank  647: mean feature #2264 (score = 4.439643)\n",
      "Rank  648: mean feature #4544 (score = 4.436337)\n",
      "Rank  649: mean feature #3542 (score = 4.435972)\n",
      "Rank  650: max feature #4789 (score = 4.434488)\n",
      "Rank  651: max feature #8300 (score = 4.433260)\n",
      "Rank  652: max feature #637 (score = 4.430971)\n",
      "Rank  653: mean feature #15232 (score = 4.428250)\n",
      "Rank  654: mean feature #8609 (score = 4.426001)\n",
      "Rank  655: mean feature #3947 (score = 4.423882)\n",
      "Rank  656: mean feature #10539 (score = 4.418477)\n",
      "Rank  657: mean feature #9179 (score = 4.418133)\n",
      "Rank  658: mean feature #11309 (score = 4.417873)\n",
      "Rank  659: max feature #14244 (score = 4.417450)\n",
      "Rank  660: max feature #6610 (score = 4.414572)\n",
      "Rank  661: mean feature #7386 (score = 4.414079)\n",
      "Rank  662: mean feature #9128 (score = 4.406107)\n",
      "Rank  663: mean feature #6254 (score = 4.400396)\n",
      "Rank  664: mean feature #12497 (score = 4.399400)\n",
      "Rank  665: mean feature #13976 (score = 4.397728)\n",
      "Rank  666: mean feature #15136 (score = 4.396041)\n",
      "Rank  667: max feature #10002 (score = 4.392993)\n",
      "Rank  668: max feature #12580 (score = 4.391487)\n",
      "Rank  669: mean feature #11131 (score = 4.391309)\n",
      "Rank  670: max feature #2839 (score = 4.390597)\n",
      "Rank  671: mean feature #1700 (score = 4.390052)\n",
      "Rank  672: mean feature #16011 (score = 4.388126)\n",
      "Rank  673: max feature #12020 (score = 4.388082)\n",
      "Rank  674: max feature #6270 (score = 4.386650)\n",
      "Rank  675: mean feature #8229 (score = 4.385574)\n",
      "Rank  676: max feature #1334 (score = 4.382619)\n",
      "Rank  677: max feature #5647 (score = 4.381695)\n",
      "Rank  678: max feature #10405 (score = 4.380823)\n",
      "Rank  679: mean feature #5266 (score = 4.380110)\n",
      "Rank  680: max feature #512 (score = 4.379659)\n",
      "Rank  681: max feature #5076 (score = 4.378181)\n",
      "Rank  682: max feature #10700 (score = 4.377839)\n",
      "Rank  683: max feature #2733 (score = 4.374291)\n",
      "Rank  684: mean feature #15169 (score = 4.374288)\n",
      "Rank  685: max feature #8244 (score = 4.372441)\n",
      "Rank  686: max feature #7899 (score = 4.372299)\n",
      "Rank  687: max feature #8349 (score = 4.370965)\n",
      "Rank  688: mean feature #4152 (score = 4.365700)\n",
      "Rank  689: max feature #11075 (score = 4.364975)\n",
      "Rank  690: max feature #15840 (score = 4.364258)\n",
      "Rank  691: max feature #16220 (score = 4.362286)\n",
      "Rank  692: max feature #15136 (score = 4.362118)\n",
      "Rank  693: max feature #2297 (score = 4.361494)\n",
      "Rank  694: mean feature #1599 (score = 4.358952)\n",
      "Rank  695: mean feature #294 (score = 4.358939)\n",
      "Rank  696: max feature #615 (score = 4.355708)\n",
      "Rank  697: max feature #963 (score = 4.353743)\n",
      "Rank  698: mean feature #15816 (score = 4.352448)\n",
      "Rank  699: mean feature #12637 (score = 4.351748)\n",
      "Rank  700: max feature #4126 (score = 4.351397)\n",
      "Rank  701: max feature #1172 (score = 4.351042)\n",
      "Rank  702: max feature #13040 (score = 4.348887)\n",
      "Rank  703: max feature #5867 (score = 4.346059)\n",
      "Rank  704: max feature #14010 (score = 4.345989)\n",
      "Rank  705: max feature #1199 (score = 4.337025)\n",
      "Rank  706: max feature #12196 (score = 4.335167)\n",
      "Rank  707: max feature #4236 (score = 4.334517)\n",
      "Rank  708: max feature #5656 (score = 4.334160)\n",
      "Rank  709: max feature #3958 (score = 4.333719)\n",
      "Rank  710: max feature #7709 (score = 4.332812)\n",
      "Rank  711: max feature #3590 (score = 4.332612)\n",
      "Rank  712: mean feature #10040 (score = 4.328147)\n",
      "Rank  713: mean feature #6864 (score = 4.325260)\n",
      "Rank  714: max feature #12398 (score = 4.324067)\n",
      "Rank  715: max feature #7646 (score = 4.323761)\n",
      "Rank  716: max feature #10545 (score = 4.321642)\n",
      "Rank  717: max feature #16293 (score = 4.318104)\n",
      "Rank  718: max feature #9925 (score = 4.315659)\n",
      "Rank  719: mean feature #12909 (score = 4.311453)\n",
      "Rank  720: mean feature #7046 (score = 4.311085)\n",
      "Rank  721: mean feature #6570 (score = 4.308605)\n",
      "Rank  722: max feature #10833 (score = 4.304292)\n",
      "Rank  723: mean feature #16117 (score = 4.301629)\n",
      "Rank  724: max feature #16011 (score = 4.300889)\n",
      "Rank  725: max feature #9948 (score = 4.300493)\n",
      "Rank  726: max feature #15323 (score = 4.299241)\n",
      "Rank  727: max feature #11044 (score = 4.298700)\n",
      "Rank  728: max feature #587 (score = 4.297813)\n",
      "Rank  729: max feature #12298 (score = 4.297032)\n",
      "Rank  730: mean feature #5142 (score = 4.295611)\n",
      "Rank  731: max feature #15398 (score = 4.295324)\n",
      "Rank  732: max feature #9301 (score = 4.293559)\n",
      "Rank  733: mean feature #14099 (score = 4.293330)\n",
      "Rank  734: mean feature #2702 (score = 4.293235)\n",
      "Rank  735: max feature #2289 (score = 4.292403)\n",
      "Rank  736: mean feature #14386 (score = 4.290583)\n",
      "Rank  737: max feature #15747 (score = 4.290560)\n",
      "Rank  738: max feature #7227 (score = 4.288804)\n",
      "Rank  739: max feature #4314 (score = 4.288511)\n",
      "Rank  740: max feature #1180 (score = 4.286614)\n",
      "Rank  741: max feature #1739 (score = 4.286304)\n",
      "Rank  742: mean feature #7452 (score = 4.283941)\n",
      "Rank  743: max feature #4720 (score = 4.282943)\n",
      "Rank  744: max feature #14986 (score = 4.281618)\n",
      "Rank  745: max feature #12723 (score = 4.280927)\n",
      "Rank  746: max feature #4372 (score = 4.278854)\n",
      "Rank  747: mean feature #11979 (score = 4.278798)\n",
      "Rank  748: mean feature #11679 (score = 4.276713)\n",
      "Rank  749: max feature #10976 (score = 4.274689)\n",
      "Rank  750: mean feature #12694 (score = 4.274353)\n",
      "Rank  751: max feature #6167 (score = 4.273037)\n",
      "Rank  752: mean feature #10033 (score = 4.270450)\n",
      "Rank  753: mean feature #15079 (score = 4.269685)\n",
      "Rank  754: mean feature #3456 (score = 4.269012)\n",
      "Rank  755: mean feature #14053 (score = 4.267696)\n",
      "Rank  756: max feature #11131 (score = 4.263256)\n",
      "Rank  757: max feature #2570 (score = 4.263170)\n",
      "Rank  758: max feature #15165 (score = 4.262930)\n",
      "Rank  759: max feature #325 (score = 4.262021)\n",
      "Rank  760: max feature #9655 (score = 4.261903)\n",
      "Rank  761: mean feature #1501 (score = 4.260864)\n",
      "Rank  762: max feature #13627 (score = 4.258168)\n",
      "Rank  763: max feature #14650 (score = 4.257003)\n",
      "Rank  764: max feature #13555 (score = 4.255445)\n",
      "Rank  765: max feature #3749 (score = 4.254216)\n",
      "Rank  766: max feature #7997 (score = 4.251999)\n",
      "Rank  767: mean feature #11633 (score = 4.251651)\n",
      "Rank  768: mean feature #6486 (score = 4.249801)\n",
      "Rank  769: max feature #14517 (score = 4.248393)\n",
      "Rank  770: mean feature #3154 (score = 4.248262)\n",
      "Rank  771: mean feature #2149 (score = 4.247963)\n",
      "Rank  772: mean feature #12682 (score = 4.247608)\n",
      "Rank  773: mean feature #3993 (score = 4.247407)\n",
      "Rank  774: max feature #945 (score = 4.247079)\n",
      "Rank  775: max feature #5577 (score = 4.246952)\n",
      "Rank  776: mean feature #2366 (score = 4.246913)\n",
      "Rank  777: max feature #2045 (score = 4.244032)\n",
      "Rank  778: mean feature #4746 (score = 4.241331)\n",
      "Rank  779: mean feature #5354 (score = 4.240697)\n",
      "Rank  780: mean feature #4236 (score = 4.237989)\n",
      "Rank  781: mean feature #15857 (score = 4.236504)\n",
      "Rank  782: max feature #13390 (score = 4.236395)\n",
      "Rank  783: max feature #4633 (score = 4.235704)\n",
      "Rank  784: mean feature #3982 (score = 4.230305)\n",
      "Rank  785: max feature #11441 (score = 4.230017)\n",
      "Rank  786: mean feature #16179 (score = 4.228567)\n",
      "Rank  787: mean feature #6289 (score = 4.228415)\n",
      "Rank  788: max feature #14698 (score = 4.227824)\n",
      "Rank  789: mean feature #6211 (score = 4.227750)\n",
      "Rank  790: max feature #5486 (score = 4.227633)\n",
      "Rank  791: max feature #10600 (score = 4.226014)\n",
      "Rank  792: max feature #10279 (score = 4.225420)\n",
      "Rank  793: max feature #1254 (score = 4.225370)\n",
      "Rank  794: max feature #720 (score = 4.224873)\n",
      "Rank  795: max feature #1399 (score = 4.223558)\n",
      "Rank  796: max feature #2048 (score = 4.222191)\n",
      "Rank  797: mean feature #10710 (score = 4.221936)\n",
      "Rank  798: mean feature #10650 (score = 4.220622)\n",
      "Rank  799: max feature #4441 (score = 4.220440)\n",
      "Rank  800: max feature #10693 (score = 4.217724)\n",
      "Rank  801: max feature #6430 (score = 4.216840)\n",
      "Rank  802: max feature #5027 (score = 4.212367)\n",
      "Rank  803: mean feature #1733 (score = 4.211171)\n",
      "Rank  804: max feature #3533 (score = 4.210960)\n",
      "Rank  805: max feature #13353 (score = 4.209166)\n",
      "Rank  806: mean feature #6000 (score = 4.208746)\n",
      "Rank  807: mean feature #2152 (score = 4.207216)\n",
      "Rank  808: mean feature #6281 (score = 4.206845)\n",
      "Rank  809: max feature #10821 (score = 4.206559)\n",
      "Rank  810: max feature #9112 (score = 4.205574)\n",
      "Rank  811: max feature #4485 (score = 4.204229)\n",
      "Rank  812: max feature #2442 (score = 4.200669)\n",
      "Rank  813: max feature #1420 (score = 4.198007)\n",
      "Rank  814: max feature #3746 (score = 4.197613)\n",
      "Rank  815: mean feature #6694 (score = 4.196515)\n",
      "Rank  816: max feature #3050 (score = 4.192886)\n",
      "Rank  817: mean feature #10645 (score = 4.191916)\n",
      "Rank  818: max feature #11733 (score = 4.190317)\n",
      "Rank  819: mean feature #7804 (score = 4.185423)\n",
      "Rank  820: max feature #15206 (score = 4.183754)\n",
      "Rank  821: mean feature #1211 (score = 4.183642)\n",
      "Rank  822: max feature #699 (score = 4.182014)\n",
      "Rank  823: max feature #13386 (score = 4.181803)\n",
      "Rank  824: max feature #7886 (score = 4.179070)\n",
      "Rank  825: mean feature #4314 (score = 4.177372)\n",
      "Rank  826: max feature #11578 (score = 4.177206)\n",
      "Rank  827: max feature #11979 (score = 4.174865)\n",
      "Rank  828: max feature #1700 (score = 4.174164)\n",
      "Rank  829: max feature #7797 (score = 4.173289)\n",
      "Rank  830: max feature #9053 (score = 4.171193)\n",
      "Rank  831: mean feature #8984 (score = 4.169339)\n",
      "Rank  832: max feature #11992 (score = 4.169271)\n",
      "Rank  833: max feature #14076 (score = 4.168710)\n",
      "Rank  834: max feature #15098 (score = 4.166918)\n",
      "Rank  835: mean feature #12362 (score = 4.163947)\n",
      "Rank  836: max feature #1881 (score = 4.163906)\n",
      "Rank  837: max feature #5295 (score = 4.163813)\n",
      "Rank  838: max feature #14412 (score = 4.163361)\n",
      "Rank  839: mean feature #951 (score = 4.162670)\n",
      "Rank  840: mean feature #216 (score = 4.162369)\n",
      "Rank  841: mean feature #4988 (score = 4.160563)\n",
      "Rank  842: mean feature #4536 (score = 4.160533)\n",
      "Rank  843: max feature #6689 (score = 4.158321)\n",
      "Rank  844: mean feature #931 (score = 4.158183)\n",
      "Rank  845: max feature #5454 (score = 4.156718)\n",
      "Rank  846: max feature #8221 (score = 4.155946)\n",
      "Rank  847: max feature #2712 (score = 4.154687)\n",
      "Rank  848: mean feature #4964 (score = 4.153221)\n",
      "Rank  849: mean feature #6618 (score = 4.151511)\n",
      "Rank  850: max feature #16117 (score = 4.150829)\n",
      "Rank  851: mean feature #14095 (score = 4.150287)\n",
      "Rank  852: max feature #12178 (score = 4.150276)\n",
      "Rank  853: mean feature #1074 (score = 4.150004)\n",
      "Rank  854: max feature #5581 (score = 4.149162)\n",
      "Rank  855: max feature #8113 (score = 4.149135)\n",
      "Rank  856: max feature #15005 (score = 4.147876)\n",
      "Rank  857: mean feature #14442 (score = 4.147487)\n",
      "Rank  858: mean feature #9751 (score = 4.143188)\n",
      "Rank  859: max feature #12553 (score = 4.142200)\n",
      "Rank  860: mean feature #15145 (score = 4.141723)\n",
      "Rank  861: mean feature #5445 (score = 4.141159)\n",
      "Rank  862: mean feature #4890 (score = 4.141075)\n",
      "Rank  863: max feature #4920 (score = 4.137345)\n",
      "Rank  864: max feature #5006 (score = 4.137137)\n",
      "Rank  865: mean feature #15254 (score = 4.136550)\n",
      "Rank  866: max feature #1885 (score = 4.135843)\n",
      "Rank  867: max feature #1679 (score = 4.134066)\n",
      "Rank  868: max feature #11641 (score = 4.133540)\n",
      "Rank  869: max feature #12304 (score = 4.132856)\n",
      "Rank  870: mean feature #13040 (score = 4.131406)\n",
      "Rank  871: max feature #13258 (score = 4.130439)\n",
      "Rank  872: max feature #9273 (score = 4.127610)\n",
      "Rank  873: max feature #16230 (score = 4.126477)\n",
      "Rank  874: max feature #11488 (score = 4.126070)\n",
      "Rank  875: mean feature #1746 (score = 4.125750)\n",
      "Rank  876: mean feature #14919 (score = 4.124415)\n",
      "Rank  877: max feature #3808 (score = 4.121709)\n",
      "Rank  878: mean feature #6615 (score = 4.118998)\n",
      "Rank  879: max feature #7093 (score = 4.118019)\n",
      "Rank  880: max feature #9205 (score = 4.113078)\n",
      "Rank  881: mean feature #6571 (score = 4.112469)\n",
      "Rank  882: mean feature #5615 (score = 4.112013)\n",
      "Rank  883: max feature #1903 (score = 4.111085)\n",
      "Rank  884: mean feature #12717 (score = 4.110936)\n",
      "Rank  885: max feature #3582 (score = 4.109845)\n",
      "Rank  886: max feature #3613 (score = 4.109656)\n",
      "Rank  887: mean feature #10155 (score = 4.105750)\n",
      "Rank  888: mean feature #4183 (score = 4.101892)\n",
      "Rank  889: max feature #2740 (score = 4.101823)\n",
      "Rank  890: max feature #5708 (score = 4.100779)\n",
      "Rank  891: max feature #8798 (score = 4.098499)\n",
      "Rank  892: max feature #9929 (score = 4.097884)\n",
      "Rank  893: max feature #9611 (score = 4.096620)\n",
      "Rank  894: mean feature #10788 (score = 4.094217)\n",
      "Rank  895: mean feature #14076 (score = 4.094184)\n",
      "Rank  896: mean feature #8633 (score = 4.089096)\n",
      "Rank  897: max feature #6637 (score = 4.088536)\n",
      "Rank  898: mean feature #8537 (score = 4.088049)\n",
      "Rank  899: mean feature #13646 (score = 4.087569)\n",
      "Rank  900: mean feature #86 (score = 4.086662)\n",
      "Rank  901: max feature #2535 (score = 4.086371)\n",
      "Rank  902: max feature #11289 (score = 4.083857)\n",
      "Rank  903: mean feature #10933 (score = 4.082976)\n",
      "Rank  904: max feature #4412 (score = 4.082426)\n",
      "Rank  905: max feature #3743 (score = 4.080270)\n",
      "Rank  906: max feature #8486 (score = 4.079532)\n",
      "Rank  907: max feature #12412 (score = 4.078393)\n",
      "Rank  908: max feature #6902 (score = 4.076239)\n",
      "Rank  909: mean feature #9925 (score = 4.075644)\n",
      "Rank  910: mean feature #2490 (score = 4.074308)\n",
      "Rank  911: mean feature #2792 (score = 4.073952)\n",
      "Rank  912: mean feature #3705 (score = 4.072274)\n",
      "Rank  913: mean feature #1813 (score = 4.072027)\n",
      "Rank  914: mean feature #437 (score = 4.070491)\n",
      "Rank  915: max feature #4531 (score = 4.070425)\n",
      "Rank  916: max feature #9179 (score = 4.070416)\n",
      "Rank  917: mean feature #9538 (score = 4.067986)\n",
      "Rank  918: mean feature #12020 (score = 4.065385)\n",
      "Rank  919: max feature #11444 (score = 4.065372)\n",
      "Rank  920: max feature #3494 (score = 4.062647)\n",
      "Rank  921: max feature #10759 (score = 4.061489)\n",
      "Rank  922: max feature #15430 (score = 4.061241)\n",
      "Rank  923: max feature #3371 (score = 4.060534)\n",
      "Rank  924: mean feature #4730 (score = 4.058569)\n",
      "Rank  925: mean feature #10879 (score = 4.058207)\n",
      "Rank  926: mean feature #10238 (score = 4.057483)\n",
      "Rank  927: mean feature #493 (score = 4.056827)\n",
      "Rank  928: max feature #11633 (score = 4.056674)\n",
      "Rank  929: max feature #13379 (score = 4.056209)\n",
      "Rank  930: max feature #11232 (score = 4.055440)\n",
      "Rank  931: max feature #9336 (score = 4.054345)\n",
      "Rank  932: mean feature #8244 (score = 4.053259)\n",
      "Rank  933: mean feature #6173 (score = 4.052144)\n",
      "Rank  934: max feature #14314 (score = 4.052103)\n",
      "Rank  935: max feature #15262 (score = 4.051666)\n",
      "Rank  936: max feature #261 (score = 4.050436)\n",
      "Rank  937: max feature #9244 (score = 4.049857)\n",
      "Rank  938: mean feature #5256 (score = 4.048272)\n",
      "Rank  939: mean feature #6609 (score = 4.047598)\n",
      "Rank  940: max feature #14326 (score = 4.045605)\n",
      "Rank  941: mean feature #482 (score = 4.045081)\n",
      "Rank  942: mean feature #505 (score = 4.044770)\n",
      "Rank  943: max feature #8934 (score = 4.044236)\n",
      "Rank  944: max feature #9890 (score = 4.043170)\n",
      "Rank  945: max feature #14873 (score = 4.042985)\n",
      "Rank  946: mean feature #8440 (score = 4.042897)\n",
      "Rank  947: mean feature #1198 (score = 4.036806)\n",
      "Rank  948: max feature #12645 (score = 4.036641)\n",
      "Rank  949: mean feature #3193 (score = 4.035893)\n",
      "Rank  950: mean feature #11049 (score = 4.035456)\n",
      "Rank  951: max feature #13991 (score = 4.035342)\n",
      "Rank  952: mean feature #12344 (score = 4.034812)\n",
      "Rank  953: max feature #9465 (score = 4.034581)\n",
      "Rank  954: max feature #11254 (score = 4.033404)\n",
      "Rank  955: max feature #3118 (score = 4.031566)\n",
      "Rank  956: max feature #875 (score = 4.028495)\n",
      "Rank  957: mean feature #13947 (score = 4.027114)\n",
      "Rank  958: max feature #9558 (score = 4.024353)\n",
      "Rank  959: mean feature #6935 (score = 4.024176)\n",
      "Rank  960: mean feature #12398 (score = 4.023575)\n",
      "Rank  961: max feature #5240 (score = 4.023309)\n",
      "Rank  962: mean feature #5485 (score = 4.021908)\n",
      "Rank  963: mean feature #13352 (score = 4.021748)\n",
      "Rank  964: max feature #2942 (score = 4.021218)\n",
      "Rank  965: max feature #12082 (score = 4.019866)\n",
      "Rank  966: max feature #277 (score = 4.017988)\n",
      "Rank  967: mean feature #12812 (score = 4.012891)\n",
      "Rank  968: max feature #15816 (score = 4.010519)\n",
      "Rank  969: max feature #10211 (score = 4.008695)\n",
      "Rank  970: max feature #5722 (score = 4.007780)\n",
      "Rank  971: max feature #9094 (score = 4.007717)\n",
      "Rank  972: mean feature #12699 (score = 4.007712)\n",
      "Rank  973: max feature #15593 (score = 4.007494)\n",
      "Rank  974: mean feature #9954 (score = 4.005389)\n",
      "Rank  975: max feature #15425 (score = 4.004722)\n",
      "Rank  976: mean feature #12228 (score = 4.003367)\n",
      "Rank  977: max feature #15531 (score = 4.001868)\n",
      "Rank  978: max feature #15417 (score = 4.001537)\n",
      "Rank  979: mean feature #12209 (score = 4.000819)\n",
      "Rank  980: max feature #12126 (score = 3.999810)\n",
      "Rank  981: max feature #12909 (score = 3.999444)\n",
      "Rank  982: max feature #10427 (score = 3.997913)\n",
      "Rank  983: max feature #14407 (score = 3.995640)\n",
      "Rank  984: mean feature #13338 (score = 3.993226)\n",
      "Rank  985: mean feature #4878 (score = 3.992755)\n",
      "Rank  986: max feature #7282 (score = 3.991630)\n",
      "Rank  987: mean feature #2182 (score = 3.990533)\n",
      "Rank  988: mean feature #2925 (score = 3.989547)\n",
      "Rank  989: mean feature #7316 (score = 3.988705)\n",
      "Rank  990: mean feature #5041 (score = 3.985262)\n",
      "Rank  991: max feature #13540 (score = 3.984614)\n",
      "Rank  992: mean feature #10295 (score = 3.981441)\n",
      "Rank  993: mean feature #12381 (score = 3.980876)\n",
      "Rank  994: mean feature #10497 (score = 3.980317)\n",
      "Rank  995: mean feature #1279 (score = 3.979841)\n",
      "Rank  996: max feature #8787 (score = 3.979266)\n",
      "Rank  997: max feature #14053 (score = 3.977985)\n",
      "Rank  998: mean feature #1143 (score = 3.977794)\n",
      "Rank  999: mean feature #2252 (score = 3.976160)\n",
      "Rank 1000: max feature #12228 (score = 3.976084)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117627/516470752.py:7: RuntimeWarning: invalid value encountered in divide\n",
      "  t_stats = np.abs((X_pos.mean(0) - X_neg.mean(0)) /\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(Xc)\n",
    "\n",
    "D = Xc.shape[1] // 2\n",
    "\n",
    "X_pos, X_neg = Xs[y == 1], Xs[y == 0]\n",
    "t_stats = np.abs((X_pos.mean(0) - X_neg.mean(0)) /\n",
    "                 np.sqrt(X_pos.var(0) / len(X_pos) + X_neg.var(0) / len(X_neg)))\n",
    "ranked_idx = rank_and_print(t_stats, D, \"T-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bc8ad87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== F-test top 1000 features ===\n",
      "Rank    1: mean feature #1541 (score = 90.344655)\n",
      "Rank    2: mean feature #10424 (score = 85.820289)\n",
      "Rank    3: mean feature #15085 (score = 84.318700)\n",
      "Rank    4: mean feature #10515 (score = 80.515695)\n",
      "Rank    5: mean feature #12299 (score = 79.622996)\n",
      "Rank    6: mean feature #7357 (score = 76.125641)\n",
      "Rank    7: mean feature #1381 (score = 74.895672)\n",
      "Rank    8: mean feature #11637 (score = 72.995094)\n",
      "Rank    9: mean feature #14370 (score = 72.390726)\n",
      "Rank   10: mean feature #6703 (score = 71.805893)\n",
      "Rank   11: mean feature #15621 (score = 70.357265)\n",
      "Rank   12: mean feature #255 (score = 69.605259)\n",
      "Rank   13: mean feature #10769 (score = 68.638974)\n",
      "Rank   14: mean feature #1520 (score = 68.432080)\n",
      "Rank   15: mean feature #3471 (score = 68.423135)\n",
      "Rank   16: mean feature #10656 (score = 68.274496)\n",
      "Rank   17: mean feature #9095 (score = 66.369306)\n",
      "Rank   18: mean feature #13882 (score = 66.335655)\n",
      "Rank   19: mean feature #1405 (score = 65.870977)\n",
      "Rank   20: mean feature #10010 (score = 65.751621)\n",
      "Rank   21: mean feature #10354 (score = 65.291134)\n",
      "Rank   22: mean feature #6290 (score = 64.961861)\n",
      "Rank   23: mean feature #11926 (score = 62.845267)\n",
      "Rank   24: mean feature #523 (score = 62.553893)\n",
      "Rank   25: mean feature #9502 (score = 62.482781)\n",
      "Rank   26: mean feature #8413 (score = 61.654035)\n",
      "Rank   27: mean feature #8333 (score = 61.545011)\n",
      "Rank   28: mean feature #14745 (score = 61.381486)\n",
      "Rank   29: mean feature #4558 (score = 60.809334)\n",
      "Rank   30: mean feature #1143 (score = 60.452738)\n",
      "Rank   31: mean feature #12282 (score = 59.999930)\n",
      "Rank   32: mean feature #4600 (score = 57.788734)\n",
      "Rank   33: mean feature #939 (score = 57.466182)\n",
      "Rank   34: mean feature #7589 (score = 56.850736)\n",
      "Rank   35: mean feature #12647 (score = 55.347627)\n",
      "Rank   36: mean feature #10561 (score = 55.091897)\n",
      "Rank   37: mean feature #11397 (score = 54.600834)\n",
      "Rank   38: mean feature #110 (score = 54.043417)\n",
      "Rank   39: mean feature #1712 (score = 53.029281)\n",
      "Rank   40: mean feature #1174 (score = 52.249826)\n",
      "Rank   41: mean feature #8430 (score = 51.180263)\n",
      "Rank   42: mean feature #12576 (score = 50.822068)\n",
      "Rank   43: mean feature #8776 (score = 50.782929)\n",
      "Rank   44: mean feature #13500 (score = 50.609827)\n",
      "Rank   45: mean feature #5317 (score = 50.330968)\n",
      "Rank   46: mean feature #10560 (score = 50.123092)\n",
      "Rank   47: mean feature #12149 (score = 49.083226)\n",
      "Rank   48: mean feature #12865 (score = 48.915011)\n",
      "Rank   49: mean feature #3609 (score = 48.788108)\n",
      "Rank   50: mean feature #14622 (score = 48.741056)\n",
      "Rank   51: mean feature #5144 (score = 48.629275)\n",
      "Rank   52: mean feature #15348 (score = 48.116343)\n",
      "Rank   53: mean feature #8823 (score = 48.050434)\n",
      "Rank   54: mean feature #13877 (score = 47.251834)\n",
      "Rank   55: mean feature #12515 (score = 47.119795)\n",
      "Rank   56: mean feature #1363 (score = 46.754393)\n",
      "Rank   57: mean feature #7456 (score = 46.427483)\n",
      "Rank   58: mean feature #6254 (score = 46.112384)\n",
      "Rank   59: mean feature #8732 (score = 46.071872)\n",
      "Rank   60: mean feature #5041 (score = 45.757603)\n",
      "Rank   61: mean feature #6694 (score = 45.541010)\n",
      "Rank   62: mean feature #15762 (score = 45.392276)\n",
      "Rank   63: mean feature #28 (score = 45.391746)\n",
      "Rank   64: mean feature #5315 (score = 45.048420)\n",
      "Rank   65: mean feature #2182 (score = 44.766705)\n",
      "Rank   66: mean feature #10618 (score = 44.700910)\n",
      "Rank   67: mean feature #10040 (score = 44.416812)\n",
      "Rank   68: mean feature #8225 (score = 44.219654)\n",
      "Rank   69: mean feature #2505 (score = 43.542750)\n",
      "Rank   70: mean feature #5273 (score = 43.471232)\n",
      "Rank   71: mean feature #667 (score = 43.415166)\n",
      "Rank   72: mean feature #5256 (score = 42.938233)\n",
      "Rank   73: mean feature #11235 (score = 42.856952)\n",
      "Rank   74: mean feature #11103 (score = 42.802604)\n",
      "Rank   75: mean feature #2310 (score = 42.398350)\n",
      "Rank   76: mean feature #8543 (score = 42.353020)\n",
      "Rank   77: mean feature #4110 (score = 42.122251)\n",
      "Rank   78: mean feature #5612 (score = 42.056248)\n",
      "Rank   79: mean feature #7654 (score = 41.299112)\n",
      "Rank   80: mean feature #7067 (score = 41.150757)\n",
      "Rank   81: mean feature #720 (score = 41.014302)\n",
      "Rank   82: mean feature #10421 (score = 41.006232)\n",
      "Rank   83: mean feature #5103 (score = 40.803563)\n",
      "Rank   84: mean feature #493 (score = 40.762440)\n",
      "Rank   85: mean feature #6615 (score = 40.733251)\n",
      "Rank   86: mean feature #5776 (score = 40.446276)\n",
      "Rank   87: mean feature #8618 (score = 40.349557)\n",
      "Rank   88: mean feature #3962 (score = 40.222258)\n",
      "Rank   89: mean feature #12637 (score = 40.105788)\n",
      "Rank   90: mean feature #13646 (score = 40.045081)\n",
      "Rank   91: mean feature #8667 (score = 40.038158)\n",
      "Rank   92: mean feature #3147 (score = 40.010970)\n",
      "Rank   93: mean feature #1390 (score = 39.778294)\n",
      "Rank   94: mean feature #8665 (score = 39.641591)\n",
      "Rank   95: mean feature #4408 (score = 39.076906)\n",
      "Rank   96: mean feature #10460 (score = 38.661449)\n",
      "Rank   97: mean feature #9945 (score = 38.645771)\n",
      "Rank   98: mean feature #931 (score = 38.594507)\n",
      "Rank   99: mean feature #5652 (score = 38.521131)\n",
      "Rank  100: mean feature #6038 (score = 38.431434)\n",
      "Rank  101: mean feature #15169 (score = 38.270262)\n",
      "Rank  102: mean feature #12211 (score = 37.930160)\n",
      "Rank  103: mean feature #5817 (score = 37.856553)\n",
      "Rank  104: mean feature #585 (score = 37.573989)\n",
      "Rank  105: mean feature #3990 (score = 37.251050)\n",
      "Rank  106: mean feature #8424 (score = 37.145747)\n",
      "Rank  107: mean feature #3059 (score = 36.667509)\n",
      "Rank  108: mean feature #10459 (score = 36.609649)\n",
      "Rank  109: mean feature #6281 (score = 36.456630)\n",
      "Rank  110: mean feature #1051 (score = 36.037602)\n",
      "Rank  111: mean feature #14363 (score = 35.970039)\n",
      "Rank  112: mean feature #11552 (score = 35.935508)\n",
      "Rank  113: mean feature #6070 (score = 35.872267)\n",
      "Rank  114: mean feature #9930 (score = 35.857319)\n",
      "Rank  115: mean feature #6470 (score = 35.854395)\n",
      "Rank  116: mean feature #10172 (score = 35.484841)\n",
      "Rank  117: mean feature #5523 (score = 35.271551)\n",
      "Rank  118: mean feature #8080 (score = 35.142672)\n",
      "Rank  119: mean feature #3958 (score = 34.721382)\n",
      "Rank  120: mean feature #13727 (score = 34.716060)\n",
      "Rank  121: mean feature #9230 (score = 34.432255)\n",
      "Rank  122: mean feature #14919 (score = 34.175691)\n",
      "Rank  123: mean feature #8380 (score = 34.117728)\n",
      "Rank  124: mean feature #16290 (score = 34.002071)\n",
      "Rank  125: mean feature #14910 (score = 33.944692)\n",
      "Rank  126: mean feature #2415 (score = 33.757646)\n",
      "Rank  127: mean feature #5301 (score = 33.753567)\n",
      "Rank  128: mean feature #13991 (score = 33.737015)\n",
      "Rank  129: mean feature #7804 (score = 33.375126)\n",
      "Rank  130: mean feature #10113 (score = 33.184942)\n",
      "Rank  131: mean feature #15128 (score = 33.018598)\n",
      "Rank  132: mean feature #5297 (score = 32.823779)\n",
      "Rank  133: mean feature #12553 (score = 32.753058)\n",
      "Rank  134: mean feature #13241 (score = 32.680466)\n",
      "Rank  135: mean feature #9882 (score = 32.569694)\n",
      "Rank  136: mean feature #10740 (score = 32.474852)\n",
      "Rank  137: mean feature #12663 (score = 32.470145)\n",
      "Rank  138: mean feature #6072 (score = 32.342709)\n",
      "Rank  139: mean feature #284 (score = 32.338317)\n",
      "Rank  140: mean feature #10792 (score = 32.287835)\n",
      "Rank  141: mean feature #4206 (score = 32.163710)\n",
      "Rank  142: mean feature #10002 (score = 32.125532)\n",
      "Rank  143: mean feature #9437 (score = 32.096595)\n",
      "Rank  144: mean feature #12352 (score = 31.931928)\n",
      "Rank  145: mean feature #13353 (score = 31.812782)\n",
      "Rank  146: mean feature #15482 (score = 31.810990)\n",
      "Rank  147: mean feature #14123 (score = 31.788759)\n",
      "Rank  148: mean feature #2488 (score = 31.406509)\n",
      "Rank  149: mean feature #1891 (score = 31.268905)\n",
      "Rank  150: mean feature #2617 (score = 30.952527)\n",
      "Rank  151: mean feature #14614 (score = 30.927205)\n",
      "Rank  152: mean feature #14136 (score = 30.861514)\n",
      "Rank  153: mean feature #3564 (score = 30.746015)\n",
      "Rank  154: mean feature #10719 (score = 30.537664)\n",
      "Rank  155: mean feature #10418 (score = 30.521305)\n",
      "Rank  156: mean feature #5409 (score = 30.369081)\n",
      "Rank  157: mean feature #8947 (score = 30.258127)\n",
      "Rank  158: mean feature #12398 (score = 30.252272)\n",
      "Rank  159: mean feature #9908 (score = 30.145929)\n",
      "Rank  160: mean feature #9245 (score = 30.026234)\n",
      "Rank  161: mean feature #11149 (score = 29.840881)\n",
      "Rank  162: mean feature #10929 (score = 29.717722)\n",
      "Rank  163: mean feature #15396 (score = 29.650464)\n",
      "Rank  164: mean feature #2352 (score = 29.532624)\n",
      "Rank  165: mean feature #635 (score = 29.524234)\n",
      "Rank  166: mean feature #14609 (score = 29.489276)\n",
      "Rank  167: mean feature #14650 (score = 29.336259)\n",
      "Rank  168: mean feature #3613 (score = 29.237706)\n",
      "Rank  169: mean feature #8679 (score = 29.220649)\n",
      "Rank  170: mean feature #6770 (score = 29.188191)\n",
      "Rank  171: mean feature #14255 (score = 29.185486)\n",
      "Rank  172: mean feature #5375 (score = 29.087539)\n",
      "Rank  173: mean feature #15632 (score = 29.075695)\n",
      "Rank  174: mean feature #8275 (score = 29.059983)\n",
      "Rank  175: mean feature #14277 (score = 29.038450)\n",
      "Rank  176: mean feature #8639 (score = 28.954986)\n",
      "Rank  177: mean feature #14442 (score = 28.952082)\n",
      "Rank  178: mean feature #12381 (score = 28.932567)\n",
      "Rank  179: mean feature #11131 (score = 28.871267)\n",
      "Rank  180: mean feature #3412 (score = 28.870835)\n",
      "Rank  181: mean feature #7302 (score = 28.794788)\n",
      "Rank  182: mean feature #9974 (score = 28.774937)\n",
      "Rank  183: mean feature #7282 (score = 28.704422)\n",
      "Rank  184: mean feature #6122 (score = 28.572662)\n",
      "Rank  185: mean feature #482 (score = 28.534738)\n",
      "Rank  186: mean feature #10700 (score = 28.522786)\n",
      "Rank  187: mean feature #4838 (score = 28.391191)\n",
      "Rank  188: mean feature #6238 (score = 28.389784)\n",
      "Rank  189: mean feature #8989 (score = 28.283460)\n",
      "Rank  190: mean feature #16278 (score = 28.144273)\n",
      "Rank  191: mean feature #14844 (score = 28.041521)\n",
      "Rank  192: mean feature #6275 (score = 28.010188)\n",
      "Rank  193: mean feature #1327 (score = 27.932980)\n",
      "Rank  194: mean feature #13497 (score = 27.575293)\n",
      "Rank  195: mean feature #9289 (score = 27.537137)\n",
      "Rank  196: mean feature #11827 (score = 27.420131)\n",
      "Rank  197: mean feature #13000 (score = 27.332834)\n",
      "Rank  198: mean feature #9849 (score = 27.180455)\n",
      "Rank  199: mean feature #2012 (score = 27.122087)\n",
      "Rank  200: mean feature #11488 (score = 27.086479)\n",
      "Rank  201: mean feature #4236 (score = 27.024183)\n",
      "Rank  202: mean feature #12484 (score = 26.971887)\n",
      "Rank  203: mean feature #4084 (score = 26.954659)\n",
      "Rank  204: mean feature #12723 (score = 26.885697)\n",
      "Rank  205: mean feature #3957 (score = 26.841374)\n",
      "Rank  206: mean feature #16250 (score = 26.789298)\n",
      "Rank  207: mean feature #15816 (score = 26.766177)\n",
      "Rank  208: mean feature #13132 (score = 26.647708)\n",
      "Rank  209: mean feature #5618 (score = 26.486871)\n",
      "Rank  210: mean feature #12209 (score = 26.446138)\n",
      "Rank  211: mean feature #12304 (score = 26.416263)\n",
      "Rank  212: mean feature #4372 (score = 26.409216)\n",
      "Rank  213: mean feature #15196 (score = 26.334371)\n",
      "Rank  214: mean feature #15857 (score = 26.286806)\n",
      "Rank  215: mean feature #5006 (score = 26.235892)\n",
      "Rank  216: mean feature #6173 (score = 26.229276)\n",
      "Rank  217: mean feature #1958 (score = 26.179344)\n",
      "Rank  218: mean feature #8229 (score = 26.176586)\n",
      "Rank  219: mean feature #1334 (score = 26.161996)\n",
      "Rank  220: mean feature #15145 (score = 26.126219)\n",
      "Rank  221: mean feature #2566 (score = 26.098395)\n",
      "Rank  222: mean feature #14175 (score = 26.086200)\n",
      "Rank  223: mean feature #1180 (score = 26.042333)\n",
      "Rank  224: mean feature #14134 (score = 25.662216)\n",
      "Rank  225: mean feature #4314 (score = 25.610901)\n",
      "Rank  226: mean feature #7517 (score = 25.582790)\n",
      "Rank  227: mean feature #10833 (score = 25.559550)\n",
      "Rank  228: mean feature #963 (score = 25.533356)\n",
      "Rank  229: mean feature #10756 (score = 25.459579)\n",
      "Rank  230: mean feature #1547 (score = 25.445423)\n",
      "Rank  231: mean feature #11324 (score = 25.408315)\n",
      "Rank  232: mean feature #3746 (score = 25.402157)\n",
      "Rank  233: mean feature #9149 (score = 25.279936)\n",
      "Rank  234: mean feature #13471 (score = 25.251055)\n",
      "Rank  235: mean feature #6100 (score = 25.233035)\n",
      "Rank  236: mean feature #13252 (score = 25.212356)\n",
      "Rank  237: mean feature #15251 (score = 25.199506)\n",
      "Rank  238: mean feature #9088 (score = 25.076434)\n",
      "Rank  239: mean feature #11633 (score = 25.056399)\n",
      "Rank  240: mean feature #1637 (score = 24.800181)\n",
      "Rank  241: mean feature #10235 (score = 24.787174)\n",
      "Rank  242: mean feature #14608 (score = 24.745122)\n",
      "Rank  243: mean feature #9118 (score = 24.725962)\n",
      "Rank  244: mean feature #8097 (score = 24.666912)\n",
      "Rank  245: mean feature #12469 (score = 24.642012)\n",
      "Rank  246: mean feature #14772 (score = 24.615176)\n",
      "Rank  247: mean feature #15557 (score = 24.578656)\n",
      "Rank  248: mean feature #3494 (score = 24.577892)\n",
      "Rank  249: mean feature #9813 (score = 24.562857)\n",
      "Rank  250: mean feature #2535 (score = 24.510972)\n",
      "Rank  251: mean feature #1704 (score = 24.393555)\n",
      "Rank  252: mean feature #856 (score = 24.371499)\n",
      "Rank  253: mean feature #2839 (score = 24.353331)\n",
      "Rank  254: mean feature #827 (score = 24.344794)\n",
      "Rank  255: mean feature #8978 (score = 24.299606)\n",
      "Rank  256: mean feature #10855 (score = 24.249966)\n",
      "Rank  257: mean feature #13912 (score = 24.244833)\n",
      "Rank  258: mean feature #14429 (score = 24.240388)\n",
      "Rank  259: mean feature #1156 (score = 24.144288)\n",
      "Rank  260: mean feature #15200 (score = 24.095144)\n",
      "Rank  261: mean feature #14892 (score = 24.068696)\n",
      "Rank  262: mean feature #14077 (score = 24.034369)\n",
      "Rank  263: mean feature #268 (score = 24.016752)\n",
      "Rank  264: mean feature #16179 (score = 23.899855)\n",
      "Rank  265: mean feature #16006 (score = 23.894170)\n",
      "Rank  266: mean feature #558 (score = 23.845137)\n",
      "Rank  267: mean feature #8714 (score = 23.807604)\n",
      "Rank  268: mean feature #6423 (score = 23.768061)\n",
      "Rank  269: mean feature #8832 (score = 23.684538)\n",
      "Rank  270: mean feature #2966 (score = 23.663428)\n",
      "Rank  271: mean feature #3998 (score = 23.657416)\n",
      "Rank  272: mean feature #6245 (score = 23.434584)\n",
      "Rank  273: mean feature #6083 (score = 23.381188)\n",
      "Rank  274: mean feature #12717 (score = 23.143570)\n",
      "Rank  275: mean feature #12041 (score = 23.113744)\n",
      "Rank  276: mean feature #9717 (score = 23.098903)\n",
      "Rank  277: mean feature #10613 (score = 22.944080)\n",
      "Rank  278: mean feature #12015 (score = 22.912136)\n",
      "Rank  279: mean feature #10976 (score = 22.690316)\n",
      "Rank  280: mean feature #9993 (score = 22.457420)\n",
      "Rank  281: mean feature #14076 (score = 22.371112)\n",
      "Rank  282: mean feature #13549 (score = 22.274481)\n",
      "Rank  283: mean feature #10720 (score = 22.242253)\n",
      "Rank  284: mean feature #14080 (score = 22.191317)\n",
      "Rank  285: mean feature #13258 (score = 22.188908)\n",
      "Rank  286: mean feature #15796 (score = 22.155116)\n",
      "Rank  287: mean feature #16271 (score = 22.090995)\n",
      "Rank  288: mean feature #4151 (score = 21.898859)\n",
      "Rank  289: mean feature #13989 (score = 21.887571)\n",
      "Rank  290: mean feature #15738 (score = 21.886497)\n",
      "Rank  291: mean feature #8349 (score = 21.820424)\n",
      "Rank  292: mean feature #7709 (score = 21.800625)\n",
      "Rank  293: mean feature #441 (score = 21.789223)\n",
      "Rank  294: mean feature #9615 (score = 21.703912)\n",
      "Rank  295: mean feature #1172 (score = 21.601347)\n",
      "Rank  296: mean feature #7861 (score = 21.574027)\n",
      "Rank  297: mean feature #9691 (score = 21.552421)\n",
      "Rank  298: mean feature #11843 (score = 21.413870)\n",
      "Rank  299: mean feature #13555 (score = 21.364792)\n",
      "Rank  300: mean feature #15398 (score = 21.256789)\n",
      "Rank  301: mean feature #9925 (score = 21.220469)\n",
      "Rank  302: mean feature #10759 (score = 21.176214)\n",
      "Rank  303: mean feature #1420 (score = 21.101600)\n",
      "Rank  304: mean feature #3482 (score = 21.084449)\n",
      "Rank  305: mean feature #13378 (score = 21.083543)\n",
      "Rank  306: mean feature #2045 (score = 21.006179)\n",
      "Rank  307: mean feature #12899 (score = 20.992299)\n",
      "Rank  308: mean feature #1863 (score = 20.959327)\n",
      "Rank  309: mean feature #14244 (score = 20.837622)\n",
      "Rank  310: mean feature #2152 (score = 20.813923)\n",
      "Rank  311: mean feature #9948 (score = 20.775235)\n",
      "Rank  312: mean feature #11044 (score = 20.761945)\n",
      "Rank  313: mean feature #615 (score = 20.717171)\n",
      "Rank  314: mean feature #1664 (score = 20.637472)\n",
      "Rank  315: mean feature #5841 (score = 20.584671)\n",
      "Rank  316: mean feature #1412 (score = 20.570154)\n",
      "Rank  317: mean feature #13530 (score = 20.497198)\n",
      "Rank  318: mean feature #12938 (score = 20.466078)\n",
      "Rank  319: mean feature #11461 (score = 20.436637)\n",
      "Rank  320: mean feature #1399 (score = 20.430940)\n",
      "Rank  321: mean feature #15572 (score = 20.399421)\n",
      "Rank  322: mean feature #15840 (score = 20.376117)\n",
      "Rank  323: mean feature #13737 (score = 20.341944)\n",
      "Rank  324: mean feature #1739 (score = 20.338252)\n",
      "Rank  325: mean feature #12831 (score = 20.275054)\n",
      "Rank  326: mean feature #8227 (score = 20.233493)\n",
      "Rank  327: mean feature #2048 (score = 20.167898)\n",
      "Rank  328: mean feature #4920 (score = 20.099361)\n",
      "Rank  329: mean feature #12595 (score = 20.079402)\n",
      "Rank  330: mean feature #699 (score = 20.068610)\n",
      "Rank  331: mean feature #2133 (score = 19.965315)\n",
      "Rank  332: mean feature #8113 (score = 19.962852)\n",
      "Rank  333: mean feature #2625 (score = 19.962572)\n",
      "Rank  334: mean feature #2570 (score = 19.934922)\n",
      "Rank  335: mean feature #11578 (score = 19.910081)\n",
      "Rank  336: mean feature #356 (score = 19.891618)\n",
      "Rank  337: mean feature #2281 (score = 19.848256)\n",
      "Rank  338: mean feature #6430 (score = 19.787834)\n",
      "Rank  339: mean feature #6332 (score = 19.782768)\n",
      "Rank  340: mean feature #5445 (score = 19.720769)\n",
      "Rank  341: mean feature #13804 (score = 19.655966)\n",
      "Rank  342: mean feature #11304 (score = 19.642161)\n",
      "Rank  343: mean feature #5680 (score = 19.619431)\n",
      "Rank  344: mean feature #16012 (score = 19.575632)\n",
      "Rank  345: mean feature #6126 (score = 19.523740)\n",
      "Rank  346: mean feature #5577 (score = 19.507959)\n",
      "Rank  347: mean feature #13968 (score = 19.485725)\n",
      "Rank  348: mean feature #4720 (score = 19.469271)\n",
      "Rank  349: mean feature #12497 (score = 19.419769)\n",
      "Rank  350: mean feature #13976 (score = 19.409504)\n",
      "Rank  351: mean feature #11857 (score = 19.395380)\n",
      "Rank  352: mean feature #15593 (score = 19.365158)\n",
      "Rank  353: mean feature #4983 (score = 19.363523)\n",
      "Rank  354: mean feature #10821 (score = 19.363305)\n",
      "Rank  355: mean feature #7227 (score = 19.332985)\n",
      "Rank  356: mean feature #11414 (score = 19.322034)\n",
      "Rank  357: mean feature #1602 (score = 19.321292)\n",
      "Rank  358: mean feature #5027 (score = 19.279280)\n",
      "Rank  359: mean feature #10697 (score = 19.252186)\n",
      "Rank  360: mean feature #2740 (score = 19.248399)\n",
      "Rank  361: mean feature #16097 (score = 19.191961)\n",
      "Rank  362: mean feature #5210 (score = 19.189071)\n",
      "Rank  363: mean feature #5489 (score = 19.158573)\n",
      "Rank  364: mean feature #4441 (score = 19.130085)\n",
      "Rank  365: mean feature #763 (score = 19.118184)\n",
      "Rank  366: mean feature #269 (score = 19.077286)\n",
      "Rank  367: mean feature #6167 (score = 19.057055)\n",
      "Rank  368: mean feature #5078 (score = 18.983347)\n",
      "Rank  369: mean feature #555 (score = 18.968696)\n",
      "Rank  370: mean feature #3342 (score = 18.936318)\n",
      "Rank  371: mean feature #3174 (score = 18.911580)\n",
      "Rank  372: mean feature #8617 (score = 18.901380)\n",
      "Rank  373: mean feature #12126 (score = 18.893524)\n",
      "Rank  374: mean feature #2021 (score = 18.882207)\n",
      "Rank  375: mean feature #15425 (score = 18.831727)\n",
      "Rank  376: mean feature #8486 (score = 18.763335)\n",
      "Rank  377: mean feature #11064 (score = 18.747610)\n",
      "Rank  378: mean feature #4755 (score = 18.700412)\n",
      "Rank  379: mean feature #1092 (score = 18.654512)\n",
      "Rank  380: mean feature #4981 (score = 18.650219)\n",
      "Rank  381: mean feature #9735 (score = 18.636562)\n",
      "Rank  382: mean feature #14595 (score = 18.612240)\n",
      "Rank  383: mean feature #9686 (score = 18.575691)\n",
      "Rank  384: mean feature #7459 (score = 18.566479)\n",
      "Rank  385: mean feature #11125 (score = 18.565275)\n",
      "Rank  386: mean feature #6610 (score = 18.555322)\n",
      "Rank  387: mean feature #13379 (score = 18.464428)\n",
      "Rank  388: mean feature #11232 (score = 18.428886)\n",
      "Rank  389: mean feature #1352 (score = 18.420867)\n",
      "Rank  390: mean feature #15512 (score = 18.420564)\n",
      "Rank  391: mean feature #3993 (score = 18.394171)\n",
      "Rank  392: mean feature #11642 (score = 18.256363)\n",
      "Rank  393: mean feature #8022 (score = 18.249911)\n",
      "Rank  394: mean feature #2819 (score = 18.246777)\n",
      "Rank  395: mean feature #6900 (score = 18.215810)\n",
      "Rank  396: mean feature #5295 (score = 18.196771)\n",
      "Rank  397: mean feature #11861 (score = 18.187769)\n",
      "Rank  398: mean feature #16235 (score = 18.155893)\n",
      "Rank  399: mean feature #1955 (score = 18.148656)\n",
      "Rank  400: mean feature #13011 (score = 18.122224)\n",
      "Rank  401: mean feature #5753 (score = 18.106686)\n",
      "Rank  402: mean feature #13540 (score = 18.106487)\n",
      "Rank  403: mean feature #8300 (score = 18.099718)\n",
      "Rank  404: mean feature #14407 (score = 18.073940)\n",
      "Rank  405: mean feature #1680 (score = 18.045550)\n",
      "Rank  406: mean feature #3073 (score = 17.985002)\n",
      "Rank  407: mean feature #12791 (score = 17.964374)\n",
      "Rank  408: mean feature #13849 (score = 17.953711)\n",
      "Rank  409: mean feature #10405 (score = 17.915293)\n",
      "Rank  410: mean feature #10997 (score = 17.897675)\n",
      "Rank  411: mean feature #484 (score = 17.882296)\n",
      "Rank  412: mean feature #3371 (score = 17.847240)\n",
      "Rank  413: mean feature #8171 (score = 17.811481)\n",
      "Rank  414: mean feature #3093 (score = 17.797072)\n",
      "Rank  415: mean feature #12909 (score = 17.796594)\n",
      "Rank  416: mean feature #13385 (score = 17.782535)\n",
      "Rank  417: mean feature #12554 (score = 17.715854)\n",
      "Rank  418: mean feature #10710 (score = 17.703592)\n",
      "Rank  419: mean feature #10888 (score = 17.604063)\n",
      "Rank  420: mean feature #6714 (score = 17.580275)\n",
      "Rank  421: mean feature #12121 (score = 17.543375)\n",
      "Rank  422: mean feature #8035 (score = 17.537000)\n",
      "Rank  423: mean feature #5647 (score = 17.486712)\n",
      "Rank  424: mean feature #1411 (score = 17.462770)\n",
      "Rank  425: mean feature #16220 (score = 17.413285)\n",
      "Rank  426: mean feature #9604 (score = 17.412545)\n",
      "Rank  427: mean feature #8184 (score = 17.406576)\n",
      "Rank  428: mean feature #15098 (score = 17.374963)\n",
      "Rank  429: mean feature #10427 (score = 17.334787)\n",
      "Rank  430: mean feature #623 (score = 17.312613)\n",
      "Rank  431: mean feature #13118 (score = 17.308928)\n",
      "Rank  432: mean feature #2712 (score = 17.307492)\n",
      "Rank  433: mean feature #13869 (score = 17.278428)\n",
      "Rank  434: mean feature #11201 (score = 17.276430)\n",
      "Rank  435: mean feature #16032 (score = 17.264487)\n",
      "Rank  436: mean feature #15323 (score = 17.252200)\n",
      "Rank  437: mean feature #3585 (score = 17.230165)\n",
      "Rank  438: mean feature #12228 (score = 17.205890)\n",
      "Rank  439: mean feature #7452 (score = 17.197164)\n",
      "Rank  440: mean feature #9611 (score = 17.187547)\n",
      "Rank  441: mean feature #216 (score = 17.178298)\n",
      "Rank  442: mean feature #4502 (score = 17.154729)\n",
      "Rank  443: mean feature #7755 (score = 17.125229)\n",
      "Rank  444: mean feature #4703 (score = 17.103759)\n",
      "Rank  445: mean feature #6695 (score = 17.090433)\n",
      "Rank  446: mean feature #12974 (score = 17.090037)\n",
      "Rank  447: mean feature #10050 (score = 17.088531)\n",
      "Rank  448: mean feature #13545 (score = 17.073253)\n",
      "Rank  449: mean feature #2437 (score = 17.061057)\n",
      "Rank  450: mean feature #150 (score = 17.032503)\n",
      "Rank  451: mean feature #12284 (score = 17.012927)\n",
      "Rank  452: mean feature #15430 (score = 17.011018)\n",
      "Rank  453: mean feature #280 (score = 16.990152)\n",
      "Rank  454: mean feature #4842 (score = 16.970377)\n",
      "Rank  455: mean feature #2725 (score = 16.921386)\n",
      "Rank  456: mean feature #11816 (score = 16.911744)\n",
      "Rank  457: mean feature #10982 (score = 16.908471)\n",
      "Rank  458: mean feature #4126 (score = 16.893927)\n",
      "Rank  459: mean feature #13824 (score = 16.890261)\n",
      "Rank  460: mean feature #13671 (score = 16.886347)\n",
      "Rank  461: mean feature #631 (score = 16.878540)\n",
      "Rank  462: mean feature #6520 (score = 16.834266)\n",
      "Rank  463: mean feature #12219 (score = 16.797477)\n",
      "Rank  464: mean feature #14349 (score = 16.777670)\n",
      "Rank  465: mean feature #6289 (score = 16.766585)\n",
      "Rank  466: mean feature #512 (score = 16.762421)\n",
      "Rank  467: mean feature #6637 (score = 16.694185)\n",
      "Rank  468: mean feature #8926 (score = 16.641781)\n",
      "Rank  469: mean feature #13627 (score = 16.633773)\n",
      "Rank  470: mean feature #818 (score = 16.600372)\n",
      "Rank  471: mean feature #6486 (score = 16.597823)\n",
      "Rank  472: mean feature #4329 (score = 16.572305)\n",
      "Rank  473: mean feature #2988 (score = 16.571173)\n",
      "Rank  474: mean feature #15214 (score = 16.519217)\n",
      "Rank  475: mean feature #2297 (score = 16.506638)\n",
      "Rank  476: mean feature #14816 (score = 16.430638)\n",
      "Rank  477: mean feature #6017 (score = 16.424991)\n",
      "Rank  478: mean feature #3788 (score = 16.422659)\n",
      "Rank  479: mean feature #15681 (score = 16.407968)\n",
      "Rank  480: mean feature #1647 (score = 16.360174)\n",
      "Rank  481: mean feature #1679 (score = 16.280478)\n",
      "Rank  482: mean feature #6689 (score = 16.237077)\n",
      "Rank  483: mean feature #15815 (score = 16.228901)\n",
      "Rank  484: mean feature #9336 (score = 16.213693)\n",
      "Rank  485: mean feature #1511 (score = 16.194939)\n",
      "Rank  486: mean feature #13395 (score = 16.179465)\n",
      "Rank  487: mean feature #3249 (score = 16.171425)\n",
      "Rank  488: mean feature #12058 (score = 16.139186)\n",
      "Rank  489: mean feature #11400 (score = 16.138540)\n",
      "Rank  490: mean feature #3604 (score = 16.079624)\n",
      "Rank  491: mean feature #15239 (score = 16.004473)\n",
      "Rank  492: mean feature #15782 (score = 16.004430)\n",
      "Rank  493: mean feature #945 (score = 15.929307)\n",
      "Rank  494: mean feature #16230 (score = 15.913686)\n",
      "Rank  495: mean feature #6806 (score = 15.858661)\n",
      "Rank  496: mean feature #9164 (score = 15.839599)\n",
      "Rank  497: mean feature #6090 (score = 15.829249)\n",
      "Rank  498: mean feature #15206 (score = 15.793667)\n",
      "Rank  499: mean feature #5684 (score = 15.782338)\n",
      "Rank  500: mean feature #6944 (score = 15.761612)\n",
      "Rank  501: mean feature #14721 (score = 15.743420)\n",
      "Rank  502: mean feature #14412 (score = 15.699764)\n",
      "Rank  503: mean feature #7797 (score = 15.697198)\n",
      "Rank  504: mean feature #15232 (score = 15.675678)\n",
      "Rank  505: mean feature #3808 (score = 15.632696)\n",
      "Rank  506: mean feature #4183 (score = 15.623025)\n",
      "Rank  507: mean feature #4633 (score = 15.554992)\n",
      "Rank  508: mean feature #2534 (score = 15.534268)\n",
      "Rank  509: mean feature #13670 (score = 15.515113)\n",
      "Rank  510: mean feature #4385 (score = 15.494000)\n",
      "Rank  511: mean feature #11075 (score = 15.489258)\n",
      "Rank  512: mean feature #6802 (score = 15.445578)\n",
      "Rank  513: mean feature #2741 (score = 15.426995)\n",
      "Rank  514: mean feature #6410 (score = 15.421772)\n",
      "Rank  515: mean feature #9205 (score = 15.420221)\n",
      "Rank  516: mean feature #9845 (score = 15.410705)\n",
      "Rank  517: mean feature #7462 (score = 15.410442)\n",
      "Rank  518: mean feature #8671 (score = 15.385524)\n",
      "Rank  519: mean feature #9969 (score = 15.374166)\n",
      "Rank  520: mean feature #7467 (score = 15.355367)\n",
      "Rank  521: mean feature #14793 (score = 15.336091)\n",
      "Rank  522: mean feature #63 (score = 15.296205)\n",
      "Rank  523: mean feature #12775 (score = 15.289772)\n",
      "Rank  524: mean feature #11979 (score = 15.275184)\n",
      "Rank  525: mean feature #4876 (score = 15.272349)\n",
      "Rank  526: mean feature #11005 (score = 15.225091)\n",
      "Rank  527: mean feature #3677 (score = 15.196064)\n",
      "Rank  528: mean feature #97 (score = 15.172435)\n",
      "Rank  529: mean feature #1686 (score = 15.171778)\n",
      "Rank  530: mean feature #4605 (score = 15.140573)\n",
      "Rank  531: mean feature #9519 (score = 15.113670)\n",
      "Rank  532: mean feature #816 (score = 15.109350)\n",
      "Rank  533: mean feature #15615 (score = 15.077251)\n",
      "Rank  534: mean feature #1544 (score = 15.061876)\n",
      "Rank  535: mean feature #16326 (score = 15.042781)\n",
      "Rank  536: mean feature #1885 (score = 15.037049)\n",
      "Rank  537: mean feature #11087 (score = 15.017998)\n",
      "Rank  538: mean feature #8410 (score = 14.983049)\n",
      "Rank  539: mean feature #8268 (score = 14.952470)\n",
      "Rank  540: mean feature #2001 (score = 14.942583)\n",
      "Rank  541: mean feature #9301 (score = 14.923166)\n",
      "Rank  542: mean feature #3500 (score = 14.910606)\n",
      "Rank  543: mean feature #10391 (score = 14.894824)\n",
      "Rank  544: mean feature #662 (score = 14.884910)\n",
      "Rank  545: mean feature #4283 (score = 14.866315)\n",
      "Rank  546: mean feature #14189 (score = 14.844298)\n",
      "Rank  547: mean feature #9990 (score = 14.839919)\n",
      "Rank  548: mean feature #15327 (score = 14.825833)\n",
      "Rank  549: mean feature #16011 (score = 14.814820)\n",
      "Rank  550: mean feature #4153 (score = 14.787474)\n",
      "Rank  551: mean feature #9053 (score = 14.766590)\n",
      "Rank  552: mean feature #7024 (score = 14.766022)\n",
      "Rank  553: mean feature #1924 (score = 14.760832)\n",
      "Rank  554: mean feature #16248 (score = 14.722550)\n",
      "Rank  555: mean feature #716 (score = 14.691635)\n",
      "Rank  556: mean feature #6783 (score = 14.671932)\n",
      "Rank  557: mean feature #14053 (score = 14.655430)\n",
      "Rank  558: mean feature #1074 (score = 14.643245)\n",
      "Rank  559: mean feature #151 (score = 14.630029)\n",
      "Rank  560: mean feature #5057 (score = 14.602758)\n",
      "Rank  561: mean feature #2289 (score = 14.599760)\n",
      "Rank  562: mean feature #4272 (score = 14.598068)\n",
      "Rank  563: mean feature #5581 (score = 14.591333)\n",
      "Rank  564: mean feature #7886 (score = 14.536700)\n",
      "Rank  565: mean feature #3558 (score = 14.516737)\n",
      "Rank  566: mean feature #139 (score = 14.506042)\n",
      "Rank  567: mean feature #2203 (score = 14.484201)\n",
      "Rank  568: mean feature #3846 (score = 14.468228)\n",
      "Rank  569: mean feature #15453 (score = 14.457306)\n",
      "Rank  570: mean feature #1754 (score = 14.452918)\n",
      "Rank  571: mean feature #3785 (score = 14.446073)\n",
      "Rank  572: mean feature #1813 (score = 14.443615)\n",
      "Rank  573: mean feature #12802 (score = 14.441325)\n",
      "Rank  574: mean feature #12460 (score = 14.436523)\n",
      "Rank  575: mean feature #1875 (score = 14.434605)\n",
      "Rank  576: mean feature #7252 (score = 14.428428)\n",
      "Rank  577: mean feature #7735 (score = 14.423414)\n",
      "Rank  578: mean feature #13321 (score = 14.390810)\n",
      "Rank  579: mean feature #13369 (score = 14.385959)\n",
      "Rank  580: mean feature #2942 (score = 14.377254)\n",
      "Rank  581: mean feature #15012 (score = 14.368915)\n",
      "Rank  582: mean feature #6674 (score = 14.347173)\n",
      "Rank  583: mean feature #5350 (score = 14.337398)\n",
      "Rank  584: mean feature #5553 (score = 14.327911)\n",
      "Rank  585: mean feature #12394 (score = 14.314159)\n",
      "Rank  586: mean feature #4317 (score = 14.283629)\n",
      "Rank  587: mean feature #8709 (score = 14.273703)\n",
      "Rank  588: mean feature #14278 (score = 14.266175)\n",
      "Rank  589: mean feature #1988 (score = 14.233182)\n",
      "Rank  590: mean feature #14778 (score = 14.229859)\n",
      "Rank  591: mean feature #2440 (score = 14.199929)\n",
      "Rank  592: mean feature #13089 (score = 14.186539)\n",
      "Rank  593: mean feature #10827 (score = 14.185619)\n",
      "Rank  594: mean feature #14454 (score = 14.173353)\n",
      "Rank  595: mean feature #10266 (score = 14.146737)\n",
      "Rank  596: mean feature #5822 (score = 14.119981)\n",
      "Rank  597: mean feature #12315 (score = 14.112038)\n",
      "Rank  598: mean feature #12410 (score = 14.108211)\n",
      "Rank  599: mean feature #12153 (score = 14.104254)\n",
      "Rank  600: mean feature #2011 (score = 14.095825)\n",
      "Rank  601: mean feature #11136 (score = 14.064670)\n",
      "Rank  602: mean feature #257 (score = 14.060508)\n",
      "Rank  603: mean feature #9019 (score = 14.056122)\n",
      "Rank  604: mean feature #7266 (score = 14.048595)\n",
      "Rank  605: mean feature #13355 (score = 14.045419)\n",
      "Rank  606: mean feature #10522 (score = 14.041548)\n",
      "Rank  607: mean feature #277 (score = 13.996049)\n",
      "Rank  608: mean feature #4075 (score = 13.988814)\n",
      "Rank  609: mean feature #10662 (score = 13.984396)\n",
      "Rank  610: mean feature #9879 (score = 13.981295)\n",
      "Rank  611: mean feature #4740 (score = 13.973625)\n",
      "Rank  612: mean feature #3590 (score = 13.956290)\n",
      "Rank  613: mean feature #13880 (score = 13.951339)\n",
      "Rank  614: mean feature #2998 (score = 13.946367)\n",
      "Rank  615: mean feature #6618 (score = 13.935822)\n",
      "Rank  616: mean feature #9649 (score = 13.934345)\n",
      "Rank  617: mean feature #3699 (score = 13.925470)\n",
      "Rank  618: mean feature #13526 (score = 13.914616)\n",
      "Rank  619: mean feature #15238 (score = 13.914514)\n",
      "Rank  620: mean feature #2408 (score = 13.913183)\n",
      "Rank  621: mean feature #4890 (score = 13.910073)\n",
      "Rank  622: mean feature #15262 (score = 13.909218)\n",
      "Rank  623: mean feature #14447 (score = 13.895782)\n",
      "Rank  624: mean feature #13076 (score = 13.868550)\n",
      "Rank  625: mean feature #9122 (score = 13.851560)\n",
      "Rank  626: mean feature #8273 (score = 13.841299)\n",
      "Rank  627: mean feature #9558 (score = 13.834455)\n",
      "Rank  628: mean feature #1243 (score = 13.827830)\n",
      "Rank  629: mean feature #9865 (score = 13.827317)\n",
      "Rank  630: mean feature #16153 (score = 13.819065)\n",
      "Rank  631: mean feature #5486 (score = 13.808048)\n",
      "Rank  632: mean feature #10889 (score = 13.804667)\n",
      "Rank  633: mean feature #8817 (score = 13.792587)\n",
      "Rank  634: mean feature #14031 (score = 13.766811)\n",
      "Rank  635: mean feature #9700 (score = 13.759393)\n",
      "Rank  636: mean feature #1733 (score = 13.748020)\n",
      "Rank  637: mean feature #9929 (score = 13.741077)\n",
      "Rank  638: mean feature #2445 (score = 13.738093)\n",
      "Rank  639: mean feature #16334 (score = 13.726351)\n",
      "Rank  640: mean feature #15005 (score = 13.721600)\n",
      "Rank  641: mean feature #1167 (score = 13.717381)\n",
      "Rank  642: mean feature #4177 (score = 13.713147)\n",
      "Rank  643: mean feature #13858 (score = 13.710158)\n",
      "Rank  644: mean feature #15431 (score = 13.709515)\n",
      "Rank  645: mean feature #7093 (score = 13.699649)\n",
      "Rank  646: mean feature #10245 (score = 13.698368)\n",
      "Rank  647: mean feature #8614 (score = 13.672339)\n",
      "Rank  648: mean feature #2439 (score = 13.665503)\n",
      "Rank  649: mean feature #3375 (score = 13.663456)\n",
      "Rank  650: mean feature #11273 (score = 13.662612)\n",
      "Rank  651: mean feature #9288 (score = 13.645080)\n",
      "Rank  652: mean feature #350 (score = 13.634838)\n",
      "Rank  653: mean feature #6902 (score = 13.601871)\n",
      "Rank  654: mean feature #7054 (score = 13.593645)\n",
      "Rank  655: mean feature #11733 (score = 13.582583)\n",
      "Rank  656: mean feature #14084 (score = 13.553444)\n",
      "Rank  657: mean feature #10211 (score = 13.541141)\n",
      "Rank  658: mean feature #2407 (score = 13.534589)\n",
      "Rank  659: mean feature #13672 (score = 13.507082)\n",
      "Rank  660: mean feature #8735 (score = 13.493290)\n",
      "Rank  661: mean feature #1590 (score = 13.486245)\n",
      "Rank  662: mean feature #15165 (score = 13.476045)\n",
      "Rank  663: mean feature #11317 (score = 13.472233)\n",
      "Rank  664: mean feature #4098 (score = 13.469455)\n",
      "Rank  665: mean feature #11777 (score = 13.464524)\n",
      "Rank  666: mean feature #4113 (score = 13.460024)\n",
      "Rank  667: mean feature #1112 (score = 13.458676)\n",
      "Rank  668: mean feature #4259 (score = 13.451677)\n",
      "Rank  669: mean feature #10637 (score = 13.450411)\n",
      "Rank  670: mean feature #2041 (score = 13.425383)\n",
      "Rank  671: mean feature #14905 (score = 13.417029)\n",
      "Rank  672: mean feature #3126 (score = 13.405188)\n",
      "Rank  673: mean feature #2892 (score = 13.391960)\n",
      "Rank  674: mean feature #12720 (score = 13.383969)\n",
      "Rank  675: mean feature #14588 (score = 13.369984)\n",
      "Rank  676: mean feature #9319 (score = 13.360043)\n",
      "Rank  677: mean feature #11188 (score = 13.356364)\n",
      "Rank  678: mean feature #5859 (score = 13.353047)\n",
      "Rank  679: mean feature #9919 (score = 13.288055)\n",
      "Rank  680: mean feature #11014 (score = 13.283614)\n",
      "Rank  681: mean feature #8836 (score = 13.280854)\n",
      "Rank  682: mean feature #12308 (score = 13.258069)\n",
      "Rank  683: mean feature #11707 (score = 13.257261)\n",
      "Rank  684: mean feature #13816 (score = 13.249703)\n",
      "Rank  685: mean feature #11212 (score = 13.214571)\n",
      "Rank  686: mean feature #7046 (score = 13.211108)\n",
      "Rank  687: mean feature #14327 (score = 13.204990)\n",
      "Rank  688: mean feature #6270 (score = 13.180234)\n",
      "Rank  689: mean feature #1789 (score = 13.173844)\n",
      "Rank  690: mean feature #1777 (score = 13.163391)\n",
      "Rank  691: mean feature #14021 (score = 13.153320)\n",
      "Rank  692: mean feature #10709 (score = 13.145012)\n",
      "Rank  693: mean feature #1350 (score = 13.140092)\n",
      "Rank  694: mean feature #16117 (score = 13.128259)\n",
      "Rank  695: mean feature #15001 (score = 13.125370)\n",
      "Rank  696: mean feature #1199 (score = 13.119269)\n",
      "Rank  697: mean feature #15176 (score = 13.118124)\n",
      "Rank  698: mean feature #6954 (score = 13.116275)\n",
      "Rank  699: mean feature #903 (score = 13.111927)\n",
      "Rank  700: mean feature #4709 (score = 13.107743)\n",
      "Rank  701: mean feature #5828 (score = 13.103422)\n",
      "Rank  702: mean feature #10238 (score = 13.102266)\n",
      "Rank  703: mean feature #50 (score = 13.047381)\n",
      "Rank  704: mean feature #10770 (score = 13.046921)\n",
      "Rank  705: mean feature #15424 (score = 13.043851)\n",
      "Rank  706: mean feature #11971 (score = 13.034983)\n",
      "Rank  707: mean feature #14951 (score = 13.001827)\n",
      "Rank  708: mean feature #696 (score = 13.000505)\n",
      "Rank  709: mean feature #14908 (score = 13.000143)\n",
      "Rank  710: mean feature #13856 (score = 12.995828)\n",
      "Rank  711: mean feature #5358 (score = 12.993012)\n",
      "Rank  712: mean feature #4453 (score = 12.964224)\n",
      "Rank  713: mean feature #3650 (score = 12.924299)\n",
      "Rank  714: mean feature #10679 (score = 12.916855)\n",
      "Rank  715: mean feature #13156 (score = 12.910174)\n",
      "Rank  716: mean feature #8059 (score = 12.902374)\n",
      "Rank  717: mean feature #5309 (score = 12.867064)\n",
      "Rank  718: mean feature #3838 (score = 12.855852)\n",
      "Rank  719: mean feature #2397 (score = 12.847170)\n",
      "Rank  720: mean feature #8373 (score = 12.826139)\n",
      "Rank  721: mean feature #4412 (score = 12.818619)\n",
      "Rank  722: mean feature #14362 (score = 12.816148)\n",
      "Rank  723: mean feature #13602 (score = 12.773968)\n",
      "Rank  724: mean feature #13404 (score = 12.759100)\n",
      "Rank  725: mean feature #11888 (score = 12.753903)\n",
      "Rank  726: mean feature #2453 (score = 12.736225)\n",
      "Rank  727: mean feature #1881 (score = 12.730598)\n",
      "Rank  728: mean feature #7454 (score = 12.729942)\n",
      "Rank  729: mean feature #9273 (score = 12.681061)\n",
      "Rank  730: mean feature #6008 (score = 12.673876)\n",
      "Rank  731: mean feature #13182 (score = 12.637012)\n",
      "Rank  732: mean feature #13473 (score = 12.631813)\n",
      "Rank  733: mean feature #940 (score = 12.629418)\n",
      "Rank  734: mean feature #1986 (score = 12.624409)\n",
      "Rank  735: mean feature #1254 (score = 12.585501)\n",
      "Rank  736: mean feature #323 (score = 12.576832)\n",
      "Rank  737: mean feature #724 (score = 12.573156)\n",
      "Rank  738: mean feature #1508 (score = 12.553965)\n",
      "Rank  739: mean feature #11441 (score = 12.537835)\n",
      "Rank  740: mean feature #7685 (score = 12.529514)\n",
      "Rank  741: mean feature #10315 (score = 12.503347)\n",
      "Rank  742: mean feature #53 (score = 12.503105)\n",
      "Rank  743: mean feature #16293 (score = 12.489620)\n",
      "Rank  744: mean feature #15587 (score = 12.484867)\n",
      "Rank  745: mean feature #11778 (score = 12.475974)\n",
      "Rank  746: mean feature #2779 (score = 12.458575)\n",
      "Rank  747: mean feature #6092 (score = 12.457369)\n",
      "Rank  748: mean feature #3461 (score = 12.450077)\n",
      "Rank  749: mean feature #8221 (score = 12.448383)\n",
      "Rank  750: mean feature #11609 (score = 12.442699)\n",
      "Rank  751: mean feature #15718 (score = 12.441607)\n",
      "Rank  752: mean feature #15469 (score = 12.441039)\n",
      "Rank  753: mean feature #1393 (score = 12.433032)\n",
      "Rank  754: mean feature #261 (score = 12.428932)\n",
      "Rank  755: mean feature #11728 (score = 12.412141)\n",
      "Rank  756: mean feature #10805 (score = 12.411500)\n",
      "Rank  757: mean feature #15100 (score = 12.410982)\n",
      "Rank  758: mean feature #11898 (score = 12.408893)\n",
      "Rank  759: mean feature #8436 (score = 12.403710)\n",
      "Rank  760: mean feature #9556 (score = 12.394605)\n",
      "Rank  761: mean feature #2938 (score = 12.389039)\n",
      "Rank  762: mean feature #8161 (score = 12.378613)\n",
      "Rank  763: mean feature #4024 (score = 12.376821)\n",
      "Rank  764: mean feature #1888 (score = 12.373543)\n",
      "Rank  765: mean feature #10961 (score = 12.361122)\n",
      "Rank  766: mean feature #3982 (score = 12.358528)\n",
      "Rank  767: mean feature #11256 (score = 12.347909)\n",
      "Rank  768: mean feature #9167 (score = 12.324883)\n",
      "Rank  769: mean feature #2366 (score = 12.320635)\n",
      "Rank  770: mean feature #14980 (score = 12.311264)\n",
      "Rank  771: mean feature #9863 (score = 12.305679)\n",
      "Rank  772: mean feature #3270 (score = 12.301119)\n",
      "Rank  773: mean feature #13169 (score = 12.292379)\n",
      "Rank  774: mean feature #6259 (score = 12.286196)\n",
      "Rank  775: mean feature #15405 (score = 12.243613)\n",
      "Rank  776: mean feature #2775 (score = 12.238391)\n",
      "Rank  777: mean feature #14079 (score = 12.218744)\n",
      "Rank  778: mean feature #5929 (score = 12.217114)\n",
      "Rank  779: mean feature #12645 (score = 12.210437)\n",
      "Rank  780: mean feature #2357 (score = 12.189628)\n",
      "Rank  781: mean feature #1159 (score = 12.187762)\n",
      "Rank  782: mean feature #6172 (score = 12.166041)\n",
      "Rank  783: mean feature #12133 (score = 12.151991)\n",
      "Rank  784: mean feature #4660 (score = 12.114012)\n",
      "Rank  785: mean feature #12755 (score = 12.086777)\n",
      "Rank  786: mean feature #14379 (score = 12.079720)\n",
      "Rank  787: mean feature #1255 (score = 12.079105)\n",
      "Rank  788: mean feature #3743 (score = 12.077020)\n",
      "Rank  789: mean feature #2270 (score = 12.066823)\n",
      "Rank  790: mean feature #14517 (score = 12.058923)\n",
      "Rank  791: mean feature #2131 (score = 12.055789)\n",
      "Rank  792: mean feature #6261 (score = 12.047488)\n",
      "Rank  793: mean feature #2504 (score = 12.042327)\n",
      "Rank  794: mean feature #198 (score = 12.017911)\n",
      "Rank  795: mean feature #8760 (score = 12.010717)\n",
      "Rank  796: mean feature #13215 (score = 11.983276)\n",
      "Rank  797: mean feature #13398 (score = 11.970090)\n",
      "Rank  798: mean feature #5745 (score = 11.962791)\n",
      "Rank  799: mean feature #14662 (score = 11.957007)\n",
      "Rank  800: mean feature #10485 (score = 11.951817)\n",
      "Rank  801: mean feature #13561 (score = 11.947866)\n",
      "Rank  802: mean feature #3878 (score = 11.945096)\n",
      "Rank  803: mean feature #13609 (score = 11.944677)\n",
      "Rank  804: mean feature #8489 (score = 11.943423)\n",
      "Rank  805: mean feature #7866 (score = 11.936096)\n",
      "Rank  806: mean feature #9091 (score = 11.933476)\n",
      "Rank  807: mean feature #5995 (score = 11.920612)\n",
      "Rank  808: mean feature #2096 (score = 11.903830)\n",
      "Rank  809: mean feature #7997 (score = 11.900842)\n",
      "Rank  810: mean feature #11295 (score = 11.877692)\n",
      "Rank  811: mean feature #8787 (score = 11.876147)\n",
      "Rank  812: mean feature #6993 (score = 11.873204)\n",
      "Rank  813: mean feature #13338 (score = 11.862619)\n",
      "Rank  814: mean feature #8843 (score = 11.860429)\n",
      "Rank  815: mean feature #16149 (score = 11.847588)\n",
      "Rank  816: mean feature #13040 (score = 11.842436)\n",
      "Rank  817: mean feature #6951 (score = 11.838452)\n",
      "Rank  818: mean feature #8083 (score = 11.823014)\n",
      "Rank  819: mean feature #2969 (score = 11.817150)\n",
      "Rank  820: mean feature #1277 (score = 11.800840)\n",
      "Rank  821: mean feature #7556 (score = 11.798548)\n",
      "Rank  822: mean feature #13326 (score = 11.796322)\n",
      "Rank  823: mean feature #12644 (score = 11.790423)\n",
      "Rank  824: mean feature #15597 (score = 11.789057)\n",
      "Rank  825: mean feature #15284 (score = 11.781166)\n",
      "Rank  826: mean feature #1215 (score = 11.765559)\n",
      "Rank  827: mean feature #6908 (score = 11.744512)\n",
      "Rank  828: mean feature #4035 (score = 11.727504)\n",
      "Rank  829: mean feature #14173 (score = 11.718986)\n",
      "Rank  830: mean feature #4672 (score = 11.702186)\n",
      "Rank  831: mean feature #11919 (score = 11.701801)\n",
      "Rank  832: mean feature #4019 (score = 11.691010)\n",
      "Rank  833: mean feature #4604 (score = 11.690550)\n",
      "Rank  834: mean feature #6619 (score = 11.684863)\n",
      "Rank  835: mean feature #14224 (score = 11.682504)\n",
      "Rank  836: mean feature #4856 (score = 11.674276)\n",
      "Rank  837: mean feature #13358 (score = 11.670282)\n",
      "Rank  838: mean feature #5658 (score = 11.667059)\n",
      "Rank  839: mean feature #14257 (score = 11.662185)\n",
      "Rank  840: mean feature #10497 (score = 11.652802)\n",
      "Rank  841: mean feature #15747 (score = 11.639678)\n",
      "Rank  842: mean feature #13606 (score = 11.588409)\n",
      "Rank  843: mean feature #12901 (score = 11.581048)\n",
      "Rank  844: mean feature #1999 (score = 11.579444)\n",
      "Rank  845: mean feature #4318 (score = 11.559440)\n",
      "Rank  846: mean feature #1871 (score = 11.553080)\n",
      "Rank  847: mean feature #3617 (score = 11.532115)\n",
      "Rank  848: mean feature #12519 (score = 11.521142)\n",
      "Rank  849: mean feature #6055 (score = 11.510333)\n",
      "Rank  850: mean feature #15531 (score = 11.505937)\n",
      "Rank  851: mean feature #1581 (score = 11.484759)\n",
      "Rank  852: mean feature #15988 (score = 11.480984)\n",
      "Rank  853: mean feature #8908 (score = 11.475638)\n",
      "Rank  854: mean feature #2572 (score = 11.470859)\n",
      "Rank  855: mean feature #14559 (score = 11.468245)\n",
      "Rank  856: mean feature #5494 (score = 11.466407)\n",
      "Rank  857: mean feature #10609 (score = 11.463550)\n",
      "Rank  858: mean feature #4397 (score = 11.455977)\n",
      "Rank  859: mean feature #14420 (score = 11.439930)\n",
      "Rank  860: mean feature #7536 (score = 11.432895)\n",
      "Rank  861: mean feature #7047 (score = 11.431208)\n",
      "Rank  862: mean feature #3050 (score = 11.414362)\n",
      "Rank  863: mean feature #4264 (score = 11.387032)\n",
      "Rank  864: mean feature #12010 (score = 11.380087)\n",
      "Rank  865: mean feature #7770 (score = 11.379131)\n",
      "Rank  866: mean feature #5303 (score = 11.378105)\n",
      "Rank  867: mean feature #5467 (score = 11.352419)\n",
      "Rank  868: mean feature #4988 (score = 11.350879)\n",
      "Rank  869: mean feature #4485 (score = 11.349718)\n",
      "Rank  870: mean feature #1746 (score = 11.337313)\n",
      "Rank  871: mean feature #3752 (score = 11.336917)\n",
      "Rank  872: mean feature #11339 (score = 11.333403)\n",
      "Rank  873: mean feature #1945 (score = 11.310373)\n",
      "Rank  874: mean feature #12711 (score = 11.292729)\n",
      "Rank  875: mean feature #10117 (score = 11.291032)\n",
      "Rank  876: mean feature #16253 (score = 11.285253)\n",
      "Rank  877: mean feature #4465 (score = 11.283793)\n",
      "Rank  878: mean feature #7260 (score = 11.282789)\n",
      "Rank  879: mean feature #3557 (score = 11.275397)\n",
      "Rank  880: mean feature #8948 (score = 11.267496)\n",
      "Rank  881: mean feature #15136 (score = 11.267274)\n",
      "Rank  882: mean feature #4120 (score = 11.267261)\n",
      "Rank  883: mean feature #10043 (score = 11.253730)\n",
      "Rank  884: mean feature #13970 (score = 11.246233)\n",
      "Rank  885: mean feature #11620 (score = 11.244063)\n",
      "Rank  886: mean feature #3257 (score = 11.242426)\n",
      "Rank  887: mean feature #7961 (score = 11.240036)\n",
      "Rank  888: mean feature #7877 (score = 11.234203)\n",
      "Rank  889: mean feature #2442 (score = 11.229451)\n",
      "Rank  890: mean feature #14269 (score = 11.202546)\n",
      "Rank  891: mean feature #2484 (score = 11.198435)\n",
      "Rank  892: mean feature #4364 (score = 11.190984)\n",
      "Rank  893: mean feature #15154 (score = 11.181156)\n",
      "Rank  894: mean feature #4254 (score = 11.173100)\n",
      "Rank  895: mean feature #9407 (score = 11.169441)\n",
      "Rank  896: mean feature #15726 (score = 11.169316)\n",
      "Rank  897: mean feature #10902 (score = 11.169227)\n",
      "Rank  898: mean feature #6856 (score = 11.168337)\n",
      "Rank  899: mean feature #3766 (score = 11.160572)\n",
      "Rank  900: mean feature #7416 (score = 11.145588)\n",
      "Rank  901: mean feature #12551 (score = 11.140464)\n",
      "Rank  902: mean feature #9910 (score = 11.131079)\n",
      "Rank  903: mean feature #12177 (score = 11.119992)\n",
      "Rank  904: mean feature #15078 (score = 11.107510)\n",
      "Rank  905: mean feature #3142 (score = 11.089725)\n",
      "Rank  906: mean feature #3493 (score = 11.087428)\n",
      "Rank  907: mean feature #1700 (score = 11.079840)\n",
      "Rank  908: mean feature #1578 (score = 11.074243)\n",
      "Rank  909: mean feature #11476 (score = 11.070154)\n",
      "Rank  910: mean feature #8514 (score = 11.057812)\n",
      "Rank  911: mean feature #5940 (score = 11.054996)\n",
      "Rank  912: mean feature #61 (score = 11.036759)\n",
      "Rank  913: mean feature #16327 (score = 11.004080)\n",
      "Rank  914: mean feature #13593 (score = 10.994063)\n",
      "Rank  915: mean feature #10693 (score = 10.991091)\n",
      "Rank  916: mean feature #9715 (score = 10.990762)\n",
      "Rank  917: mean feature #9132 (score = 10.989887)\n",
      "Rank  918: mean feature #11379 (score = 10.976920)\n",
      "Rank  919: mean feature #1406 (score = 10.974663)\n",
      "Rank  920: mean feature #10467 (score = 10.968970)\n",
      "Rank  921: mean feature #2005 (score = 10.968315)\n",
      "Rank  922: mean feature #14780 (score = 10.965463)\n",
      "Rank  923: mean feature #6973 (score = 10.964635)\n",
      "Rank  924: mean feature #1785 (score = 10.956583)\n",
      "Rank  925: mean feature #15358 (score = 10.955537)\n",
      "Rank  926: mean feature #12139 (score = 10.953670)\n",
      "Rank  927: mean feature #7533 (score = 10.946815)\n",
      "Rank  928: mean feature #14437 (score = 10.944732)\n",
      "Rank  929: mean feature #1501 (score = 10.943626)\n",
      "Rank  930: mean feature #4999 (score = 10.919574)\n",
      "Rank  931: mean feature #3533 (score = 10.918516)\n",
      "Rank  932: mean feature #5825 (score = 10.918361)\n",
      "Rank  933: mean feature #5626 (score = 10.914944)\n",
      "Rank  934: mean feature #3582 (score = 10.911367)\n",
      "Rank  935: mean feature #4327 (score = 10.908178)\n",
      "Rank  936: mean feature #8991 (score = 10.907069)\n",
      "Rank  937: mean feature #2136 (score = 10.905945)\n",
      "Rank  938: mean feature #431 (score = 10.896638)\n",
      "Rank  939: mean feature #2325 (score = 10.889892)\n",
      "Rank  940: mean feature #2115 (score = 10.886449)\n",
      "Rank  941: mean feature #14641 (score = 10.870631)\n",
      "Rank  942: mean feature #5240 (score = 10.861016)\n",
      "Rank  943: mean feature #9059 (score = 10.854279)\n",
      "Rank  944: mean feature #8306 (score = 10.830424)\n",
      "Rank  945: mean feature #8002 (score = 10.797304)\n",
      "Rank  946: mean feature #9493 (score = 10.792821)\n",
      "Rank  947: mean feature #11990 (score = 10.782505)\n",
      "Rank  948: mean feature #8901 (score = 10.770393)\n",
      "Rank  949: mean feature #13059 (score = 10.765929)\n",
      "Rank  950: mean feature #12298 (score = 10.751405)\n",
      "Rank  951: mean feature #14948 (score = 10.739842)\n",
      "Rank  952: mean feature #15788 (score = 10.737426)\n",
      "Rank  953: mean feature #6867 (score = 10.736869)\n",
      "Rank  954: mean feature #9112 (score = 10.715173)\n",
      "Rank  955: mean feature #2280 (score = 10.699501)\n",
      "Rank  956: mean feature #8970 (score = 10.697730)\n",
      "Rank  957: mean feature #10164 (score = 10.681625)\n",
      "Rank  958: mean feature #5595 (score = 10.681350)\n",
      "Rank  959: mean feature #4187 (score = 10.663085)\n",
      "Rank  960: mean feature #13955 (score = 10.657127)\n",
      "Rank  961: mean feature #13871 (score = 10.653304)\n",
      "Rank  962: mean feature #3512 (score = 10.649340)\n",
      "Rank  963: mean feature #6763 (score = 10.639698)\n",
      "Rank  964: mean feature #15712 (score = 10.635877)\n",
      "Rank  965: mean feature #283 (score = 10.635521)\n",
      "Rank  966: mean feature #325 (score = 10.635519)\n",
      "Rank  967: mean feature #5258 (score = 10.632032)\n",
      "Rank  968: mean feature #8121 (score = 10.631746)\n",
      "Rank  969: mean feature #5013 (score = 10.630594)\n",
      "Rank  970: mean feature #4104 (score = 10.625529)\n",
      "Rank  971: mean feature #11617 (score = 10.618848)\n",
      "Rank  972: mean feature #15602 (score = 10.600223)\n",
      "Rank  973: mean feature #2826 (score = 10.599658)\n",
      "Rank  974: mean feature #4394 (score = 10.592775)\n",
      "Rank  975: mean feature #12132 (score = 10.587843)\n",
      "Rank  976: mean feature #4105 (score = 10.582694)\n",
      "Rank  977: mean feature #10390 (score = 10.580517)\n",
      "Rank  978: mean feature #8731 (score = 10.571850)\n",
      "Rank  979: mean feature #11641 (score = 10.562289)\n",
      "Rank  980: mean feature #10504 (score = 10.551483)\n",
      "Rank  981: mean feature #14552 (score = 10.548906)\n",
      "Rank  982: mean feature #2454 (score = 10.531362)\n",
      "Rank  983: mean feature #505 (score = 10.529020)\n",
      "Rank  984: mean feature #16046 (score = 10.521622)\n",
      "Rank  985: mean feature #13112 (score = 10.521378)\n",
      "Rank  986: mean feature #14663 (score = 10.520219)\n",
      "Rank  987: mean feature #11930 (score = 10.516721)\n",
      "Rank  988: mean feature #11254 (score = 10.514750)\n",
      "Rank  989: mean feature #491 (score = 10.513033)\n",
      "Rank  990: mean feature #9062 (score = 10.509175)\n",
      "Rank  991: mean feature #12746 (score = 10.494274)\n",
      "Rank  992: mean feature #15185 (score = 10.489778)\n",
      "Rank  993: mean feature #14752 (score = 10.479122)\n",
      "Rank  994: mean feature #6568 (score = 10.468306)\n",
      "Rank  995: mean feature #12740 (score = 10.460783)\n",
      "Rank  996: mean feature #10526 (score = 10.456848)\n",
      "Rank  997: mean feature #13567 (score = 10.443452)\n",
      "Rank  998: mean feature #14326 (score = 10.436014)\n",
      "Rank  999: mean feature #10089 (score = 10.434375)\n",
      "Rank 1000: mean feature #14986 (score = 10.432707)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/airlay88/surprise_sae/venv/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 2827  5798 12175] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/airlay88/surprise_sae/venv/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(Xc)\n",
    "\n",
    "skb = SelectKBest(score_func=f_classif, k=1000)\n",
    "skb.fit(Xc, y)\n",
    "f_scores = skb.scores_\n",
    "ranked_idx = rank_and_print(f_scores, D, \"F-test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c2ba20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mutual Information top 1000 features ===\n",
      "Rank    1: max feature #7768 (score = 0.000000)\n",
      "Rank    2: mean feature #3012 (score = 0.002506)\n",
      "Rank    3: max feature #780 (score = 0.000000)\n",
      "Rank    4: max feature #827 (score = 0.000000)\n",
      "Rank    5: mean feature #7082 (score = 0.000000)\n",
      "Rank    6: mean feature #4796 (score = 0.000647)\n",
      "Rank    7: mean feature #1241 (score = 0.002696)\n",
      "Rank    8: mean feature #6604 (score = 0.000000)\n",
      "Rank    9: mean feature #6038 (score = 0.011501)\n",
      "Rank   10: max feature #1904 (score = 0.000000)\n",
      "Rank   11: max feature #7221 (score = 0.000000)\n",
      "Rank   12: mean feature #2991 (score = 0.000000)\n",
      "Rank   13: max feature #1454 (score = 0.000000)\n",
      "Rank   14: mean feature #300 (score = 0.004962)\n",
      "Rank   15: max feature #4406 (score = 0.000000)\n",
      "Rank   16: mean feature #2017 (score = 0.007202)\n",
      "Rank   17: mean feature #2371 (score = 0.000000)\n",
      "Rank   18: mean feature #373 (score = 0.003534)\n",
      "Rank   19: mean feature #6182 (score = 0.001276)\n",
      "Rank   20: max feature #4204 (score = 0.000290)\n",
      "Rank   21: mean feature #461 (score = 0.000000)\n",
      "Rank   22: max feature #2876 (score = 0.000000)\n",
      "Rank   23: max feature #5047 (score = 0.000000)\n",
      "Rank   24: max feature #1944 (score = 0.000000)\n",
      "Rank   25: mean feature #2491 (score = 0.000000)\n",
      "Rank   26: max feature #367 (score = 0.000000)\n",
      "Rank   27: max feature #650 (score = 0.000000)\n",
      "Rank   28: mean feature #4018 (score = 0.000000)\n",
      "Rank   29: mean feature #978 (score = 0.000719)\n",
      "Rank   30: max feature #4447 (score = 0.000000)\n",
      "Rank   31: max feature #6369 (score = 0.000000)\n",
      "Rank   32: max feature #134 (score = 0.001416)\n",
      "Rank   33: mean feature #2791 (score = 0.000000)\n",
      "Rank   34: mean feature #838 (score = 0.000000)\n",
      "Rank   35: max feature #1072 (score = 0.001283)\n",
      "Rank   36: max feature #990 (score = 0.000000)\n",
      "Rank   37: max feature #3475 (score = 0.006355)\n",
      "Rank   38: mean feature #6697 (score = 0.000000)\n",
      "Rank   39: mean feature #546 (score = 0.000557)\n",
      "Rank   40: mean feature #2383 (score = 0.001456)\n",
      "Rank   41: max feature #1142 (score = 0.000000)\n",
      "Rank   42: mean feature #4600 (score = 0.009595)\n",
      "Rank   43: max feature #814 (score = 0.013189)\n",
      "Rank   44: max feature #2552 (score = 0.013004)\n",
      "Rank   45: max feature #6893 (score = 0.012271)\n",
      "Rank   46: max feature #3610 (score = 0.000000)\n",
      "Rank   47: max feature #4313 (score = 0.008257)\n",
      "Rank   48: mean feature #5572 (score = 0.001488)\n",
      "Rank   49: max feature #4488 (score = 0.002187)\n",
      "Rank   50: max feature #1818 (score = 0.011711)\n",
      "Rank   51: max feature #4866 (score = 0.002038)\n",
      "Rank   52: mean feature #778 (score = 0.006220)\n",
      "Rank   53: max feature #1948 (score = 0.002103)\n",
      "Rank   54: mean feature #5282 (score = 0.002434)\n",
      "Rank   55: max feature #4450 (score = 0.002121)\n",
      "Rank   56: mean feature #1541 (score = 0.000000)\n",
      "Rank   57: mean feature #451 (score = 0.006371)\n",
      "Rank   58: mean feature #1168 (score = 0.000000)\n",
      "Rank   59: mean feature #3739 (score = 0.006187)\n",
      "Rank   60: max feature #4107 (score = 0.007660)\n",
      "Rank   61: max feature #6012 (score = 0.000000)\n",
      "Rank   62: max feature #7850 (score = 0.000000)\n",
      "Rank   63: max feature #7429 (score = 0.001059)\n",
      "Rank   64: mean feature #7641 (score = 0.004769)\n",
      "Rank   65: max feature #2563 (score = 0.004806)\n",
      "Rank   66: max feature #6153 (score = 0.009439)\n",
      "Rank   67: max feature #3333 (score = 0.000000)\n",
      "Rank   68: max feature #7081 (score = 0.002793)\n",
      "Rank   69: max feature #1310 (score = 0.000000)\n",
      "Rank   70: max feature #2368 (score = 0.002946)\n",
      "Rank   71: mean feature #670 (score = 0.000000)\n",
      "Rank   72: mean feature #7880 (score = 0.007362)\n",
      "Rank   73: mean feature #720 (score = 0.009446)\n",
      "Rank   74: mean feature #3661 (score = 0.000000)\n",
      "Rank   75: mean feature #5866 (score = 0.000106)\n",
      "Rank   76: mean feature #7857 (score = 0.000000)\n",
      "Rank   77: mean feature #4205 (score = 0.000000)\n",
      "Rank   78: max feature #6735 (score = 0.000642)\n",
      "Rank   79: mean feature #3609 (score = 0.014080)\n",
      "Rank   80: max feature #2084 (score = 0.000000)\n",
      "Rank   81: max feature #6178 (score = 0.010961)\n",
      "Rank   82: mean feature #2332 (score = 0.009769)\n",
      "Rank   83: mean feature #8068 (score = 0.000232)\n",
      "Rank   84: max feature #3504 (score = 0.000000)\n",
      "Rank   85: mean feature #4408 (score = 0.005137)\n",
      "Rank   86: max feature #5918 (score = 0.000000)\n",
      "Rank   87: max feature #4673 (score = 0.006144)\n",
      "Rank   88: mean feature #5103 (score = 0.000000)\n",
      "Rank   89: mean feature #6703 (score = 0.007196)\n",
      "Rank   90: max feature #6683 (score = 0.002525)\n",
      "Rank   91: mean feature #6094 (score = 0.000906)\n",
      "Rank   92: max feature #351 (score = 0.010529)\n",
      "Rank   93: max feature #3407 (score = 0.000000)\n",
      "Rank   94: mean feature #523 (score = 0.006871)\n",
      "Rank   95: mean feature #7357 (score = 0.005139)\n",
      "Rank   96: max feature #5049 (score = 0.012038)\n",
      "Rank   97: mean feature #5317 (score = 0.007264)\n",
      "Rank   98: mean feature #1712 (score = 0.001275)\n",
      "Rank   99: mean feature #635 (score = 0.006579)\n",
      "Rank  100: max feature #6157 (score = 0.009707)\n",
      "Rank  101: mean feature #1522 (score = 0.000000)\n",
      "Rank  102: max feature #5363 (score = 0.005287)\n",
      "Rank  103: max feature #903 (score = 0.016183)\n",
      "Rank  104: mean feature #7456 (score = 0.013967)\n",
      "Rank  105: max feature #2692 (score = 0.003072)\n",
      "Rank  106: max feature #5690 (score = 0.010357)\n",
      "Rank  107: mean feature #255 (score = 0.010174)\n",
      "Rank  108: max feature #511 (score = 0.009385)\n",
      "Rank  109: max feature #1558 (score = 0.000000)\n",
      "Rank  110: mean feature #3494 (score = 0.005924)\n",
      "Rank  111: max feature #4455 (score = 0.000000)\n",
      "Rank  112: max feature #7570 (score = 0.000108)\n",
      "Rank  113: mean feature #295 (score = 0.000000)\n",
      "Rank  114: max feature #6707 (score = 0.005711)\n",
      "Rank  115: max feature #7999 (score = 0.008037)\n",
      "Rank  116: mean feature #4983 (score = 0.004438)\n",
      "Rank  117: mean feature #3471 (score = 0.008151)\n",
      "Rank  118: max feature #1053 (score = 0.005233)\n",
      "Rank  119: max feature #1271 (score = 0.003212)\n",
      "Rank  120: mean feature #7589 (score = 0.002514)\n",
      "Rank  121: mean feature #6631 (score = 0.000000)\n",
      "Rank  122: max feature #6700 (score = 0.007732)\n",
      "Rank  123: mean feature #7022 (score = 0.000000)\n",
      "Rank  124: mean feature #3162 (score = 0.000591)\n",
      "Rank  125: max feature #141 (score = 0.015203)\n",
      "Rank  126: mean feature #1719 (score = 0.000201)\n",
      "Rank  127: max feature #221 (score = 0.000000)\n",
      "Rank  128: mean feature #3524 (score = 0.000000)\n",
      "Rank  129: max feature #2577 (score = 0.005668)\n",
      "Rank  130: max feature #2220 (score = 0.004648)\n",
      "Rank  131: max feature #1700 (score = 0.000000)\n",
      "Rank  132: mean feature #2415 (score = 0.010722)\n",
      "Rank  133: max feature #440 (score = 0.000000)\n",
      "Rank  134: max feature #6430 (score = 0.003977)\n",
      "Rank  135: mean feature #2462 (score = 0.001681)\n",
      "Rank  136: max feature #7489 (score = 0.000000)\n",
      "Rank  137: max feature #1496 (score = 0.000000)\n",
      "Rank  138: mean feature #1202 (score = 0.000000)\n",
      "Rank  139: max feature #3445 (score = 0.000000)\n",
      "Rank  140: mean feature #6770 (score = 0.000000)\n",
      "Rank  141: max feature #3205 (score = 0.004566)\n",
      "Rank  142: mean feature #2845 (score = 0.006489)\n",
      "Rank  143: max feature #957 (score = 0.003842)\n",
      "Rank  144: mean feature #4989 (score = 0.000202)\n",
      "Rank  145: max feature #188 (score = 0.018161)\n",
      "Rank  146: mean feature #1704 (score = 0.005198)\n",
      "Rank  147: mean feature #5523 (score = 0.000000)\n",
      "Rank  148: mean feature #1390 (score = 0.000000)\n",
      "Rank  149: max feature #7206 (score = 0.002878)\n",
      "Rank  150: mean feature #5078 (score = 0.009770)\n",
      "Rank  151: max feature #4356 (score = 0.000000)\n",
      "Rank  152: max feature #540 (score = 0.006260)\n",
      "Rank  153: max feature #2074 (score = 0.014984)\n",
      "Rank  154: mean feature #2059 (score = 0.000000)\n",
      "Rank  155: max feature #4808 (score = 0.003685)\n",
      "Rank  156: mean feature #3878 (score = 0.013894)\n",
      "Rank  157: max feature #6038 (score = 0.000616)\n",
      "Rank  158: max feature #1810 (score = 0.005332)\n",
      "Rank  159: max feature #6553 (score = 0.000000)\n",
      "Rank  160: max feature #7703 (score = 0.002795)\n",
      "Rank  161: mean feature #6628 (score = 0.000000)\n",
      "Rank  162: max feature #4013 (score = 0.005718)\n",
      "Rank  163: mean feature #7889 (score = 0.001503)\n",
      "Rank  164: max feature #2323 (score = 0.000000)\n",
      "Rank  165: mean feature #939 (score = 0.000000)\n",
      "Rank  166: max feature #4308 (score = 0.004315)\n",
      "Rank  167: max feature #2268 (score = 0.011271)\n",
      "Rank  168: mean feature #6159 (score = 0.000000)\n",
      "Rank  169: mean feature #1036 (score = 0.000000)\n",
      "Rank  170: mean feature #1205 (score = 0.006741)\n",
      "Rank  171: max feature #1301 (score = 0.006082)\n",
      "Rank  172: max feature #3132 (score = 0.003255)\n",
      "Rank  173: mean feature #8129 (score = 0.000000)\n",
      "Rank  174: mean feature #3278 (score = 0.008944)\n",
      "Rank  175: max feature #4384 (score = 0.000000)\n",
      "Rank  176: max feature #5848 (score = 0.003300)\n",
      "Rank  177: max feature #4471 (score = 0.009281)\n",
      "Rank  178: max feature #2162 (score = 0.002960)\n",
      "Rank  179: max feature #7047 (score = 0.011736)\n",
      "Rank  180: mean feature #2488 (score = 0.012460)\n",
      "Rank  181: max feature #2528 (score = 0.000000)\n",
      "Rank  182: mean feature #1547 (score = 0.000000)\n",
      "Rank  183: mean feature #5409 (score = 0.006785)\n",
      "Rank  184: mean feature #5776 (score = 0.001670)\n",
      "Rank  185: mean feature #5817 (score = 0.000392)\n",
      "Rank  186: max feature #4746 (score = 0.008620)\n",
      "Rank  187: max feature #2635 (score = 0.003618)\n",
      "Rank  188: mean feature #2505 (score = 0.005855)\n",
      "Rank  189: max feature #4819 (score = 0.000000)\n",
      "Rank  190: mean feature #5013 (score = 0.000000)\n",
      "Rank  191: mean feature #1381 (score = 0.016773)\n",
      "Rank  192: mean feature #5520 (score = 0.000000)\n",
      "Rank  193: mean feature #237 (score = 0.002217)\n",
      "Rank  194: mean feature #1405 (score = 0.012186)\n",
      "Rank  195: max feature #4472 (score = 0.004608)\n",
      "Rank  196: mean feature #6802 (score = 0.004328)\n",
      "Rank  197: max feature #2790 (score = 0.000000)\n",
      "Rank  198: max feature #2902 (score = 0.000000)\n",
      "Rank  199: max feature #2426 (score = 0.010609)\n",
      "Rank  200: max feature #6237 (score = 0.009220)\n",
      "Rank  201: mean feature #110 (score = 0.000000)\n",
      "Rank  202: mean feature #7736 (score = 0.000000)\n",
      "Rank  203: mean feature #6902 (score = 0.012136)\n",
      "Rank  204: mean feature #4177 (score = 0.002463)\n",
      "Rank  205: max feature #1825 (score = 0.010053)\n",
      "Rank  206: max feature #2464 (score = 0.001626)\n",
      "Rank  207: mean feature #1099 (score = 0.013801)\n",
      "Rank  208: max feature #294 (score = 0.000000)\n",
      "Rank  209: mean feature #1174 (score = 0.000000)\n",
      "Rank  210: max feature #7546 (score = 0.000000)\n",
      "Rank  211: max feature #7604 (score = 0.005962)\n",
      "Rank  212: max feature #5244 (score = 0.000000)\n",
      "Rank  213: max feature #4292 (score = 0.000000)\n",
      "Rank  214: max feature #7665 (score = 0.009456)\n",
      "Rank  215: mean feature #631 (score = 0.000000)\n",
      "Rank  216: max feature #2527 (score = 0.008158)\n",
      "Rank  217: max feature #3866 (score = 0.002563)\n",
      "Rank  218: mean feature #940 (score = 0.003610)\n",
      "Rank  219: mean feature #7572 (score = 0.000000)\n",
      "Rank  220: mean feature #1446 (score = 0.005822)\n",
      "Rank  221: mean feature #5273 (score = 0.002583)\n",
      "Rank  222: mean feature #4113 (score = 0.004674)\n",
      "Rank  223: mean feature #1604 (score = 0.001026)\n",
      "Rank  224: mean feature #3990 (score = 0.000000)\n",
      "Rank  225: max feature #4707 (score = 0.004449)\n",
      "Rank  226: mean feature #7654 (score = 0.000000)\n",
      "Rank  227: max feature #33 (score = 0.001368)\n",
      "Rank  228: mean feature #5489 (score = 0.006769)\n",
      "Rank  229: max feature #5692 (score = 0.000000)\n",
      "Rank  230: mean feature #5375 (score = 0.008255)\n",
      "Rank  231: mean feature #2325 (score = 0.000000)\n",
      "Rank  232: max feature #475 (score = 0.000000)\n",
      "Rank  233: max feature #3188 (score = 0.002402)\n",
      "Rank  234: max feature #5353 (score = 0.002961)\n",
      "Rank  235: max feature #6403 (score = 0.009158)\n",
      "Rank  236: max feature #3829 (score = 0.000071)\n",
      "Rank  237: mean feature #682 (score = 0.005677)\n",
      "Rank  238: mean feature #6639 (score = 0.000000)\n",
      "Rank  239: max feature #920 (score = 0.004624)\n",
      "Rank  240: mean feature #4502 (score = 0.013851)\n",
      "Rank  241: max feature #2939 (score = 0.007400)\n",
      "Rank  242: mean feature #1881 (score = 0.000000)\n",
      "Rank  243: max feature #1245 (score = 0.011527)\n",
      "Rank  244: mean feature #6006 (score = 0.006166)\n",
      "Rank  245: mean feature #4838 (score = 0.003083)\n",
      "Rank  246: max feature #5970 (score = 0.000000)\n",
      "Rank  247: mean feature #6122 (score = 0.002319)\n",
      "Rank  248: mean feature #3820 (score = 0.000000)\n",
      "Rank  249: mean feature #7294 (score = 0.001785)\n",
      "Rank  250: max feature #3360 (score = 0.005070)\n",
      "Rank  251: max feature #6458 (score = 0.000000)\n",
      "Rank  252: max feature #5023 (score = 0.003002)\n",
      "Rank  253: max feature #3067 (score = 0.003573)\n",
      "Rank  254: mean feature #5240 (score = 0.000000)\n",
      "Rank  255: mean feature #7797 (score = 0.000000)\n",
      "Rank  256: max feature #3941 (score = 0.000000)\n",
      "Rank  257: mean feature #1519 (score = 0.000000)\n",
      "Rank  258: mean feature #5006 (score = 0.000000)\n",
      "Rank  259: mean feature #5918 (score = 0.000000)\n",
      "Rank  260: mean feature #3590 (score = 0.001122)\n",
      "Rank  261: max feature #3161 (score = 0.008695)\n",
      "Rank  262: mean feature #4558 (score = 0.005578)\n",
      "Rank  263: mean feature #4236 (score = 0.008578)\n",
      "Rank  264: max feature #5357 (score = 0.000320)\n",
      "Rank  265: max feature #1921 (score = 0.003924)\n",
      "Rank  266: max feature #2867 (score = 0.000000)\n",
      "Rank  267: mean feature #7735 (score = 0.000783)\n",
      "Rank  268: mean feature #207 (score = 0.000000)\n",
      "Rank  269: max feature #2445 (score = 0.001737)\n",
      "Rank  270: max feature #6727 (score = 0.000000)\n",
      "Rank  271: max feature #6085 (score = 0.001433)\n",
      "Rank  272: mean feature #7560 (score = 0.000000)\n",
      "Rank  273: max feature #4525 (score = 0.000000)\n",
      "Rank  274: mean feature #5612 (score = 0.008880)\n",
      "Rank  275: mean feature #7067 (score = 0.000000)\n",
      "Rank  276: mean feature #7278 (score = 0.004267)\n",
      "Rank  277: max feature #6007 (score = 0.000000)\n",
      "Rank  278: mean feature #1462 (score = 0.007267)\n",
      "Rank  279: max feature #7924 (score = 0.000000)\n",
      "Rank  280: mean feature #2021 (score = 0.005327)\n",
      "Rank  281: max feature #3441 (score = 0.005139)\n",
      "Rank  282: max feature #2198 (score = 0.002890)\n",
      "Rank  283: max feature #6652 (score = 0.000000)\n",
      "Rank  284: mean feature #4373 (score = 0.006029)\n",
      "Rank  285: max feature #1956 (score = 0.000564)\n",
      "Rank  286: max feature #76 (score = 0.000000)\n",
      "Rank  287: mean feature #3358 (score = 0.000000)\n",
      "Rank  288: max feature #1738 (score = 0.011375)\n",
      "Rank  289: mean feature #6960 (score = 0.000727)\n",
      "Rank  290: max feature #7062 (score = 0.007495)\n",
      "Rank  291: max feature #1013 (score = 0.003734)\n",
      "Rank  292: max feature #3043 (score = 0.003715)\n",
      "Rank  293: max feature #5955 (score = 0.005752)\n",
      "Rank  294: mean feature #6694 (score = 0.004966)\n",
      "Rank  295: mean feature #3947 (score = 0.000000)\n",
      "Rank  296: mean feature #4609 (score = 0.000000)\n",
      "Rank  297: max feature #3821 (score = 0.000839)\n",
      "Rank  298: max feature #7829 (score = 0.001394)\n",
      "Rank  299: max feature #2911 (score = 0.000000)\n",
      "Rank  300: max feature #522 (score = 0.000000)\n",
      "Rank  301: max feature #4206 (score = 0.011131)\n",
      "Rank  302: max feature #1782 (score = 0.005514)\n",
      "Rank  303: max feature #6590 (score = 0.000000)\n",
      "Rank  304: max feature #926 (score = 0.005784)\n",
      "Rank  305: max feature #6973 (score = 0.000000)\n",
      "Rank  306: max feature #4122 (score = 0.000000)\n",
      "Rank  307: max feature #2763 (score = 0.002986)\n",
      "Rank  308: max feature #1756 (score = 0.000000)\n",
      "Rank  309: max feature #3581 (score = 0.000000)\n",
      "Rank  310: max feature #7243 (score = 0.003753)\n",
      "Rank  311: max feature #7440 (score = 0.003262)\n",
      "Rank  312: max feature #4323 (score = 0.000243)\n",
      "Rank  313: mean feature #7459 (score = 0.004756)\n",
      "Rank  314: max feature #2131 (score = 0.000589)\n",
      "Rank  315: mean feature #3585 (score = 0.004775)\n",
      "Rank  316: max feature #936 (score = 0.007484)\n",
      "Rank  317: mean feature #6448 (score = 0.020460)\n",
      "Rank  318: mean feature #1156 (score = 0.009288)\n",
      "Rank  319: max feature #108 (score = 0.007272)\n",
      "Rank  320: mean feature #6173 (score = 0.000000)\n",
      "Rank  321: mean feature #7863 (score = 0.006725)\n",
      "Rank  322: max feature #5535 (score = 0.004453)\n",
      "Rank  323: max feature #1686 (score = 0.000000)\n",
      "Rank  324: mean feature #4206 (score = 0.007493)\n",
      "Rank  325: max feature #6719 (score = 0.000000)\n",
      "Rank  326: mean feature #5266 (score = 0.000000)\n",
      "Rank  327: mean feature #3604 (score = 0.000000)\n",
      "Rank  328: max feature #6977 (score = 0.007541)\n",
      "Rank  329: mean feature #2688 (score = 0.001578)\n",
      "Rank  330: mean feature #6254 (score = 0.006765)\n",
      "Rank  331: max feature #2596 (score = 0.014415)\n",
      "Rank  332: mean feature #257 (score = 0.014237)\n",
      "Rank  333: max feature #3269 (score = 0.014182)\n",
      "Rank  334: mean feature #6748 (score = 0.009096)\n",
      "Rank  335: mean feature #4126 (score = 0.000000)\n",
      "Rank  336: mean feature #3766 (score = 0.000000)\n",
      "Rank  337: mean feature #4013 (score = 0.005066)\n",
      "Rank  338: max feature #7624 (score = 0.000000)\n",
      "Rank  339: max feature #2369 (score = 0.004873)\n",
      "Rank  340: max feature #2213 (score = 0.000000)\n",
      "Rank  341: mean feature #2133 (score = 0.001041)\n",
      "Rank  342: max feature #417 (score = 0.003451)\n",
      "Rank  343: max feature #6250 (score = 0.000000)\n",
      "Rank  344: mean feature #133 (score = 0.002094)\n",
      "Rank  345: max feature #5888 (score = 0.006482)\n",
      "Rank  346: max feature #5884 (score = 0.005346)\n",
      "Rank  347: max feature #6953 (score = 0.002324)\n",
      "Rank  348: max feature #4555 (score = 0.000000)\n",
      "Rank  349: mean feature #4155 (score = 0.000000)\n",
      "Rank  350: mean feature #7046 (score = 0.000000)\n",
      "Rank  351: mean feature #4151 (score = 0.007816)\n",
      "Rank  352: mean feature #3958 (score = 0.009838)\n",
      "Rank  353: mean feature #8097 (score = 0.000000)\n",
      "Rank  354: mean feature #1074 (score = 0.000000)\n",
      "Rank  355: max feature #3081 (score = 0.000000)\n",
      "Rank  356: mean feature #3542 (score = 0.002749)\n",
      "Rank  357: mean feature #4605 (score = 0.000000)\n",
      "Rank  358: max feature #4128 (score = 0.000629)\n",
      "Rank  359: max feature #5425 (score = 0.000000)\n",
      "Rank  360: mean feature #5959 (score = 0.000214)\n",
      "Rank  361: max feature #5685 (score = 0.000000)\n",
      "Rank  362: mean feature #7316 (score = 0.019729)\n",
      "Rank  363: mean feature #5445 (score = 0.005635)\n",
      "Rank  364: max feature #971 (score = 0.001092)\n",
      "Rank  365: mean feature #6470 (score = 0.006043)\n",
      "Rank  366: max feature #4717 (score = 0.000000)\n",
      "Rank  367: mean feature #931 (score = 0.000891)\n",
      "Rank  368: max feature #37 (score = 0.002418)\n",
      "Rank  369: max feature #6550 (score = 0.001697)\n",
      "Rank  370: mean feature #7577 (score = 0.002771)\n",
      "Rank  371: mean feature #4564 (score = 0.001628)\n",
      "Rank  372: max feature #3515 (score = 0.013298)\n",
      "Rank  373: max feature #4750 (score = 0.000000)\n",
      "Rank  374: max feature #5142 (score = 0.000000)\n",
      "Rank  375: mean feature #951 (score = 0.000000)\n",
      "Rank  376: max feature #6416 (score = 0.005831)\n",
      "Rank  377: max feature #5454 (score = 0.010717)\n",
      "Rank  378: max feature #2503 (score = 0.000000)\n",
      "Rank  379: max feature #4792 (score = 0.004628)\n",
      "Rank  380: mean feature #86 (score = 0.002375)\n",
      "Rank  381: max feature #7198 (score = 0.006866)\n",
      "Rank  382: mean feature #7007 (score = 0.000000)\n",
      "Rank  383: mean feature #1733 (score = 0.000281)\n",
      "Rank  384: mean feature #1443 (score = 0.000000)\n",
      "Rank  385: mean feature #1279 (score = 0.005816)\n",
      "Rank  386: mean feature #6570 (score = 0.010789)\n",
      "Rank  387: max feature #2227 (score = 0.001541)\n",
      "Rank  388: max feature #6471 (score = 0.002447)\n",
      "Rank  389: mean feature #818 (score = 0.006868)\n",
      "Rank  390: mean feature #1525 (score = 0.001892)\n",
      "Rank  391: max feature #698 (score = 0.000988)\n",
      "Rank  392: mean feature #7386 (score = 0.000000)\n",
      "Rank  393: max feature #2458 (score = 0.000000)\n",
      "Rank  394: max feature #7261 (score = 0.001826)\n",
      "Rank  395: max feature #7925 (score = 0.000000)\n",
      "Rank  396: max feature #3208 (score = 0.007553)\n",
      "Rank  397: max feature #2548 (score = 0.011314)\n",
      "Rank  398: mean feature #3993 (score = 0.000000)\n",
      "Rank  399: mean feature #6139 (score = 0.000000)\n",
      "Rank  400: mean feature #1143 (score = 0.005703)\n",
      "Rank  401: max feature #8086 (score = 0.006411)\n",
      "Rank  402: max feature #6335 (score = 0.009260)\n",
      "Rank  403: max feature #224 (score = 0.001636)\n",
      "Rank  404: mean feature #4192 (score = 0.009725)\n",
      "Rank  405: mean feature #7538 (score = 0.000000)\n",
      "Rank  406: max feature #1733 (score = 0.009709)\n",
      "Rank  407: max feature #4327 (score = 0.000196)\n",
      "Rank  408: mean feature #5343 (score = 0.008978)\n",
      "Rank  409: max feature #7897 (score = 0.008102)\n",
      "Rank  410: mean feature #6144 (score = 0.005084)\n",
      "Rank  411: mean feature #2837 (score = 0.000000)\n",
      "Rank  412: mean feature #884 (score = 0.000000)\n",
      "Rank  413: mean feature #4283 (score = 0.000000)\n",
      "Rank  414: mean feature #2366 (score = 0.005547)\n",
      "Rank  415: mean feature #1224 (score = 0.016988)\n",
      "Rank  416: max feature #544 (score = 0.003942)\n",
      "Rank  417: mean feature #7264 (score = 0.000000)\n",
      "Rank  418: max feature #7987 (score = 0.000000)\n",
      "Rank  419: max feature #4242 (score = 0.005921)\n",
      "Rank  420: mean feature #7899 (score = 0.013499)\n",
      "Rank  421: max feature #5734 (score = 0.012784)\n",
      "Rank  422: mean feature #7638 (score = 0.007102)\n",
      "Rank  423: max feature #83 (score = 0.007680)\n",
      "Rank  424: max feature #1858 (score = 0.000000)\n",
      "Rank  425: mean feature #493 (score = 0.007923)\n",
      "Rank  426: max feature #6301 (score = 0.004097)\n",
      "Rank  427: mean feature #8027 (score = 0.003822)\n",
      "Rank  428: mean feature #6325 (score = 0.000000)\n",
      "Rank  429: max feature #5417 (score = 0.000000)\n",
      "Rank  430: max feature #6984 (score = 0.000000)\n",
      "Rank  431: mean feature #7282 (score = 0.006588)\n",
      "Rank  432: max feature #7320 (score = 0.005364)\n",
      "Rank  433: max feature #1621 (score = 0.000000)\n",
      "Rank  434: mean feature #1254 (score = 0.001525)\n",
      "Rank  435: max feature #6993 (score = 0.001675)\n",
      "Rank  436: max feature #7819 (score = 0.002429)\n",
      "Rank  437: mean feature #4660 (score = 0.000000)\n",
      "Rank  438: max feature #5784 (score = 0.000000)\n",
      "Rank  439: mean feature #4314 (score = 0.003988)\n",
      "Rank  440: mean feature #7804 (score = 0.008814)\n",
      "Rank  441: mean feature #1051 (score = 0.000000)\n",
      "Rank  442: max feature #3787 (score = 0.005608)\n",
      "Rank  443: mean feature #505 (score = 0.005491)\n",
      "Rank  444: max feature #5861 (score = 0.003763)\n",
      "Rank  445: max feature #1980 (score = 0.008061)\n",
      "Rank  446: max feature #5799 (score = 0.008841)\n",
      "Rank  447: mean feature #8040 (score = 0.001978)\n",
      "Rank  448: mean feature #216 (score = 0.004558)\n",
      "Rank  449: mean feature #2149 (score = 0.000000)\n",
      "Rank  450: max feature #6716 (score = 0.003591)\n",
      "Rank  451: max feature #4445 (score = 0.000980)\n",
      "Rank  452: max feature #4298 (score = 0.001177)\n",
      "Rank  453: mean feature #6618 (score = 0.000000)\n",
      "Rank  454: mean feature #6281 (score = 0.005789)\n",
      "Rank  455: max feature #2933 (score = 0.002343)\n",
      "Rank  456: mean feature #6486 (score = 0.001251)\n",
      "Rank  457: mean feature #2077 (score = 0.000802)\n",
      "Rank  458: mean feature #6290 (score = 0.000000)\n",
      "Rank  459: max feature #6061 (score = 0.001262)\n",
      "Rank  460: mean feature #6695 (score = 0.000447)\n",
      "Rank  461: mean feature #5041 (score = 0.000000)\n",
      "Rank  462: max feature #5281 (score = 0.007194)\n",
      "Rank  463: max feature #3026 (score = 0.006086)\n",
      "Rank  464: mean feature #284 (score = 0.000487)\n",
      "Rank  465: max feature #4036 (score = 0.006577)\n",
      "Rank  466: max feature #3058 (score = 0.000000)\n",
      "Rank  467: mean feature #7716 (score = 0.004483)\n",
      "Rank  468: max feature #2347 (score = 0.000000)\n",
      "Rank  469: mean feature #7516 (score = 0.008578)\n",
      "Rank  470: max feature #1398 (score = 0.007077)\n",
      "Rank  471: mean feature #482 (score = 0.003606)\n",
      "Rank  472: mean feature #1899 (score = 0.000000)\n",
      "Rank  473: max feature #1559 (score = 0.000000)\n",
      "Rank  474: max feature #1501 (score = 0.000000)\n",
      "Rank  475: mean feature #2886 (score = 0.002941)\n",
      "Rank  476: mean feature #3534 (score = 0.008557)\n",
      "Rank  477: mean feature #5354 (score = 0.000000)\n",
      "Rank  478: max feature #118 (score = 0.002341)\n",
      "Rank  479: mean feature #1334 (score = 0.000000)\n",
      "Rank  480: mean feature #5427 (score = 0.000000)\n",
      "Rank  481: mean feature #5097 (score = 0.000000)\n",
      "Rank  482: max feature #4017 (score = 0.006084)\n",
      "Rank  483: mean feature #4317 (score = 0.008850)\n",
      "Rank  484: mean feature #3613 (score = 0.001140)\n",
      "Rank  485: max feature #4490 (score = 0.000465)\n",
      "Rank  486: mean feature #4007 (score = 0.013885)\n",
      "Rank  487: mean feature #4789 (score = 0.002568)\n",
      "Rank  488: mean feature #3154 (score = 0.000000)\n",
      "Rank  489: max feature #6194 (score = 0.010311)\n",
      "Rank  490: mean feature #5615 (score = 0.000000)\n",
      "Rank  491: max feature #5554 (score = 0.003483)\n",
      "Rank  492: mean feature #2252 (score = 0.007827)\n",
      "Rank  493: mean feature #4183 (score = 0.003954)\n",
      "Rank  494: mean feature #2248 (score = 0.008402)\n",
      "Rank  495: max feature #3233 (score = 0.012674)\n",
      "Rank  496: mean feature #6211 (score = 0.000000)\n",
      "Rank  497: max feature #2065 (score = 0.007877)\n",
      "Rank  498: mean feature #2890 (score = 0.005526)\n",
      "Rank  499: mean feature #1501 (score = 0.002591)\n",
      "Rank  500: max feature #2957 (score = 0.001500)\n",
      "Rank  501: mean feature #5256 (score = 0.003988)\n",
      "Rank  502: max feature #2453 (score = 0.000000)\n",
      "Rank  503: max feature #2857 (score = 0.010000)\n",
      "Rank  504: max feature #248 (score = 0.000000)\n",
      "Rank  505: mean feature #4152 (score = 0.003175)\n",
      "Rank  506: mean feature #4988 (score = 0.004486)\n",
      "Rank  507: max feature #326 (score = 0.000950)\n",
      "Rank  508: mean feature #5144 (score = 0.001250)\n",
      "Rank  509: max feature #5305 (score = 0.005056)\n",
      "Rank  510: max feature #4435 (score = 0.008795)\n",
      "Rank  511: max feature #7820 (score = 0.008441)\n",
      "Rank  512: max feature #2641 (score = 0.000000)\n",
      "Rank  513: max feature #6351 (score = 0.003556)\n",
      "Rank  514: mean feature #7452 (score = 0.017220)\n",
      "Rank  515: mean feature #5408 (score = 0.005571)\n",
      "Rank  516: max feature #4607 (score = 0.006225)\n",
      "Rank  517: max feature #5820 (score = 0.000000)\n",
      "Rank  518: max feature #4116 (score = 0.004065)\n",
      "Rank  519: max feature #4759 (score = 0.010013)\n",
      "Rank  520: mean feature #2428 (score = 0.004183)\n",
      "Rank  521: mean feature #4360 (score = 0.001711)\n",
      "Rank  522: max feature #879 (score = 0.000000)\n",
      "Rank  523: max feature #5997 (score = 0.007982)\n",
      "Rank  524: max feature #870 (score = 0.000530)\n",
      "Rank  525: mean feature #6141 (score = 0.000000)\n",
      "Rank  526: max feature #3394 (score = 0.002647)\n",
      "Rank  527: max feature #2784 (score = 0.011397)\n",
      "Rank  528: mean feature #4746 (score = 0.000000)\n",
      "Rank  529: max feature #1841 (score = 0.001888)\n",
      "Rank  530: mean feature #7418 (score = 0.001632)\n",
      "Rank  531: mean feature #6000 (score = 0.000000)\n",
      "Rank  532: max feature #441 (score = 0.005750)\n",
      "Rank  533: mean feature #3193 (score = 0.002836)\n",
      "Rank  534: mean feature #4918 (score = 0.003212)\n",
      "Rank  535: mean feature #4536 (score = 0.001958)\n",
      "Rank  536: max feature #5782 (score = 0.000000)\n",
      "Rank  537: max feature #3836 (score = 0.001452)\n",
      "Rank  538: max feature #4362 (score = 0.004087)\n",
      "Rank  539: max feature #232 (score = 0.000000)\n",
      "Rank  540: max feature #2518 (score = 0.003628)\n",
      "Rank  541: mean feature #6921 (score = 0.000000)\n",
      "Rank  542: mean feature #766 (score = 0.000000)\n",
      "Rank  543: mean feature #1090 (score = 0.009311)\n",
      "Rank  544: mean feature #6259 (score = 0.009479)\n",
      "Rank  545: mean feature #4372 (score = 0.000000)\n",
      "Rank  546: max feature #2305 (score = 0.010342)\n",
      "Rank  547: mean feature #615 (score = 0.006334)\n",
      "Rank  548: mean feature #6268 (score = 0.000000)\n",
      "Rank  549: mean feature #5485 (score = 0.007886)\n",
      "Rank  550: max feature #4152 (score = 0.007198)\n",
      "Rank  551: mean feature #261 (score = 0.003545)\n",
      "Rank  552: max feature #1963 (score = 0.007735)\n",
      "Rank  553: mean feature #1700 (score = 0.014863)\n",
      "Rank  554: mean feature #6728 (score = 0.006510)\n",
      "Rank  555: mean feature #534 (score = 0.006796)\n",
      "Rank  556: max feature #2365 (score = 0.000000)\n",
      "Rank  557: mean feature #6336 (score = 0.000000)\n",
      "Rank  558: mean feature #3810 (score = 0.002710)\n",
      "Rank  559: max feature #1848 (score = 0.001527)\n",
      "Rank  560: max feature #1925 (score = 0.011086)\n",
      "Rank  561: mean feature #2702 (score = 0.003579)\n",
      "Rank  562: max feature #4189 (score = 0.000000)\n",
      "Rank  563: max feature #5160 (score = 0.000000)\n",
      "Rank  564: max feature #1403 (score = 0.000000)\n",
      "Rank  565: mean feature #1813 (score = 0.002933)\n",
      "Rank  566: mean feature #1635 (score = 0.001985)\n",
      "Rank  567: max feature #420 (score = 0.000000)\n",
      "Rank  568: max feature #5903 (score = 0.000007)\n",
      "Rank  569: mean feature #2182 (score = 0.010888)\n",
      "Rank  570: mean feature #2865 (score = 0.007708)\n",
      "Rank  571: mean feature #7750 (score = 0.015612)\n",
      "Rank  572: max feature #5933 (score = 0.000000)\n",
      "Rank  573: mean feature #2792 (score = 0.002262)\n",
      "Rank  574: mean feature #7718 (score = 0.006571)\n",
      "Rank  575: mean feature #5142 (score = 0.001134)\n",
      "Rank  576: max feature #5907 (score = 0.000000)\n",
      "Rank  577: mean feature #2285 (score = 0.000000)\n",
      "Rank  578: mean feature #1211 (score = 0.011548)\n",
      "Rank  579: mean feature #5461 (score = 0.000875)\n",
      "Rank  580: mean feature #810 (score = 0.000000)\n",
      "Rank  581: max feature #2996 (score = 0.006428)\n",
      "Rank  582: mean feature #2359 (score = 0.000768)\n",
      "Rank  583: mean feature #3208 (score = 0.000000)\n",
      "Rank  584: mean feature #6840 (score = 0.000000)\n",
      "Rank  585: max feature #1119 (score = 0.007994)\n",
      "Rank  586: max feature #8079 (score = 0.003704)\n",
      "Rank  587: mean feature #5499 (score = 0.000000)\n",
      "Rank  588: max feature #2143 (score = 0.000000)\n",
      "Rank  589: max feature #4747 (score = 0.012088)\n",
      "Rank  590: max feature #4004 (score = 0.000758)\n",
      "Rank  591: mean feature #3705 (score = 0.004834)\n",
      "Rank  592: mean feature #32 (score = 0.006238)\n",
      "Rank  593: mean feature #6017 (score = 0.005661)\n",
      "Rank  594: mean feature #4964 (score = 0.002276)\n",
      "Rank  595: mean feature #1411 (score = 0.004164)\n",
      "Rank  596: max feature #4305 (score = 0.000000)\n",
      "Rank  597: max feature #4106 (score = 0.004003)\n",
      "Rank  598: mean feature #100 (score = 0.009612)\n",
      "Rank  599: mean feature #2853 (score = 0.005950)\n",
      "Rank  600: mean feature #3456 (score = 0.007259)\n",
      "Rank  601: mean feature #6289 (score = 0.000000)\n",
      "Rank  602: mean feature #2725 (score = 0.000000)\n",
      "Rank  603: max feature #1071 (score = 0.000000)\n",
      "Rank  604: max feature #5066 (score = 0.010742)\n",
      "Rank  605: mean feature #3484 (score = 0.003966)\n",
      "Rank  606: max feature #6634 (score = 0.000000)\n",
      "Rank  607: max feature #4507 (score = 0.000000)\n",
      "Rank  608: mean feature #1382 (score = 0.001954)\n",
      "Rank  609: max feature #6323 (score = 0.015135)\n",
      "Rank  610: mean feature #6753 (score = 0.000202)\n",
      "Rank  611: mean feature #1345 (score = 0.006643)\n",
      "Rank  612: max feature #1048 (score = 0.008346)\n",
      "Rank  613: max feature #4848 (score = 0.004923)\n",
      "Rank  614: mean feature #2975 (score = 0.000000)\n",
      "Rank  615: max feature #7929 (score = 0.000000)\n",
      "Rank  616: mean feature #6654 (score = 0.000000)\n",
      "Rank  617: mean feature #7182 (score = 0.000000)\n",
      "Rank  618: max feature #7223 (score = 0.000171)\n",
      "Rank  619: max feature #3961 (score = 0.000638)\n",
      "Rank  620: mean feature #945 (score = 0.000000)\n",
      "Rank  621: mean feature #4140 (score = 0.006358)\n",
      "Rank  622: max feature #3823 (score = 0.008066)\n",
      "Rank  623: max feature #3048 (score = 0.000000)\n",
      "Rank  624: mean feature #1746 (score = 0.004457)\n",
      "Rank  625: max feature #4403 (score = 0.000000)\n",
      "Rank  626: max feature #7691 (score = 0.000000)\n",
      "Rank  627: mean feature #7024 (score = 0.000000)\n",
      "Rank  628: max feature #953 (score = 0.004284)\n",
      "Rank  629: mean feature #4730 (score = 0.006303)\n",
      "Rank  630: max feature #3592 (score = 0.008906)\n",
      "Rank  631: mean feature #4723 (score = 0.002507)\n",
      "Rank  632: max feature #4170 (score = 0.000000)\n",
      "Rank  633: mean feature #1520 (score = 0.000000)\n",
      "Rank  634: mean feature #3310 (score = 0.000000)\n",
      "Rank  635: mean feature #6864 (score = 0.000000)\n",
      "Rank  636: mean feature #4076 (score = 0.007925)\n",
      "Rank  637: max feature #2508 (score = 0.006691)\n",
      "Rank  638: max feature #6824 (score = 0.006941)\n",
      "Rank  639: max feature #7401 (score = 0.000000)\n",
      "Rank  640: mean feature #6991 (score = 0.004804)\n",
      "Rank  641: mean feature #1958 (score = 0.004838)\n",
      "Rank  642: mean feature #2617 (score = 0.002508)\n",
      "Rank  643: max feature #5755 (score = 0.002145)\n",
      "Rank  644: max feature #2306 (score = 0.008898)\n",
      "Rank  645: mean feature #5845 (score = 0.004120)\n",
      "Rank  646: mean feature #1413 (score = 0.000000)\n",
      "Rank  647: max feature #4117 (score = 0.009080)\n",
      "Rank  648: max feature #1585 (score = 0.000000)\n",
      "Rank  649: max feature #3020 (score = 0.005470)\n",
      "Rank  650: mean feature #8022 (score = 0.002423)\n",
      "Rank  651: mean feature #1599 (score = 0.004243)\n",
      "Rank  652: mean feature #1092 (score = 0.000000)\n",
      "Rank  653: max feature #1134 (score = 0.006784)\n",
      "Rank  654: mean feature #2310 (score = 0.009128)\n",
      "Rank  655: mean feature #3759 (score = 0.002340)\n",
      "Rank  656: mean feature #5281 (score = 0.008188)\n",
      "Rank  657: mean feature #3811 (score = 0.000000)\n",
      "Rank  658: mean feature #5487 (score = 0.000000)\n",
      "Rank  659: max feature #1608 (score = 0.004864)\n",
      "Rank  660: mean feature #3982 (score = 0.000000)\n",
      "Rank  661: mean feature #614 (score = 0.002266)\n",
      "Rank  662: mean feature #2591 (score = 0.000000)\n",
      "Rank  663: mean feature #5920 (score = 0.002820)\n",
      "Rank  664: max feature #345 (score = 0.000879)\n",
      "Rank  665: max feature #5834 (score = 0.011134)\n",
      "Rank  666: max feature #6648 (score = 0.000000)\n",
      "Rank  667: max feature #7040 (score = 0.003910)\n",
      "Rank  668: mean feature #4890 (score = 0.004372)\n",
      "Rank  669: max feature #6631 (score = 0.000000)\n",
      "Rank  670: mean feature #1180 (score = 0.004875)\n",
      "Rank  671: mean feature #3549 (score = 0.014459)\n",
      "Rank  672: mean feature #4702 (score = 0.002285)\n",
      "Rank  673: mean feature #6772 (score = 0.000000)\n",
      "Rank  674: mean feature #6571 (score = 0.003972)\n",
      "Rank  675: mean feature #8172 (score = 0.000000)\n",
      "Rank  676: mean feature #1352 (score = 0.015664)\n",
      "Rank  677: max feature #4985 (score = 0.000849)\n",
      "Rank  678: mean feature #4646 (score = 0.004013)\n",
      "Rank  679: max feature #6681 (score = 0.000939)\n",
      "Rank  680: max feature #2483 (score = 0.000000)\n",
      "Rank  681: mean feature #277 (score = 0.010255)\n",
      "Rank  682: mean feature #587 (score = 0.017697)\n",
      "Rank  683: mean feature #4259 (score = 0.000000)\n",
      "Rank  684: mean feature #5521 (score = 0.004458)\n",
      "Rank  685: mean feature #5076 (score = 0.003960)\n",
      "Rank  686: mean feature #3573 (score = 0.000000)\n",
      "Rank  687: max feature #4309 (score = 0.000000)\n",
      "Rank  688: max feature #2214 (score = 0.001747)\n",
      "Rank  689: mean feature #4547 (score = 0.006866)\n",
      "Rank  690: mean feature #2552 (score = 0.000000)\n",
      "Rank  691: mean feature #5334 (score = 0.005057)\n",
      "Rank  692: max feature #1801 (score = 0.001314)\n",
      "Rank  693: mean feature #107 (score = 0.003149)\n",
      "Rank  694: mean feature #2397 (score = 0.000324)\n",
      "Rank  695: max feature #5756 (score = 0.000000)\n",
      "Rank  696: max feature #4502 (score = 0.008173)\n",
      "Rank  697: max feature #631 (score = 0.000000)\n",
      "Rank  698: max feature #3585 (score = 0.002460)\n",
      "Rank  699: max feature #3416 (score = 0.000000)\n",
      "Rank  700: max feature #6730 (score = 0.000000)\n",
      "Rank  701: max feature #6628 (score = 0.009381)\n",
      "Rank  702: mean feature #7280 (score = 0.002081)\n",
      "Rank  703: mean feature #4920 (score = 0.002515)\n",
      "Rank  704: mean feature #1393 (score = 0.000000)\n",
      "Rank  705: max feature #584 (score = 0.004270)\n",
      "Rank  706: mean feature #5576 (score = 0.000000)\n",
      "Rank  707: max feature #4810 (score = 0.000000)\n",
      "Rank  708: mean feature #8063 (score = 0.007902)\n",
      "Rank  709: max feature #4112 (score = 0.008347)\n",
      "Rank  710: mean feature #2625 (score = 0.001214)\n",
      "Rank  711: max feature #755 (score = 0.001775)\n",
      "Rank  712: mean feature #6806 (score = 0.009018)\n",
      "Rank  713: max feature #734 (score = 0.007961)\n",
      "Rank  714: max feature #5493 (score = 0.001528)\n",
      "Rank  715: mean feature #6609 (score = 0.000000)\n",
      "Rank  716: max feature #5279 (score = 0.007324)\n",
      "Rank  717: mean feature #1637 (score = 0.001206)\n",
      "Rank  718: max feature #2679 (score = 0.011245)\n",
      "Rank  719: max feature #6718 (score = 0.000334)\n",
      "Rank  720: mean feature #5083 (score = 0.000000)\n",
      "Rank  721: mean feature #2527 (score = 0.000000)\n",
      "Rank  722: max feature #3070 (score = 0.005020)\n",
      "Rank  723: max feature #6546 (score = 0.002204)\n",
      "Rank  724: mean feature #7455 (score = 0.006936)\n",
      "Rank  725: max feature #2700 (score = 0.000000)\n",
      "Rank  726: mean feature #2925 (score = 0.000000)\n",
      "Rank  727: mean feature #5241 (score = 0.008702)\n",
      "Rank  728: max feature #6887 (score = 0.004402)\n",
      "Rank  729: mean feature #6928 (score = 0.000000)\n",
      "Rank  730: mean feature #662 (score = 0.000633)\n",
      "Rank  731: max feature #7070 (score = 0.000000)\n",
      "Rank  732: mean feature #4276 (score = 0.000399)\n",
      "Rank  733: max feature #2940 (score = 0.000000)\n",
      "Rank  734: max feature #5925 (score = 0.001009)\n",
      "Rank  735: mean feature #3148 (score = 0.010483)\n",
      "Rank  736: mean feature #5216 (score = 0.004622)\n",
      "Rank  737: max feature #7008 (score = 0.000000)\n",
      "Rank  738: mean feature #6795 (score = 0.000000)\n",
      "Rank  739: mean feature #8000 (score = 0.000000)\n",
      "Rank  740: mean feature #3531 (score = 0.000000)\n",
      "Rank  741: max feature #2741 (score = 0.004365)\n",
      "Rank  742: mean feature #2051 (score = 0.011802)\n",
      "Rank  743: mean feature #2297 (score = 0.000000)\n",
      "Rank  744: mean feature #2445 (score = 0.004897)\n",
      "Rank  745: max feature #3009 (score = 0.000308)\n",
      "Rank  746: mean feature #7838 (score = 0.000000)\n",
      "Rank  747: max feature #3378 (score = 0.011194)\n",
      "Rank  748: max feature #2103 (score = 0.000000)\n",
      "Rank  749: mean feature #7861 (score = 0.000000)\n",
      "Rank  750: max feature #988 (score = 0.000000)\n",
      "Rank  751: max feature #7555 (score = 0.007072)\n",
      "Rank  752: mean feature #1874 (score = 0.003605)\n",
      "Rank  753: mean feature #2566 (score = 0.005493)\n",
      "Rank  754: max feature #3493 (score = 0.000000)\n",
      "Rank  755: mean feature #249 (score = 0.007076)\n",
      "Rank  756: max feature #4732 (score = 0.000000)\n",
      "Rank  757: mean feature #3500 (score = 0.009632)\n",
      "Rank  758: max feature #6944 (score = 0.007612)\n",
      "Rank  759: max feature #4563 (score = 0.007539)\n",
      "Rank  760: mean feature #498 (score = 0.003603)\n",
      "Rank  761: mean feature #4544 (score = 0.003773)\n",
      "Rank  762: mean feature #4075 (score = 0.002015)\n",
      "Rank  763: mean feature #1199 (score = 0.002929)\n",
      "Rank  764: max feature #3417 (score = 0.007406)\n",
      "Rank  765: max feature #4620 (score = 0.001784)\n",
      "Rank  766: max feature #6386 (score = 0.005016)\n",
      "Rank  767: mean feature #1664 (score = 0.000000)\n",
      "Rank  768: mean feature #1260 (score = 0.008147)\n",
      "Rank  769: mean feature #5701 (score = 0.010860)\n",
      "Rank  770: mean feature #2682 (score = 0.005305)\n",
      "Rank  771: max feature #902 (score = 0.003600)\n",
      "Rank  772: mean feature #6615 (score = 0.003416)\n",
      "Rank  773: mean feature #5002 (score = 0.005068)\n",
      "Rank  774: mean feature #8121 (score = 0.008587)\n",
      "Rank  775: mean feature #2442 (score = 0.000545)\n",
      "Rank  776: max feature #5937 (score = 0.010385)\n",
      "Rank  777: mean feature #6126 (score = 0.000000)\n",
      "Rank  778: mean feature #7536 (score = 0.003850)\n",
      "Rank  779: mean feature #1173 (score = 0.000000)\n",
      "Rank  780: max feature #2687 (score = 0.013189)\n",
      "Rank  781: mean feature #1406 (score = 0.000000)\n",
      "Rank  782: mean feature #2270 (score = 0.000000)\n",
      "Rank  783: mean feature #3774 (score = 0.000000)\n",
      "Rank  784: max feature #6620 (score = 0.000000)\n",
      "Rank  785: mean feature #4485 (score = 0.000000)\n",
      "Rank  786: mean feature #723 (score = 0.000000)\n",
      "Rank  787: max feature #2397 (score = 0.000000)\n",
      "Rank  788: mean feature #294 (score = 0.002732)\n",
      "Rank  789: mean feature #5179 (score = 0.014030)\n",
      "Rank  790: mean feature #4631 (score = 0.007382)\n",
      "Rank  791: mean feature #2440 (score = 0.000000)\n",
      "Rank  792: max feature #7380 (score = 0.003000)\n",
      "Rank  793: max feature #1773 (score = 0.009087)\n",
      "Rank  794: max feature #6813 (score = 0.000000)\n",
      "Rank  795: max feature #1025 (score = 0.000000)\n",
      "Rank  796: mean feature #215 (score = 0.001185)\n",
      "Rank  797: mean feature #3075 (score = 0.006889)\n",
      "Rank  798: max feature #1038 (score = 0.000000)\n",
      "Rank  799: mean feature #8080 (score = 0.001854)\n",
      "Rank  800: max feature #5146 (score = 0.001323)\n",
      "Rank  801: max feature #290 (score = 0.002660)\n",
      "Rank  802: mean feature #3143 (score = 0.000000)\n",
      "Rank  803: max feature #3194 (score = 0.004552)\n",
      "Rank  804: mean feature #7722 (score = 0.000000)\n",
      "Rank  805: mean feature #1082 (score = 0.000000)\n",
      "Rank  806: max feature #2263 (score = 0.004923)\n",
      "Rank  807: max feature #52 (score = 0.000000)\n",
      "Rank  808: max feature #2663 (score = 0.013602)\n",
      "Rank  809: max feature #4610 (score = 0.000017)\n",
      "Rank  810: mean feature #4780 (score = 0.000000)\n",
      "Rank  811: max feature #900 (score = 0.003627)\n",
      "Rank  812: mean feature #727 (score = 0.000000)\n",
      "Rank  813: max feature #7977 (score = 0.000000)\n",
      "Rank  814: max feature #4966 (score = 0.003480)\n",
      "Rank  815: max feature #2046 (score = 0.007050)\n",
      "Rank  816: mean feature #3785 (score = 0.000000)\n",
      "Rank  817: max feature #395 (score = 0.008412)\n",
      "Rank  818: max feature #1618 (score = 0.000985)\n",
      "Rank  819: max feature #7004 (score = 0.002695)\n",
      "Rank  820: max feature #1708 (score = 0.002795)\n",
      "Rank  821: max feature #1418 (score = 0.010821)\n",
      "Rank  822: max feature #2710 (score = 0.000000)\n",
      "Rank  823: max feature #2541 (score = 0.000000)\n",
      "Rank  824: mean feature #473 (score = 0.009161)\n",
      "Rank  825: mean feature #1766 (score = 0.003175)\n",
      "Rank  826: max feature #2417 (score = 0.009134)\n",
      "Rank  827: max feature #7782 (score = 0.006190)\n",
      "Rank  828: max feature #4828 (score = 0.002855)\n",
      "Rank  829: mean feature #8101 (score = 0.003691)\n",
      "Rank  830: mean feature #67 (score = 0.000408)\n",
      "Rank  831: mean feature #916 (score = 0.005210)\n",
      "Rank  832: mean feature #431 (score = 0.009284)\n",
      "Rank  833: mean feature #3335 (score = 0.000839)\n",
      "Rank  834: mean feature #6551 (score = 0.004137)\n",
      "Rank  835: max feature #6715 (score = 0.001506)\n",
      "Rank  836: max feature #5781 (score = 0.007796)\n",
      "Rank  837: mean feature #1010 (score = 0.000000)\n",
      "Rank  838: mean feature #2152 (score = 0.000000)\n",
      "Rank  839: mean feature #3719 (score = 0.000000)\n",
      "Rank  840: mean feature #3074 (score = 0.000000)\n",
      "Rank  841: mean feature #1859 (score = 0.000000)\n",
      "Rank  842: max feature #3289 (score = 0.009176)\n",
      "Rank  843: mean feature #836 (score = 0.004230)\n",
      "Rank  844: mean feature #657 (score = 0.007807)\n",
      "Rank  845: mean feature #1653 (score = 0.000494)\n",
      "Rank  846: mean feature #1353 (score = 0.002292)\n",
      "Rank  847: mean feature #667 (score = 0.001020)\n",
      "Rank  848: max feature #145 (score = 0.003307)\n",
      "Rank  849: max feature #6125 (score = 0.000112)\n",
      "Rank  850: max feature #7258 (score = 0.008243)\n",
      "Rank  851: max feature #599 (score = 0.004704)\n",
      "Rank  852: max feature #706 (score = 0.003700)\n",
      "Rank  853: max feature #5333 (score = 0.000000)\n",
      "Rank  854: mean feature #2264 (score = 0.007580)\n",
      "Rank  855: max feature #7674 (score = 0.010252)\n",
      "Rank  856: max feature #1050 (score = 0.005409)\n",
      "Rank  857: mean feature #1995 (score = 0.002779)\n",
      "Rank  858: mean feature #8155 (score = 0.000000)\n",
      "Rank  859: mean feature #6494 (score = 0.000000)\n",
      "Rank  860: max feature #2872 (score = 0.000000)\n",
      "Rank  861: mean feature #4812 (score = 0.001819)\n",
      "Rank  862: mean feature #1251 (score = 0.000000)\n",
      "Rank  863: mean feature #6624 (score = 0.002605)\n",
      "Rank  864: mean feature #1261 (score = 0.000000)\n",
      "Rank  865: mean feature #5431 (score = 0.000000)\n",
      "Rank  866: max feature #258 (score = 0.000000)\n",
      "Rank  867: mean feature #1159 (score = 0.003962)\n",
      "Rank  868: mean feature #4452 (score = 0.011985)\n",
      "Rank  869: mean feature #4669 (score = 0.000000)\n",
      "Rank  870: max feature #1257 (score = 0.006634)\n",
      "Rank  871: max feature #3547 (score = 0.000000)\n",
      "Rank  872: max feature #1327 (score = 0.002747)\n",
      "Rank  873: max feature #5440 (score = 0.008637)\n",
      "Rank  874: max feature #13 (score = 0.011960)\n",
      "Rank  875: mean feature #8184 (score = 0.000330)\n",
      "Rank  876: mean feature #795 (score = 0.000000)\n",
      "Rank  877: mean feature #935 (score = 0.003436)\n",
      "Rank  878: mean feature #6370 (score = 0.004962)\n",
      "Rank  879: mean feature #763 (score = 0.000680)\n",
      "Rank  880: max feature #3457 (score = 0.001957)\n",
      "Rank  881: mean feature #6613 (score = 0.001851)\n",
      "Rank  882: max feature #5362 (score = 0.001751)\n",
      "Rank  883: mean feature #2503 (score = 0.005390)\n",
      "Rank  884: mean feature #2760 (score = 0.002264)\n",
      "Rank  885: max feature #4585 (score = 0.002564)\n",
      "Rank  886: mean feature #3743 (score = 0.000000)\n",
      "Rank  887: mean feature #7252 (score = 0.005960)\n",
      "Rank  888: max feature #3953 (score = 0.000177)\n",
      "Rank  889: mean feature #7414 (score = 0.000000)\n",
      "Rank  890: mean feature #7 (score = 0.000000)\n",
      "Rank  891: max feature #4372 (score = 0.000000)\n",
      "Rank  892: max feature #3017 (score = 0.004671)\n",
      "Rank  893: mean feature #4098 (score = 0.000000)\n",
      "Rank  894: max feature #2421 (score = 0.003200)\n",
      "Rank  895: mean feature #430 (score = 0.000000)\n",
      "Rank  896: max feature #3939 (score = 0.001748)\n",
      "Rank  897: max feature #1508 (score = 0.011662)\n",
      "Rank  898: max feature #3234 (score = 0.003614)\n",
      "Rank  899: max feature #2487 (score = 0.003359)\n",
      "Rank  900: mean feature #6058 (score = 0.000000)\n",
      "Rank  901: mean feature #6935 (score = 0.000000)\n",
      "Rank  902: max feature #7059 (score = 0.005442)\n",
      "Rank  903: max feature #2517 (score = 0.000491)\n",
      "Rank  904: mean feature #4910 (score = 0.004369)\n",
      "Rank  905: max feature #4494 (score = 0.000000)\n",
      "Rank  906: max feature #5961 (score = 0.015551)\n",
      "Rank  907: max feature #1567 (score = 0.000000)\n",
      "Rank  908: mean feature #4300 (score = 0.000000)\n",
      "Rank  909: mean feature #6283 (score = 0.000000)\n",
      "Rank  910: mean feature #3050 (score = 0.002867)\n",
      "Rank  911: max feature #3117 (score = 0.006345)\n",
      "Rank  912: max feature #2813 (score = 0.000000)\n",
      "Rank  913: mean feature #5865 (score = 0.006461)\n",
      "Rank  914: mean feature #332 (score = 0.000000)\n",
      "Rank  915: mean feature #5460 (score = 0.000000)\n",
      "Rank  916: mean feature #2115 (score = 0.004649)\n",
      "Rank  917: max feature #3856 (score = 0.000000)\n",
      "Rank  918: max feature #3357 (score = 0.000000)\n",
      "Rank  919: mean feature #388 (score = 0.000000)\n",
      "Rank  920: mean feature #4753 (score = 0.000000)\n",
      "Rank  921: mean feature #1988 (score = 0.014095)\n",
      "Rank  922: max feature #1722 (score = 0.007900)\n",
      "Rank  923: mean feature #4213 (score = 0.000000)\n",
      "Rank  924: mean feature #4948 (score = 0.001587)\n",
      "Rank  925: max feature #5716 (score = 0.009259)\n",
      "Rank  926: mean feature #3557 (score = 0.005065)\n",
      "Rank  927: mean feature #3126 (score = 0.000000)\n",
      "Rank  928: max feature #5894 (score = 0.005394)\n",
      "Rank  929: mean feature #1315 (score = 0.000453)\n",
      "Rank  930: mean feature #3366 (score = 0.000000)\n",
      "Rank  931: mean feature #2789 (score = 0.000000)\n",
      "Rank  932: mean feature #1770 (score = 0.000000)\n",
      "Rank  933: max feature #5840 (score = 0.000000)\n",
      "Rank  934: max feature #1633 (score = 0.000000)\n",
      "Rank  935: mean feature #6718 (score = 0.000000)\n",
      "Rank  936: mean feature #5245 (score = 0.002612)\n",
      "Rank  937: max feature #7728 (score = 0.000000)\n",
      "Rank  938: mean feature #1018 (score = 0.000000)\n",
      "Rank  939: mean feature #1420 (score = 0.006773)\n",
      "Rank  940: max feature #6238 (score = 0.000000)\n",
      "Rank  941: max feature #7039 (score = 0.000126)\n",
      "Rank  942: max feature #1014 (score = 0.000000)\n",
      "Rank  943: mean feature #2998 (score = 0.011421)\n",
      "Rank  944: mean feature #87 (score = 0.002689)\n",
      "Rank  945: max feature #653 (score = 0.005784)\n",
      "Rank  946: mean feature #7961 (score = 0.006962)\n",
      "Rank  947: max feature #2062 (score = 0.000000)\n",
      "Rank  948: mean feature #3547 (score = 0.000000)\n",
      "Rank  949: max feature #1346 (score = 0.000000)\n",
      "Rank  950: max feature #5532 (score = 0.013917)\n",
      "Rank  951: max feature #5178 (score = 0.000013)\n",
      "Rank  952: max feature #6588 (score = 0.008472)\n",
      "Rank  953: mean feature #4801 (score = 0.000000)\n",
      "Rank  954: mean feature #2661 (score = 0.004688)\n",
      "Rank  955: mean feature #127 (score = 0.001763)\n",
      "Rank  956: mean feature #2174 (score = 0.000000)\n",
      "Rank  957: mean feature #6707 (score = 0.000000)\n",
      "Rank  958: max feature #3466 (score = 0.000000)\n",
      "Rank  959: max feature #2126 (score = 0.000000)\n",
      "Rank  960: mean feature #88 (score = 0.000742)\n",
      "Rank  961: mean feature #637 (score = 0.000000)\n",
      "Rank  962: mean feature #4111 (score = 0.003062)\n",
      "Rank  963: max feature #1872 (score = 0.000000)\n",
      "Rank  964: mean feature #437 (score = 0.000000)\n",
      "Rank  965: mean feature #4470 (score = 0.003611)\n",
      "Rank  966: mean feature #7062 (score = 0.005771)\n",
      "Rank  967: mean feature #2746 (score = 0.000000)\n",
      "Rank  968: mean feature #3624 (score = 0.000000)\n",
      "Rank  969: max feature #244 (score = 0.012806)\n",
      "Rank  970: max feature #7014 (score = 0.000000)\n",
      "Rank  971: max feature #5887 (score = 0.001983)\n",
      "Rank  972: max feature #6024 (score = 0.000000)\n",
      "Rank  973: mean feature #1258 (score = 0.006620)\n",
      "Rank  974: mean feature #5365 (score = 0.013784)\n",
      "Rank  975: mean feature #6332 (score = 0.005258)\n",
      "Rank  976: max feature #5298 (score = 0.005265)\n",
      "Rank  977: mean feature #2570 (score = 0.000000)\n",
      "Rank  978: mean feature #2316 (score = 0.000000)\n",
      "Rank  979: max feature #8013 (score = 0.000000)\n",
      "Rank  980: mean feature #6769 (score = 0.000000)\n",
      "Rank  981: mean feature #6237 (score = 0.000000)\n",
      "Rank  982: max feature #4791 (score = 0.007719)\n",
      "Rank  983: mean feature #3533 (score = 0.000000)\n",
      "Rank  984: mean feature #7726 (score = 0.006667)\n",
      "Rank  985: mean feature #6487 (score = 0.000000)\n",
      "Rank  986: mean feature #1275 (score = 0.005378)\n",
      "Rank  987: mean feature #169 (score = 0.000000)\n",
      "Rank  988: mean feature #2584 (score = 0.000000)\n",
      "Rank  989: max feature #6155 (score = 0.006755)\n",
      "Rank  990: mean feature #1473 (score = 0.007826)\n",
      "Rank  991: mean feature #5247 (score = 0.010852)\n",
      "Rank  992: mean feature #3625 (score = 0.000000)\n",
      "Rank  993: mean feature #8078 (score = 0.000000)\n",
      "Rank  994: mean feature #1679 (score = 0.000000)\n",
      "Rank  995: max feature #1879 (score = 0.000980)\n",
      "Rank  996: mean feature #268 (score = 0.007197)\n",
      "Rank  997: max feature #6853 (score = 0.000000)\n",
      "Rank  998: mean feature #3339 (score = 0.000000)\n",
      "Rank  999: max feature #272 (score = 0.001358)\n",
      "Rank 1000: mean feature #3718 (score = 0.000950)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  660, 13495,  1043, ...,  7569,  7443,  8191])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Mutual Information (filter)\n",
    "mi_scores = mutual_info_classif(Xc, y, discrete_features=False)\n",
    "ranked_idx = rank_and_print(mi_scores, D, \"Mutual Information\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fe738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) L1-regularized Logistic Regression (embedded)\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(Xc)\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', solver='saga', C=1.0, max_iter=5000)\n",
    "sfm_lr = SelectFromModel(estimator=lr, max_features=1000)\n",
    "sfm_lr.fit(Xs, y)\n",
    "# Get absolute coefficients as scores\n",
    "lr_coef_scores = np.abs(sfm_lr.estimator_.coef_).flatten()\n",
    "ranked_idx = rank_and_print(lr_coef_scores, D, \"L1-Logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cd0a077",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_idx = ranked_idx[:1000]\n",
    "X_test = X_test_all_feat[:, top_idx]\n",
    "X_val = X_val_all_feat[:, top_idx]\n",
    "X_top = Xc[:, top_idx]      \n",
    "\n",
    "X_train = X_top\n",
    "y_train = y\n",
    "\n",
    "\n",
    "# X_test = X_test_all_feat[:, :]\n",
    "# X_val = X_val_all_feat[:, :]\n",
    "# X_top = Xc[:, :]      \n",
    "\n",
    "# X_train = X_top\n",
    "# y_train = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97c93d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.55      0.55       268\n",
      "           1       0.55      0.54      0.54       268\n",
      "\n",
      "    accuracy                           0.54       536\n",
      "   macro avg       0.54      0.54      0.54       536\n",
      "weighted avg       0.54      0.54      0.54       536\n",
      "\n",
      "ROC AUC: 0.5699209177990644\n"
     ]
    }
   ],
   "source": [
    "# 5) Train with L1 logistic regression & balanced class weights\n",
    "clf = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(\n",
    "        penalty=\"l1\",\n",
    "        solver=\"saga\",\n",
    "        # class_weight=\"balanced\",\n",
    "        C=1.0,\n",
    "        max_iter=7000,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 6) Evaluate\n",
    "y_pred   = clf.predict(X_test)\n",
    "y_probs  = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_probs))\n",
    "\n",
    "# 7) Inspect which of your top-1000 actually got nonzero weights\n",
    "lr = clf.named_steps[\"logisticregression\"]\n",
    "coefs = lr.coef_.ravel()\n",
    "nz    = np.where(coefs != 0)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dfaa751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best C (inverse reg. strength): 0.001\n",
      "CV ROC AUC: 0.712782018435753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.09      0.15       249\n",
      "           1       0.81      0.96      0.88      1005\n",
      "\n",
      "    accuracy                           0.79      1254\n",
      "   macro avg       0.59      0.53      0.51      1254\n",
      "weighted avg       0.72      0.79      0.73      1254\n",
      "\n",
      "Test ROC AUC: 0.6285160542668184\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\"logisticregression__C\": [0.0001, 0.001, 0.01, 0.1]}\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        solver=\"saga\",    \n",
    "        # solver=\"liblinear\",    \n",
    "        # class_weight=\"balanced\",\n",
    "        max_iter=10000,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best C (inverse reg. strength):\", search.best_params_[\"logisticregression__C\"])\n",
    "print(\"CV ROC AUC:\", search.best_score_)\n",
    "\n",
    "\n",
    "best_clf = search.best_estimator_\n",
    "y_pred_probs = best_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred       = best_clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Test ROC AUC:\", roc_auc_score(y_test, y_pred_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3e77399c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[186], line 23\u001b[0m\n\u001b[1;32m      3\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m make_pipeline(\n\u001b[1;32m      4\u001b[0m     StandardScaler(),\n\u001b[1;32m      5\u001b[0m     LogisticRegression(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     16\u001b[0m     pipeline,\n\u001b[1;32m     17\u001b[0m     param_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 23\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest C (inverse reg. strength):\u001b[39m\u001b[38;5;124m\"\u001b[39m, search\u001b[38;5;241m.\u001b[39mbest_params_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogisticregression__C\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCV ROC AUC:\u001b[39m\u001b[38;5;124m\"\u001b[39m, search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[0;32m~/surprise_sae/venv/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/surprise_sae/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/surprise_sae/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/surprise_sae/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/surprise_sae/venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/surprise_sae/venv/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/surprise_sae/venv/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/surprise_sae/venv/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\"logisticregression__C\": [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        solver=\"saga\",    \n",
    "        # solver=\"liblinear\",    \n",
    "        # class_weight=\"balanced\",\n",
    "        max_iter=7000,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best C (inverse reg. strength):\", search.best_params_[\"logisticregression__C\"])\n",
    "print(\"CV ROC AUC:\", search.best_score_)\n",
    "\n",
    "\n",
    "best_clf = search.best_estimator_\n",
    "y_pred_probs = best_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred       = best_clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Test ROC AUC:\", roc_auc_score(y_test, y_pred_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c2516dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best C (inverse reg. strength): 0.001\n",
      "CV ROC AUC: 0.7387063289671826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.09      0.14       249\n",
      "           1       0.81      0.96      0.88      1005\n",
      "\n",
      "    accuracy                           0.78      1254\n",
      "   macro avg       0.57      0.52      0.51      1254\n",
      "weighted avg       0.71      0.78      0.73      1254\n",
      "\n",
      "Test ROC AUC: 0.5974305180922695\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\"logisticregression__C\": [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        solver=\"saga\",    \n",
    "        # solver=\"liblinear\",    \n",
    "        # class_weight=\"balanced\",\n",
    "        max_iter=6000,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best C (inverse reg. strength):\", search.best_params_[\"logisticregression__C\"])\n",
    "print(\"CV ROC AUC:\", search.best_score_)\n",
    "\n",
    "\n",
    "best_clf = search.best_estimator_\n",
    "y_pred_probs = best_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred       = best_clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Test ROC AUC:\", roc_auc_score(y_test, y_pred_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "01459b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1: train loss = 0.5550\n",
      "Epoch  2: train loss = 0.4773\n",
      "Epoch  3: train loss = 0.4398\n",
      "Epoch  4: train loss = 0.4152\n",
      "Epoch  5: train loss = 0.3894\n",
      "Epoch  6: train loss = 0.3730\n",
      "Epoch  7: train loss = 0.3489\n",
      "Epoch  8: train loss = 0.3264\n",
      "Epoch  9: train loss = 0.3141\n",
      "Epoch 10: train loss = 0.2901\n",
      "Epoch 11: train loss = 0.2751\n",
      "Epoch 12: train loss = 0.2518\n",
      "Epoch 13: train loss = 0.2413\n",
      "Epoch 14: train loss = 0.2234\n",
      "Epoch 15: train loss = 0.2052\n",
      "Epoch 16: train loss = 0.1906\n",
      "Epoch 17: train loss = 0.1833\n",
      "Epoch 18: train loss = 0.1690\n",
      "Epoch 19: train loss = 0.1585\n",
      "Epoch 20: train loss = 0.1441\n",
      "Epoch 21: train loss = 0.1336\n",
      "Epoch 22: train loss = 0.1252\n",
      "Epoch 23: train loss = 0.1164\n",
      "Epoch 24: train loss = 0.1077\n",
      "Epoch 25: train loss = 0.1022\n",
      "Epoch 26: train loss = 0.0960\n",
      "Epoch 27: train loss = 0.0844\n",
      "Epoch 28: train loss = 0.0827\n",
      "Epoch 29: train loss = 0.0752\n",
      "Epoch 30: train loss = 0.0739\n",
      "Epoch 31: train loss = 0.0658\n",
      "Epoch 32: train loss = 0.0627\n",
      "Epoch 33: train loss = 0.0559\n",
      "Epoch 34: train loss = 0.0577\n",
      "Epoch 35: train loss = 0.0486\n",
      "Epoch 36: train loss = 0.0523\n",
      "Epoch 37: train loss = 0.0438\n",
      "Epoch 38: train loss = 0.0436\n",
      "Epoch 39: train loss = 0.0412\n",
      "Epoch 40: train loss = 0.0375\n",
      "Epoch 41: train loss = 0.0367\n",
      "Epoch 42: train loss = 0.0377\n",
      "Epoch 43: train loss = 0.0333\n",
      "Epoch 44: train loss = 0.0336\n",
      "Epoch 45: train loss = 0.0309\n",
      "Epoch 46: train loss = 0.0265\n",
      "Epoch 47: train loss = 0.0298\n",
      "Epoch 48: train loss = 0.0275\n",
      "Epoch 49: train loss = 0.0239\n",
      "Epoch 50: train loss = 0.0239\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.27      0.27       249\n",
      "           1       0.82      0.82      0.82      1005\n",
      "\n",
      "    accuracy                           0.71      1254\n",
      "   macro avg       0.55      0.55      0.55      1254\n",
      "weighted avg       0.71      0.71      0.71      1254\n",
      "\n",
      "Test ROC AUC: 0.5752042997862095\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_t = torch.from_numpy(X_train).float().to(device)\n",
    "y_train_t = torch.from_numpy(y_train).float().unsqueeze(1).to(device)\n",
    "X_test_t  = torch.from_numpy(X_test).float().to(device)\n",
    "y_test_t  = torch.from_numpy(y_test).float().unsqueeze(1).to(device)\n",
    "\n",
    "# DataLoader\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "class ShallowMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = ShallowMLP(input_dim=X_top.shape[1]).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 4) Training loop\n",
    "n_epochs = 50\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    avg_loss = total_loss / len(train_dl.dataset)\n",
    "    print(f\"Epoch {epoch:2d}: train loss = {avg_loss:.4f}\")\n",
    "\n",
    "# 5) Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_prob = model(X_test_t).cpu().numpy().flatten()\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Test ROC AUC:\", roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1333966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.79091+0.01652\ttest-auc:0.58206+0.02945\n",
      "[50]\ttrain-auc:1.00000+0.00000\ttest-auc:0.69692+0.02358\n",
      "[100]\ttrain-auc:1.00000+0.00000\ttest-auc:0.70410+0.02146\n",
      "[150]\ttrain-auc:1.00000+0.00000\ttest-auc:0.71121+0.01732\n",
      "[200]\ttrain-auc:1.00000+0.00000\ttest-auc:0.71543+0.01728\n",
      "[206]\ttrain-auc:1.00000+0.00000\ttest-auc:0.71560+0.01736\n",
      "Optimal boosting rounds: 188\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.18      0.22       222\n",
      "           1       0.79      0.89      0.84       793\n",
      "\n",
      "    accuracy                           0.73      1015\n",
      "   macro avg       0.55      0.53      0.53      1015\n",
      "weighted avg       0.69      0.73      0.70      1015\n",
      "\n",
      "Test ROC AUC: 0.5895618190700158\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest  = xgb.DMatrix(X_test,  label=y_test)\n",
    "\n",
    "\n",
    "scale_pos_weight = float((y_train == 0).sum()) / (y_train == 1).sum()\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"objective\":        \"binary:logistic\",\n",
    "    \"eval_metric\":      \"auc\",\n",
    "    \"scale_pos_weight\": scale_pos_weight,\n",
    "    \"tree_method\":      \"hist\",       \n",
    "    \"grow_policy\":      \"lossguide\",  \n",
    "    \"max_depth\":        6,\n",
    "    \"learning_rate\":    0.1,\n",
    "    \"subsample\":        0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"random_state\":     42,\n",
    "    \"verbosity\":        1\n",
    "}\n",
    "\n",
    "\n",
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    nfold=5,\n",
    "    early_stopping_rounds=20,\n",
    "    metrics=\"auc\",\n",
    "    seed=42,\n",
    "    as_pandas=True,\n",
    "    verbose_eval=50\n",
    ")\n",
    "best_rounds = len(cv_results)\n",
    "print(f\"Optimal boosting rounds: {best_rounds}\")\n",
    "\n",
    "\n",
    "bst = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=best_rounds\n",
    ")\n",
    "\n",
    "\n",
    "y_prob = bst.predict(dtest)\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Test ROC AUC:\", roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaf7986c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1  Train Loss: 0.7287  Val Loss: 0.7052\n",
      "Epoch  2  Train Loss: 0.7222  Val Loss: 0.6993\n",
      "Epoch  3  Train Loss: 0.7098  Val Loss: 0.7035\n",
      "Epoch  4  Train Loss: 0.7063  Val Loss: 0.6919\n",
      "Epoch  5  Train Loss: 0.7005  Val Loss: 0.6840\n",
      "Epoch  6  Train Loss: 0.6916  Val Loss: 0.6746\n",
      "Epoch  7  Train Loss: 0.6873  Val Loss: 0.6716\n",
      "Epoch  8  Train Loss: 0.6853  Val Loss: 0.6692\n",
      "Epoch  9  Train Loss: 0.6779  Val Loss: 0.6602\n",
      "Epoch 10  Train Loss: 0.6739  Val Loss: 0.6603\n",
      "Epoch 11  Train Loss: 0.6646  Val Loss: 0.6576\n",
      "Epoch 12  Train Loss: 0.6642  Val Loss: 0.6516\n",
      "Epoch 13  Train Loss: 0.6611  Val Loss: 0.6547\n",
      "Epoch 14  Train Loss: 0.6503  Val Loss: 0.6446\n",
      "Epoch 15  Train Loss: 0.6475  Val Loss: 0.6369\n",
      "Epoch 16  Train Loss: 0.6485  Val Loss: 0.6352\n",
      "Epoch 17  Train Loss: 0.6489  Val Loss: 0.6302\n",
      "Epoch 18  Train Loss: 0.6424  Val Loss: 0.6334\n",
      "Epoch 19  Train Loss: 0.6356  Val Loss: 0.6293\n",
      "Epoch 20  Train Loss: 0.6369  Val Loss: 0.6220\n",
      "Epoch 21  Train Loss: 0.6317  Val Loss: 0.6224\n",
      "Epoch 22  Train Loss: 0.6295  Val Loss: 0.6214\n",
      "Epoch 23  Train Loss: 0.6223  Val Loss: 0.6160\n",
      "Epoch 24  Train Loss: 0.6254  Val Loss: 0.6150\n",
      "Epoch 25  Train Loss: 0.6238  Val Loss: 0.6108\n",
      "Epoch 26  Train Loss: 0.6153  Val Loss: 0.6107\n",
      "Epoch 27  Train Loss: 0.6137  Val Loss: 0.6113\n",
      "Epoch 28  Train Loss: 0.6097  Val Loss: 0.6049\n",
      "Epoch 29  Train Loss: 0.6073  Val Loss: 0.6028\n",
      "Epoch 30  Train Loss: 0.6081  Val Loss: 0.6019\n",
      "Epoch 31  Train Loss: 0.6046  Val Loss: 0.5987\n",
      "Epoch 32  Train Loss: 0.6043  Val Loss: 0.6004\n",
      "Epoch 33  Train Loss: 0.6015  Val Loss: 0.5954\n",
      "Epoch 34  Train Loss: 0.5943  Val Loss: 0.5978\n",
      "Epoch 35  Train Loss: 0.5981  Val Loss: 0.5943\n",
      "Epoch 36  Train Loss: 0.5961  Val Loss: 0.5932\n",
      "Epoch 37  Train Loss: 0.5933  Val Loss: 0.5856\n",
      "Epoch 38  Train Loss: 0.5893  Val Loss: 0.5876\n",
      "Epoch 39  Train Loss: 0.5909  Val Loss: 0.5866\n",
      "Epoch 40  Train Loss: 0.5834  Val Loss: 0.5842\n",
      "Epoch 41  Train Loss: 0.5839  Val Loss: 0.5843\n",
      "Epoch 42  Train Loss: 0.5852  Val Loss: 0.5809\n",
      "Epoch 43  Train Loss: 0.5823  Val Loss: 0.5863\n",
      "Epoch 44  Train Loss: 0.5803  Val Loss: 0.5777\n",
      "Epoch 45  Train Loss: 0.5736  Val Loss: 0.5781\n",
      "Epoch 46  Train Loss: 0.5778  Val Loss: 0.5742\n",
      "Epoch 47  Train Loss: 0.5759  Val Loss: 0.5771\n",
      "Epoch 48  Train Loss: 0.5748  Val Loss: 0.5748\n",
      "Epoch 49  Train Loss: 0.5759  Val Loss: 0.5720\n",
      "Epoch 50  Train Loss: 0.5670  Val Loss: 0.5767\n",
      "Epoch 51  Train Loss: 0.5739  Val Loss: 0.5717\n",
      "Epoch 52  Train Loss: 0.5665  Val Loss: 0.5709\n",
      "Epoch 53  Train Loss: 0.5700  Val Loss: 0.5705\n",
      "Epoch 54  Train Loss: 0.5616  Val Loss: 0.5659\n",
      "Epoch 55  Train Loss: 0.5652  Val Loss: 0.5685\n",
      "Epoch 56  Train Loss: 0.5619  Val Loss: 0.5664\n",
      "Epoch 57  Train Loss: 0.5626  Val Loss: 0.5652\n",
      "Epoch 58  Train Loss: 0.5586  Val Loss: 0.5641\n",
      "Epoch 59  Train Loss: 0.5577  Val Loss: 0.5667\n",
      "Epoch 60  Train Loss: 0.5604  Val Loss: 0.5587\n",
      "Epoch 61  Train Loss: 0.5552  Val Loss: 0.5616\n",
      "Epoch 62  Train Loss: 0.5578  Val Loss: 0.5633\n",
      "Epoch 63  Train Loss: 0.5536  Val Loss: 0.5607\n",
      "Epoch 64  Train Loss: 0.5480  Val Loss: 0.5586\n",
      "Epoch 65  Train Loss: 0.5530  Val Loss: 0.5576\n",
      "Epoch 66  Train Loss: 0.5558  Val Loss: 0.5573\n",
      "Epoch 67  Train Loss: 0.5542  Val Loss: 0.5591\n",
      "Epoch 68  Train Loss: 0.5525  Val Loss: 0.5560\n",
      "Epoch 69  Train Loss: 0.5435  Val Loss: 0.5536\n",
      "Epoch 70  Train Loss: 0.5521  Val Loss: 0.5590\n",
      "Epoch 71  Train Loss: 0.5498  Val Loss: 0.5537\n",
      "Epoch 72  Train Loss: 0.5470  Val Loss: 0.5563\n",
      "Epoch 73  Train Loss: 0.5506  Val Loss: 0.5545\n",
      "Epoch 74  Train Loss: 0.5448  Val Loss: 0.5544\n",
      "Epoch 75  Train Loss: 0.5441  Val Loss: 0.5526\n",
      "Epoch 76  Train Loss: 0.5437  Val Loss: 0.5515\n",
      "Epoch 77  Train Loss: 0.5441  Val Loss: 0.5505\n",
      "Epoch 78  Train Loss: 0.5404  Val Loss: 0.5506\n",
      "Epoch 79  Train Loss: 0.5375  Val Loss: 0.5478\n",
      "Epoch 80  Train Loss: 0.5392  Val Loss: 0.5472\n",
      "Epoch 81  Train Loss: 0.5395  Val Loss: 0.5485\n",
      "Epoch 82  Train Loss: 0.5402  Val Loss: 0.5476\n",
      "Epoch 83  Train Loss: 0.5340  Val Loss: 0.5500\n",
      "Epoch 84  Train Loss: 0.5390  Val Loss: 0.5461\n",
      "Epoch 85  Train Loss: 0.5335  Val Loss: 0.5455\n",
      "Epoch 86  Train Loss: 0.5326  Val Loss: 0.5473\n",
      "Epoch 87  Train Loss: 0.5374  Val Loss: 0.5463\n",
      "Epoch 88  Train Loss: 0.5363  Val Loss: 0.5476\n",
      "Epoch 89  Train Loss: 0.5374  Val Loss: 0.5471\n",
      "Epoch 90  Train Loss: 0.5342  Val Loss: 0.5446\n",
      "Epoch 91  Train Loss: 0.5283  Val Loss: 0.5454\n",
      "Epoch 92  Train Loss: 0.5330  Val Loss: 0.5429\n",
      "Epoch 93  Train Loss: 0.5281  Val Loss: 0.5448\n",
      "Epoch 94  Train Loss: 0.5296  Val Loss: 0.5446\n",
      "Epoch 95  Train Loss: 0.5321  Val Loss: 0.5432\n",
      "Epoch 96  Train Loss: 0.5233  Val Loss: 0.5435\n",
      "Epoch 97  Train Loss: 0.5257  Val Loss: 0.5440\n",
      "Epoch 98  Train Loss: 0.5279  Val Loss: 0.5408\n",
      "Epoch 99  Train Loss: 0.5259  Val Loss: 0.5426\n",
      "Epoch 100  Train Loss: 0.5256  Val Loss: 0.5396\n",
      "Epoch 101  Train Loss: 0.5290  Val Loss: 0.5407\n",
      "Epoch 102  Train Loss: 0.5263  Val Loss: 0.5400\n",
      "Epoch 103  Train Loss: 0.5266  Val Loss: 0.5407\n",
      "Epoch 104  Train Loss: 0.5250  Val Loss: 0.5410\n",
      "Epoch 105  Train Loss: 0.5260  Val Loss: 0.5421\n",
      "Epoch 106  Train Loss: 0.5246  Val Loss: 0.5385\n",
      "Epoch 107  Train Loss: 0.5249  Val Loss: 0.5399\n",
      "Epoch 108  Train Loss: 0.5244  Val Loss: 0.5379\n",
      "Epoch 109  Train Loss: 0.5242  Val Loss: 0.5392\n",
      "Epoch 110  Train Loss: 0.5223  Val Loss: 0.5391\n",
      "Epoch 111  Train Loss: 0.5185  Val Loss: 0.5379\n",
      "Epoch 112  Train Loss: 0.5179  Val Loss: 0.5391\n",
      "Epoch 113  Train Loss: 0.5213  Val Loss: 0.5393\n",
      "Epoch 114  Train Loss: 0.5174  Val Loss: 0.5368\n",
      "Epoch 115  Train Loss: 0.5184  Val Loss: 0.5381\n",
      "Epoch 116  Train Loss: 0.5204  Val Loss: 0.5362\n",
      "Epoch 117  Train Loss: 0.5180  Val Loss: 0.5367\n",
      "Epoch 118  Train Loss: 0.5186  Val Loss: 0.5356\n",
      "Epoch 119  Train Loss: 0.5157  Val Loss: 0.5366\n",
      "Epoch 120  Train Loss: 0.5151  Val Loss: 0.5345\n",
      "Epoch 121  Train Loss: 0.5191  Val Loss: 0.5359\n",
      "Epoch 122  Train Loss: 0.5164  Val Loss: 0.5368\n",
      "Epoch 123  Train Loss: 0.5182  Val Loss: 0.5356\n",
      "Epoch 124  Train Loss: 0.5119  Val Loss: 0.5363\n",
      "Epoch 125  Train Loss: 0.5188  Val Loss: 0.5370\n",
      "Epoch 126  Train Loss: 0.5134  Val Loss: 0.5360\n",
      "Epoch 127  Train Loss: 0.5138  Val Loss: 0.5360\n",
      "Epoch 128  Train Loss: 0.5155  Val Loss: 0.5351\n",
      "Epoch 129  Train Loss: 0.5164  Val Loss: 0.5340\n",
      "Epoch 130  Train Loss: 0.5158  Val Loss: 0.5360\n",
      "Epoch 131  Train Loss: 0.5142  Val Loss: 0.5358\n",
      "Epoch 132  Train Loss: 0.5146  Val Loss: 0.5357\n",
      "Epoch 133  Train Loss: 0.5117  Val Loss: 0.5338\n",
      "Epoch 134  Train Loss: 0.5149  Val Loss: 0.5355\n",
      "Epoch 135  Train Loss: 0.5125  Val Loss: 0.5343\n",
      "Epoch 136  Train Loss: 0.5102  Val Loss: 0.5333\n",
      "Epoch 137  Train Loss: 0.5068  Val Loss: 0.5345\n",
      "Epoch 138  Train Loss: 0.5129  Val Loss: 0.5329\n",
      "Epoch 139  Train Loss: 0.5130  Val Loss: 0.5335\n",
      "Epoch 140  Train Loss: 0.5111  Val Loss: 0.5332\n",
      "Epoch 141  Train Loss: 0.5087  Val Loss: 0.5332\n",
      "Epoch 142  Train Loss: 0.5095  Val Loss: 0.5322\n",
      "Epoch 143  Train Loss: 0.5077  Val Loss: 0.5358\n",
      "Epoch 144  Train Loss: 0.5113  Val Loss: 0.5335\n",
      "Epoch 145  Train Loss: 0.5100  Val Loss: 0.5321\n",
      "Epoch 146  Train Loss: 0.5075  Val Loss: 0.5344\n",
      "Epoch 147  Train Loss: 0.5088  Val Loss: 0.5325\n",
      "Epoch 148  Train Loss: 0.5066  Val Loss: 0.5312\n",
      "Epoch 149  Train Loss: 0.5087  Val Loss: 0.5318\n",
      "Epoch 150  Train Loss: 0.5072  Val Loss: 0.5318\n",
      "Epoch 151  Train Loss: 0.5060  Val Loss: 0.5321\n",
      "Epoch 152  Train Loss: 0.5115  Val Loss: 0.5340\n",
      "Epoch 153  Train Loss: 0.5052  Val Loss: 0.5324\n",
      "Epoch 154  Train Loss: 0.5076  Val Loss: 0.5324\n",
      "Epoch 155  Train Loss: 0.5065  Val Loss: 0.5320\n",
      "Epoch 156  Train Loss: 0.5105  Val Loss: 0.5323\n",
      "Epoch 157  Train Loss: 0.5068  Val Loss: 0.5316\n",
      "Epoch 158  Train Loss: 0.5080  Val Loss: 0.5315\n",
      "Epoch 159  Train Loss: 0.5061  Val Loss: 0.5304\n",
      "Epoch 160  Train Loss: 0.5068  Val Loss: 0.5303\n",
      "Epoch 161  Train Loss: 0.5095  Val Loss: 0.5314\n",
      "Epoch 162  Train Loss: 0.5050  Val Loss: 0.5323\n",
      "Epoch 163  Train Loss: 0.5092  Val Loss: 0.5306\n",
      "Epoch 164  Train Loss: 0.5092  Val Loss: 0.5317\n",
      "Epoch 165  Train Loss: 0.5040  Val Loss: 0.5315\n",
      "Epoch 166  Train Loss: 0.5007  Val Loss: 0.5314\n",
      "Epoch 167  Train Loss: 0.5076  Val Loss: 0.5316\n",
      "Epoch 168  Train Loss: 0.5054  Val Loss: 0.5317\n",
      "Epoch 169  Train Loss: 0.5081  Val Loss: 0.5316\n",
      "Epoch 170  Train Loss: 0.5049  Val Loss: 0.5315\n",
      "Epoch 171  Train Loss: 0.5011  Val Loss: 0.5315\n",
      "Epoch 172  Train Loss: 0.5008  Val Loss: 0.5307\n",
      "Epoch 173  Train Loss: 0.5088  Val Loss: 0.5315\n",
      "Epoch 174  Train Loss: 0.5029  Val Loss: 0.5308\n",
      "Epoch 175  Train Loss: 0.4982  Val Loss: 0.5312\n",
      "Epoch 176  Train Loss: 0.5042  Val Loss: 0.5313\n",
      "Epoch 177  Train Loss: 0.4985  Val Loss: 0.5306\n",
      "Epoch 178  Train Loss: 0.5042  Val Loss: 0.5307\n",
      "Epoch 179  Train Loss: 0.5003  Val Loss: 0.5306\n",
      "Epoch 180  Train Loss: 0.5013  Val Loss: 0.5303\n",
      "Epoch 181  Train Loss: 0.5029  Val Loss: 0.5305\n",
      "Epoch 182  Train Loss: 0.4983  Val Loss: 0.5313\n",
      "Epoch 183  Train Loss: 0.5027  Val Loss: 0.5314\n",
      "Epoch 184  Train Loss: 0.5038  Val Loss: 0.5311\n",
      "Epoch 185  Train Loss: 0.5020  Val Loss: 0.5308\n",
      "Epoch 186  Train Loss: 0.5065  Val Loss: 0.5310\n",
      "Epoch 187  Train Loss: 0.5000  Val Loss: 0.5302\n",
      "Epoch 188  Train Loss: 0.5000  Val Loss: 0.5301\n",
      "Epoch 189  Train Loss: 0.5002  Val Loss: 0.5297\n",
      "Epoch 190  Train Loss: 0.4965  Val Loss: 0.5287\n",
      "Epoch 191  Train Loss: 0.4980  Val Loss: 0.5305\n",
      "Epoch 192  Train Loss: 0.4973  Val Loss: 0.5305\n",
      "Epoch 193  Train Loss: 0.4965  Val Loss: 0.5310\n",
      "Epoch 194  Train Loss: 0.4997  Val Loss: 0.5295\n",
      "Epoch 195  Train Loss: 0.5036  Val Loss: 0.5305\n",
      "Epoch 196  Train Loss: 0.4987  Val Loss: 0.5301\n",
      "Epoch 197  Train Loss: 0.5020  Val Loss: 0.5303\n",
      "Epoch 198  Train Loss: 0.4932  Val Loss: 0.5297\n",
      "Epoch 199  Train Loss: 0.4981  Val Loss: 0.5293\n",
      "Epoch 200  Train Loss: 0.4969  Val Loss: 0.5301\n",
      "Epoch 201  Train Loss: 0.4995  Val Loss: 0.5297\n",
      "Epoch 202  Train Loss: 0.4983  Val Loss: 0.5296\n",
      "Epoch 203  Train Loss: 0.4978  Val Loss: 0.5300\n",
      "Epoch 204  Train Loss: 0.5022  Val Loss: 0.5299\n",
      "Epoch 205  Train Loss: 0.4985  Val Loss: 0.5299\n",
      "Epoch 206  Train Loss: 0.4956  Val Loss: 0.5299\n",
      "Epoch 207  Train Loss: 0.4961  Val Loss: 0.5299\n",
      "Epoch 208  Train Loss: 0.4970  Val Loss: 0.5298\n",
      "Epoch 209  Train Loss: 0.4961  Val Loss: 0.5300\n",
      "Epoch 210  Train Loss: 0.4892  Val Loss: 0.5297\n",
      "Epoch 211  Train Loss: 0.4940  Val Loss: 0.5300\n",
      "Epoch 212  Train Loss: 0.4990  Val Loss: 0.5298\n",
      "Epoch 213  Train Loss: 0.4974  Val Loss: 0.5295\n",
      "Epoch 214  Train Loss: 0.4954  Val Loss: 0.5289\n",
      "Epoch 215  Train Loss: 0.4965  Val Loss: 0.5295\n",
      "Epoch 216  Train Loss: 0.5003  Val Loss: 0.5300\n",
      "Epoch 217  Train Loss: 0.4968  Val Loss: 0.5299\n",
      "Epoch 218  Train Loss: 0.4904  Val Loss: 0.5305\n",
      "Epoch 219  Train Loss: 0.4943  Val Loss: 0.5298\n",
      "Epoch 220  Train Loss: 0.4956  Val Loss: 0.5294\n",
      "Epoch 221  Train Loss: 0.4922  Val Loss: 0.5290\n",
      "Epoch 222  Train Loss: 0.4979  Val Loss: 0.5300\n",
      "Epoch 223  Train Loss: 0.4890  Val Loss: 0.5288\n",
      "Epoch 224  Train Loss: 0.4953  Val Loss: 0.5299\n",
      "Epoch 225  Train Loss: 0.4905  Val Loss: 0.5288\n",
      "Epoch 226  Train Loss: 0.4937  Val Loss: 0.5291\n",
      "Epoch 227  Train Loss: 0.4915  Val Loss: 0.5293\n",
      "Epoch 228  Train Loss: 0.4931  Val Loss: 0.5289\n",
      "Epoch 229  Train Loss: 0.4954  Val Loss: 0.5296\n",
      "Epoch 230  Train Loss: 0.4958  Val Loss: 0.5290\n",
      "Epoch 231  Train Loss: 0.4969  Val Loss: 0.5296\n",
      "Epoch 232  Train Loss: 0.4908  Val Loss: 0.5291\n",
      "Epoch 233  Train Loss: 0.4931  Val Loss: 0.5291\n",
      "Epoch 234  Train Loss: 0.4950  Val Loss: 0.5293\n",
      "Epoch 235  Train Loss: 0.4954  Val Loss: 0.5292\n",
      "Epoch 236  Train Loss: 0.4934  Val Loss: 0.5293\n",
      "Epoch 237  Train Loss: 0.4892  Val Loss: 0.5295\n",
      "Epoch 238  Train Loss: 0.4933  Val Loss: 0.5295\n",
      "Epoch 239  Train Loss: 0.4947  Val Loss: 0.5286\n",
      "Epoch 240  Train Loss: 0.4893  Val Loss: 0.5300\n",
      "Epoch 241  Train Loss: 0.4941  Val Loss: 0.5287\n",
      "Epoch 242  Train Loss: 0.4922  Val Loss: 0.5290\n",
      "Epoch 243  Train Loss: 0.4937  Val Loss: 0.5294\n",
      "Epoch 244  Train Loss: 0.4934  Val Loss: 0.5285\n",
      "Epoch 245  Train Loss: 0.4947  Val Loss: 0.5281\n",
      "Epoch 246  Train Loss: 0.4926  Val Loss: 0.5286\n",
      "Epoch 247  Train Loss: 0.4926  Val Loss: 0.5288\n",
      "Epoch 248  Train Loss: 0.4904  Val Loss: 0.5290\n",
      "Epoch 249  Train Loss: 0.4907  Val Loss: 0.5293\n",
      "Epoch 250  Train Loss: 0.4942  Val Loss: 0.5292\n",
      "Epoch 251  Train Loss: 0.4975  Val Loss: 0.5282\n",
      "Epoch 252  Train Loss: 0.4878  Val Loss: 0.5291\n",
      "Epoch 253  Train Loss: 0.4894  Val Loss: 0.5289\n",
      "Epoch 254  Train Loss: 0.4885  Val Loss: 0.5293\n",
      "Epoch 255  Train Loss: 0.4904  Val Loss: 0.5291\n",
      "Epoch 256  Train Loss: 0.4904  Val Loss: 0.5287\n",
      "Epoch 257  Train Loss: 0.4888  Val Loss: 0.5283\n",
      "Epoch 258  Train Loss: 0.4903  Val Loss: 0.5292\n",
      "Epoch 259  Train Loss: 0.4894  Val Loss: 0.5287\n",
      "Epoch 260  Train Loss: 0.4859  Val Loss: 0.5284\n",
      "Epoch 261  Train Loss: 0.4887  Val Loss: 0.5284\n",
      "Epoch 262  Train Loss: 0.4885  Val Loss: 0.5287\n",
      "Epoch 263  Train Loss: 0.4893  Val Loss: 0.5283\n",
      "Epoch 264  Train Loss: 0.4885  Val Loss: 0.5287\n",
      "Epoch 265  Train Loss: 0.4858  Val Loss: 0.5296\n",
      "Epoch 266  Train Loss: 0.4876  Val Loss: 0.5292\n",
      "Epoch 267  Train Loss: 0.4884  Val Loss: 0.5285\n",
      "Epoch 268  Train Loss: 0.4896  Val Loss: 0.5285\n",
      "Epoch 269  Train Loss: 0.4875  Val Loss: 0.5291\n",
      "Epoch 270  Train Loss: 0.4846  Val Loss: 0.5289\n",
      "Epoch 271  Train Loss: 0.4884  Val Loss: 0.5295\n",
      "Epoch 272  Train Loss: 0.4876  Val Loss: 0.5284\n",
      "Epoch 273  Train Loss: 0.4828  Val Loss: 0.5289\n",
      "Epoch 274  Train Loss: 0.4886  Val Loss: 0.5288\n",
      "Epoch 275  Train Loss: 0.4878  Val Loss: 0.5283\n",
      "Epoch 276  Train Loss: 0.4872  Val Loss: 0.5292\n",
      "Epoch 277  Train Loss: 0.4914  Val Loss: 0.5284\n",
      "Epoch 278  Train Loss: 0.4867  Val Loss: 0.5289\n",
      "Epoch 279  Train Loss: 0.4838  Val Loss: 0.5286\n",
      "Epoch 280  Train Loss: 0.4813  Val Loss: 0.5290\n",
      "Epoch 281  Train Loss: 0.4900  Val Loss: 0.5293\n",
      "Epoch 282  Train Loss: 0.4847  Val Loss: 0.5287\n",
      "Epoch 283  Train Loss: 0.4871  Val Loss: 0.5285\n",
      "Epoch 284  Train Loss: 0.4846  Val Loss: 0.5287\n",
      "Epoch 285  Train Loss: 0.4849  Val Loss: 0.5283\n",
      "Epoch 286  Train Loss: 0.4896  Val Loss: 0.5290\n",
      "Epoch 287  Train Loss: 0.4874  Val Loss: 0.5297\n",
      "Epoch 288  Train Loss: 0.4864  Val Loss: 0.5289\n",
      "Epoch 289  Train Loss: 0.4860  Val Loss: 0.5287\n",
      "Epoch 290  Train Loss: 0.4825  Val Loss: 0.5290\n",
      "Epoch 291  Train Loss: 0.4881  Val Loss: 0.5288\n",
      "Epoch 292  Train Loss: 0.4832  Val Loss: 0.5288\n",
      "Epoch 293  Train Loss: 0.4865  Val Loss: 0.5286\n",
      "Epoch 294  Train Loss: 0.4860  Val Loss: 0.5291\n",
      "Epoch 295  Train Loss: 0.4869  Val Loss: 0.5295\n",
      "Epoch 296  Train Loss: 0.4817  Val Loss: 0.5283\n",
      "Epoch 297  Train Loss: 0.4810  Val Loss: 0.5285\n",
      "Epoch 298  Train Loss: 0.4880  Val Loss: 0.5286\n",
      "Epoch 299  Train Loss: 0.4856  Val Loss: 0.5283\n",
      "Epoch 300  Train Loss: 0.4851  Val Loss: 0.5272\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      0.02      0.04       249\n",
      "         1.0       0.80      0.98      0.88      1005\n",
      "\n",
      "    accuracy                           0.79      1254\n",
      "   macro avg       0.49      0.50      0.46      1254\n",
      "weighted avg       0.68      0.79      0.71      1254\n",
      "\n",
      "Test ROC AUC: 0.6285160542668186\n"
     ]
    }
   ],
   "source": [
    "# 3 layer mlp\n",
    "\n",
    "def to_tensor_dataset(X, y):\n",
    "    Xt = torch.from_numpy(X).float().to(device)\n",
    "    yt = torch.from_numpy(y).float().unsqueeze(1).to(device)\n",
    "    return TensorDataset(Xt, yt)\n",
    "\n",
    "train_ds = to_tensor_dataset(X_train, y_train)\n",
    "val_ds   = to_tensor_dataset(X_val, y_val)\n",
    "test_ds  = to_tensor_dataset(X_test, y_test)\n",
    "\n",
    "batch_size = 32\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "pos = np.sum(y_train == 1)\n",
    "neg = np.sum(y_train == 0)\n",
    "pos_weight = torch.tensor(neg / pos, dtype=torch.float).to(device)\n",
    "\n",
    "# 5) Model definition\n",
    "class ShallowMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = ShallowMLP(input_dim=X_train.shape[1]).to(device)\n",
    "\n",
    "# 4) Optimizer and loss\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-6, weight_decay=1e-5)\n",
    "criterion = nn.BCELoss()\n",
    "# criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# 5) Training & Validation Loop\n",
    "n_epochs = 300\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # -- Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for xb, yb in train_dl:\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * xb.size(0)\n",
    "    train_loss /= len(train_dl.dataset)\n",
    "\n",
    "    # -- Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_dl:\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            val_loss += loss.item() * xb.size(0)\n",
    "    val_loss /= len(val_dl.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch:2d}  Train Loss: {train_loss:.4f}  Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Optional: save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "# 6) Load best model and test evaluation\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "y_probs = []\n",
    "y_true  = []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_dl:\n",
    "        probs = model(xb)\n",
    "        y_probs.extend(probs.cpu().numpy().flatten().tolist())\n",
    "        y_true .extend(yb.cpu().numpy().flatten().tolist())\n",
    "\n",
    "y_pred = (np.array(y_probs) >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(\"Test ROC AUC:\", roc_auc_score(y_true, y_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25c03ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1  Train Loss: 0.6794  Val Loss: 0.6720\n",
      "Epoch  2  Train Loss: 0.6789  Val Loss: 0.6685\n",
      "Epoch  3  Train Loss: 0.6763  Val Loss: 0.6645\n",
      "Epoch  4  Train Loss: 0.6725  Val Loss: 0.6687\n",
      "Epoch  5  Train Loss: 0.6671  Val Loss: 0.6643\n",
      "Epoch  6  Train Loss: 0.6626  Val Loss: 0.6624\n",
      "Epoch  7  Train Loss: 0.6660  Val Loss: 0.6556\n",
      "Epoch  8  Train Loss: 0.6610  Val Loss: 0.6592\n",
      "Epoch  9  Train Loss: 0.6593  Val Loss: 0.6531\n",
      "Epoch 10  Train Loss: 0.6511  Val Loss: 0.6602\n",
      "Epoch 11  Train Loss: 0.6574  Val Loss: 0.6512\n",
      "Epoch 12  Train Loss: 0.6480  Val Loss: 0.6512\n",
      "Epoch 13  Train Loss: 0.6436  Val Loss: 0.6455\n",
      "Epoch 14  Train Loss: 0.6464  Val Loss: 0.6457\n",
      "Epoch 15  Train Loss: 0.6451  Val Loss: 0.6486\n",
      "Epoch 16  Train Loss: 0.6426  Val Loss: 0.6466\n",
      "Epoch 17  Train Loss: 0.6390  Val Loss: 0.6403\n",
      "Epoch 18  Train Loss: 0.6357  Val Loss: 0.6386\n",
      "Epoch 19  Train Loss: 0.6340  Val Loss: 0.6384\n",
      "Epoch 20  Train Loss: 0.6348  Val Loss: 0.6393\n",
      "Epoch 21  Train Loss: 0.6279  Val Loss: 0.6362\n",
      "Epoch 22  Train Loss: 0.6300  Val Loss: 0.6362\n",
      "Epoch 23  Train Loss: 0.6255  Val Loss: 0.6330\n",
      "Epoch 24  Train Loss: 0.6310  Val Loss: 0.6343\n",
      "Epoch 25  Train Loss: 0.6174  Val Loss: 0.6353\n",
      "Epoch 26  Train Loss: 0.6227  Val Loss: 0.6340\n",
      "Epoch 27  Train Loss: 0.6221  Val Loss: 0.6333\n",
      "Epoch 28  Train Loss: 0.6188  Val Loss: 0.6277\n",
      "Epoch 29  Train Loss: 0.6157  Val Loss: 0.6319\n",
      "Epoch 30  Train Loss: 0.6127  Val Loss: 0.6268\n",
      "Epoch 31  Train Loss: 0.6090  Val Loss: 0.6259\n",
      "Epoch 32  Train Loss: 0.6090  Val Loss: 0.6236\n",
      "Epoch 33  Train Loss: 0.6090  Val Loss: 0.6222\n",
      "Epoch 34  Train Loss: 0.6098  Val Loss: 0.6281\n",
      "Epoch 35  Train Loss: 0.6032  Val Loss: 0.6193\n",
      "Epoch 36  Train Loss: 0.6046  Val Loss: 0.6135\n",
      "Epoch 37  Train Loss: 0.6053  Val Loss: 0.6163\n",
      "Epoch 38  Train Loss: 0.5987  Val Loss: 0.6164\n",
      "Epoch 39  Train Loss: 0.6012  Val Loss: 0.6161\n",
      "Epoch 40  Train Loss: 0.6003  Val Loss: 0.6170\n",
      "Epoch 41  Train Loss: 0.5927  Val Loss: 0.6122\n",
      "Epoch 42  Train Loss: 0.5959  Val Loss: 0.6144\n",
      "Epoch 43  Train Loss: 0.6021  Val Loss: 0.6132\n",
      "Epoch 44  Train Loss: 0.5919  Val Loss: 0.6095\n",
      "Epoch 45  Train Loss: 0.5960  Val Loss: 0.6096\n",
      "Epoch 46  Train Loss: 0.5915  Val Loss: 0.6066\n",
      "Epoch 47  Train Loss: 0.5906  Val Loss: 0.6113\n",
      "Epoch 48  Train Loss: 0.5820  Val Loss: 0.6056\n",
      "Epoch 49  Train Loss: 0.5868  Val Loss: 0.6094\n",
      "Epoch 50  Train Loss: 0.5873  Val Loss: 0.6031\n",
      "Epoch 51  Train Loss: 0.5898  Val Loss: 0.6017\n",
      "Epoch 52  Train Loss: 0.5861  Val Loss: 0.6071\n",
      "Epoch 53  Train Loss: 0.5848  Val Loss: 0.6058\n",
      "Epoch 54  Train Loss: 0.5831  Val Loss: 0.5956\n",
      "Epoch 55  Train Loss: 0.5859  Val Loss: 0.6024\n",
      "Epoch 56  Train Loss: 0.5796  Val Loss: 0.6032\n",
      "Epoch 57  Train Loss: 0.5776  Val Loss: 0.6005\n",
      "Epoch 58  Train Loss: 0.5718  Val Loss: 0.5975\n",
      "Epoch 59  Train Loss: 0.5771  Val Loss: 0.5952\n",
      "Epoch 60  Train Loss: 0.5716  Val Loss: 0.5969\n",
      "Epoch 61  Train Loss: 0.5778  Val Loss: 0.5986\n",
      "Epoch 62  Train Loss: 0.5724  Val Loss: 0.5953\n",
      "Epoch 63  Train Loss: 0.5732  Val Loss: 0.5923\n",
      "Epoch 64  Train Loss: 0.5729  Val Loss: 0.5966\n",
      "Epoch 65  Train Loss: 0.5697  Val Loss: 0.5891\n",
      "Epoch 66  Train Loss: 0.5675  Val Loss: 0.5894\n",
      "Epoch 67  Train Loss: 0.5691  Val Loss: 0.5888\n",
      "Epoch 68  Train Loss: 0.5699  Val Loss: 0.5920\n",
      "Epoch 69  Train Loss: 0.5642  Val Loss: 0.5880\n",
      "Epoch 70  Train Loss: 0.5686  Val Loss: 0.5875\n",
      "Epoch 71  Train Loss: 0.5714  Val Loss: 0.5883\n",
      "Epoch 72  Train Loss: 0.5641  Val Loss: 0.5862\n",
      "Epoch 73  Train Loss: 0.5678  Val Loss: 0.5849\n",
      "Epoch 74  Train Loss: 0.5651  Val Loss: 0.5859\n",
      "Epoch 75  Train Loss: 0.5676  Val Loss: 0.5832\n",
      "Epoch 76  Train Loss: 0.5605  Val Loss: 0.5854\n",
      "Epoch 77  Train Loss: 0.5593  Val Loss: 0.5836\n",
      "Epoch 78  Train Loss: 0.5600  Val Loss: 0.5828\n",
      "Epoch 79  Train Loss: 0.5644  Val Loss: 0.5843\n",
      "Epoch 80  Train Loss: 0.5669  Val Loss: 0.5787\n",
      "Epoch 81  Train Loss: 0.5619  Val Loss: 0.5803\n",
      "Epoch 82  Train Loss: 0.5608  Val Loss: 0.5790\n",
      "Epoch 83  Train Loss: 0.5625  Val Loss: 0.5803\n",
      "Epoch 84  Train Loss: 0.5588  Val Loss: 0.5792\n",
      "Epoch 85  Train Loss: 0.5556  Val Loss: 0.5750\n",
      "Epoch 86  Train Loss: 0.5593  Val Loss: 0.5785\n",
      "Epoch 87  Train Loss: 0.5607  Val Loss: 0.5779\n",
      "Epoch 88  Train Loss: 0.5467  Val Loss: 0.5750\n",
      "Epoch 89  Train Loss: 0.5575  Val Loss: 0.5744\n",
      "Epoch 90  Train Loss: 0.5554  Val Loss: 0.5767\n",
      "Epoch 91  Train Loss: 0.5540  Val Loss: 0.5770\n",
      "Epoch 92  Train Loss: 0.5490  Val Loss: 0.5720\n",
      "Epoch 93  Train Loss: 0.5490  Val Loss: 0.5753\n",
      "Epoch 94  Train Loss: 0.5605  Val Loss: 0.5764\n",
      "Epoch 95  Train Loss: 0.5491  Val Loss: 0.5774\n",
      "Epoch 96  Train Loss: 0.5546  Val Loss: 0.5743\n",
      "Epoch 97  Train Loss: 0.5506  Val Loss: 0.5745\n",
      "Epoch 98  Train Loss: 0.5580  Val Loss: 0.5736\n",
      "Epoch 99  Train Loss: 0.5518  Val Loss: 0.5748\n",
      "Epoch 100  Train Loss: 0.5482  Val Loss: 0.5709\n",
      "Epoch 101  Train Loss: 0.5465  Val Loss: 0.5755\n",
      "Epoch 102  Train Loss: 0.5521  Val Loss: 0.5714\n",
      "Epoch 103  Train Loss: 0.5476  Val Loss: 0.5723\n",
      "Epoch 104  Train Loss: 0.5534  Val Loss: 0.5703\n",
      "Epoch 105  Train Loss: 0.5501  Val Loss: 0.5716\n",
      "Epoch 106  Train Loss: 0.5507  Val Loss: 0.5714\n",
      "Epoch 107  Train Loss: 0.5448  Val Loss: 0.5714\n",
      "Epoch 108  Train Loss: 0.5468  Val Loss: 0.5664\n",
      "Epoch 109  Train Loss: 0.5529  Val Loss: 0.5678\n",
      "Epoch 110  Train Loss: 0.5500  Val Loss: 0.5680\n",
      "Epoch 111  Train Loss: 0.5491  Val Loss: 0.5666\n",
      "Epoch 112  Train Loss: 0.5459  Val Loss: 0.5644\n",
      "Epoch 113  Train Loss: 0.5453  Val Loss: 0.5681\n",
      "Epoch 114  Train Loss: 0.5445  Val Loss: 0.5698\n",
      "Epoch 115  Train Loss: 0.5434  Val Loss: 0.5667\n",
      "Epoch 116  Train Loss: 0.5429  Val Loss: 0.5684\n",
      "Epoch 117  Train Loss: 0.5394  Val Loss: 0.5653\n",
      "Epoch 118  Train Loss: 0.5508  Val Loss: 0.5680\n",
      "Epoch 119  Train Loss: 0.5413  Val Loss: 0.5629\n",
      "Epoch 120  Train Loss: 0.5413  Val Loss: 0.5657\n",
      "Epoch 121  Train Loss: 0.5393  Val Loss: 0.5621\n",
      "Epoch 122  Train Loss: 0.5390  Val Loss: 0.5657\n",
      "Epoch 123  Train Loss: 0.5483  Val Loss: 0.5625\n",
      "Epoch 124  Train Loss: 0.5485  Val Loss: 0.5635\n",
      "Epoch 125  Train Loss: 0.5471  Val Loss: 0.5646\n",
      "Epoch 126  Train Loss: 0.5414  Val Loss: 0.5600\n",
      "Epoch 127  Train Loss: 0.5430  Val Loss: 0.5633\n",
      "Epoch 128  Train Loss: 0.5429  Val Loss: 0.5648\n",
      "Epoch 129  Train Loss: 0.5446  Val Loss: 0.5610\n",
      "Epoch 130  Train Loss: 0.5436  Val Loss: 0.5607\n",
      "Epoch 131  Train Loss: 0.5375  Val Loss: 0.5635\n",
      "Epoch 132  Train Loss: 0.5424  Val Loss: 0.5590\n",
      "Epoch 133  Train Loss: 0.5450  Val Loss: 0.5623\n",
      "Epoch 134  Train Loss: 0.5372  Val Loss: 0.5609\n",
      "Epoch 135  Train Loss: 0.5420  Val Loss: 0.5627\n",
      "Epoch 136  Train Loss: 0.5417  Val Loss: 0.5578\n",
      "Epoch 137  Train Loss: 0.5436  Val Loss: 0.5604\n",
      "Epoch 138  Train Loss: 0.5380  Val Loss: 0.5596\n",
      "Epoch 139  Train Loss: 0.5396  Val Loss: 0.5549\n",
      "Epoch 140  Train Loss: 0.5384  Val Loss: 0.5564\n",
      "Epoch 141  Train Loss: 0.5409  Val Loss: 0.5615\n",
      "Epoch 142  Train Loss: 0.5432  Val Loss: 0.5583\n",
      "Epoch 143  Train Loss: 0.5409  Val Loss: 0.5565\n",
      "Epoch 144  Train Loss: 0.5368  Val Loss: 0.5537\n",
      "Epoch 145  Train Loss: 0.5388  Val Loss: 0.5597\n",
      "Epoch 146  Train Loss: 0.5405  Val Loss: 0.5593\n",
      "Epoch 147  Train Loss: 0.5414  Val Loss: 0.5548\n",
      "Epoch 148  Train Loss: 0.5431  Val Loss: 0.5549\n",
      "Epoch 149  Train Loss: 0.5437  Val Loss: 0.5579\n",
      "Epoch 150  Train Loss: 0.5440  Val Loss: 0.5623\n",
      "Epoch 151  Train Loss: 0.5408  Val Loss: 0.5579\n",
      "Epoch 152  Train Loss: 0.5359  Val Loss: 0.5581\n",
      "Epoch 153  Train Loss: 0.5369  Val Loss: 0.5546\n",
      "Epoch 154  Train Loss: 0.5354  Val Loss: 0.5570\n",
      "Epoch 155  Train Loss: 0.5407  Val Loss: 0.5525\n",
      "Epoch 156  Train Loss: 0.5446  Val Loss: 0.5573\n",
      "Epoch 157  Train Loss: 0.5365  Val Loss: 0.5563\n",
      "Epoch 158  Train Loss: 0.5316  Val Loss: 0.5585\n",
      "Epoch 159  Train Loss: 0.5351  Val Loss: 0.5547\n",
      "Epoch 160  Train Loss: 0.5373  Val Loss: 0.5524\n",
      "Epoch 161  Train Loss: 0.5389  Val Loss: 0.5537\n",
      "Epoch 162  Train Loss: 0.5425  Val Loss: 0.5560\n",
      "Epoch 163  Train Loss: 0.5353  Val Loss: 0.5553\n",
      "Epoch 164  Train Loss: 0.5331  Val Loss: 0.5555\n",
      "Epoch 165  Train Loss: 0.5405  Val Loss: 0.5558\n",
      "Epoch 166  Train Loss: 0.5352  Val Loss: 0.5552\n",
      "Epoch 167  Train Loss: 0.5323  Val Loss: 0.5521\n",
      "Epoch 168  Train Loss: 0.5385  Val Loss: 0.5538\n",
      "Epoch 169  Train Loss: 0.5328  Val Loss: 0.5523\n",
      "Epoch 170  Train Loss: 0.5358  Val Loss: 0.5544\n",
      "Epoch 171  Train Loss: 0.5283  Val Loss: 0.5554\n",
      "Epoch 172  Train Loss: 0.5334  Val Loss: 0.5522\n",
      "Epoch 173  Train Loss: 0.5370  Val Loss: 0.5532\n",
      "Epoch 174  Train Loss: 0.5312  Val Loss: 0.5531\n",
      "Epoch 175  Train Loss: 0.5306  Val Loss: 0.5533\n",
      "Epoch 176  Train Loss: 0.5328  Val Loss: 0.5517\n",
      "Epoch 177  Train Loss: 0.5348  Val Loss: 0.5524\n",
      "Epoch 178  Train Loss: 0.5352  Val Loss: 0.5507\n",
      "Epoch 179  Train Loss: 0.5374  Val Loss: 0.5529\n",
      "Epoch 180  Train Loss: 0.5341  Val Loss: 0.5532\n",
      "Epoch 181  Train Loss: 0.5350  Val Loss: 0.5529\n",
      "Epoch 182  Train Loss: 0.5325  Val Loss: 0.5521\n",
      "Epoch 183  Train Loss: 0.5352  Val Loss: 0.5496\n",
      "Epoch 184  Train Loss: 0.5361  Val Loss: 0.5546\n",
      "Epoch 185  Train Loss: 0.5352  Val Loss: 0.5544\n",
      "Epoch 186  Train Loss: 0.5357  Val Loss: 0.5493\n",
      "Epoch 187  Train Loss: 0.5326  Val Loss: 0.5521\n",
      "Epoch 188  Train Loss: 0.5279  Val Loss: 0.5526\n",
      "Epoch 189  Train Loss: 0.5351  Val Loss: 0.5505\n",
      "Epoch 190  Train Loss: 0.5289  Val Loss: 0.5523\n",
      "Epoch 191  Train Loss: 0.5304  Val Loss: 0.5500\n",
      "Epoch 192  Train Loss: 0.5324  Val Loss: 0.5486\n",
      "Epoch 193  Train Loss: 0.5310  Val Loss: 0.5504\n",
      "Epoch 194  Train Loss: 0.5360  Val Loss: 0.5483\n",
      "Epoch 195  Train Loss: 0.5253  Val Loss: 0.5517\n",
      "Epoch 196  Train Loss: 0.5394  Val Loss: 0.5527\n",
      "Epoch 197  Train Loss: 0.5301  Val Loss: 0.5515\n",
      "Epoch 198  Train Loss: 0.5330  Val Loss: 0.5524\n",
      "Epoch 199  Train Loss: 0.5346  Val Loss: 0.5485\n",
      "Epoch 200  Train Loss: 0.5356  Val Loss: 0.5519\n",
      "Epoch 201  Train Loss: 0.5312  Val Loss: 0.5529\n",
      "Epoch 202  Train Loss: 0.5344  Val Loss: 0.5511\n",
      "Epoch 203  Train Loss: 0.5309  Val Loss: 0.5474\n",
      "Epoch 204  Train Loss: 0.5347  Val Loss: 0.5461\n",
      "Epoch 205  Train Loss: 0.5325  Val Loss: 0.5489\n",
      "Epoch 206  Train Loss: 0.5309  Val Loss: 0.5488\n",
      "Epoch 207  Train Loss: 0.5374  Val Loss: 0.5469\n",
      "Epoch 208  Train Loss: 0.5309  Val Loss: 0.5494\n",
      "Epoch 209  Train Loss: 0.5261  Val Loss: 0.5490\n",
      "Epoch 210  Train Loss: 0.5351  Val Loss: 0.5488\n",
      "Epoch 211  Train Loss: 0.5272  Val Loss: 0.5514\n",
      "Epoch 212  Train Loss: 0.5360  Val Loss: 0.5467\n",
      "Epoch 213  Train Loss: 0.5336  Val Loss: 0.5469\n",
      "Epoch 214  Train Loss: 0.5306  Val Loss: 0.5515\n",
      "Epoch 215  Train Loss: 0.5390  Val Loss: 0.5511\n",
      "Epoch 216  Train Loss: 0.5320  Val Loss: 0.5453\n",
      "Epoch 217  Train Loss: 0.5331  Val Loss: 0.5444\n",
      "Epoch 218  Train Loss: 0.5319  Val Loss: 0.5501\n",
      "Epoch 219  Train Loss: 0.5249  Val Loss: 0.5473\n",
      "Epoch 220  Train Loss: 0.5264  Val Loss: 0.5492\n",
      "Epoch 221  Train Loss: 0.5331  Val Loss: 0.5507\n",
      "Epoch 222  Train Loss: 0.5332  Val Loss: 0.5485\n",
      "Epoch 223  Train Loss: 0.5331  Val Loss: 0.5504\n",
      "Epoch 224  Train Loss: 0.5306  Val Loss: 0.5459\n",
      "Epoch 225  Train Loss: 0.5260  Val Loss: 0.5485\n",
      "Epoch 226  Train Loss: 0.5331  Val Loss: 0.5459\n",
      "Epoch 227  Train Loss: 0.5273  Val Loss: 0.5446\n",
      "Epoch 228  Train Loss: 0.5308  Val Loss: 0.5472\n",
      "Epoch 229  Train Loss: 0.5275  Val Loss: 0.5442\n",
      "Epoch 230  Train Loss: 0.5222  Val Loss: 0.5459\n",
      "Epoch 231  Train Loss: 0.5304  Val Loss: 0.5503\n",
      "Epoch 232  Train Loss: 0.5285  Val Loss: 0.5491\n",
      "Epoch 233  Train Loss: 0.5244  Val Loss: 0.5452\n",
      "Epoch 234  Train Loss: 0.5289  Val Loss: 0.5478\n",
      "Epoch 235  Train Loss: 0.5274  Val Loss: 0.5462\n",
      "Epoch 236  Train Loss: 0.5265  Val Loss: 0.5475\n",
      "Epoch 237  Train Loss: 0.5338  Val Loss: 0.5446\n",
      "Epoch 238  Train Loss: 0.5309  Val Loss: 0.5456\n",
      "Epoch 239  Train Loss: 0.5255  Val Loss: 0.5501\n",
      "Epoch 240  Train Loss: 0.5272  Val Loss: 0.5464\n",
      "Epoch 241  Train Loss: 0.5285  Val Loss: 0.5468\n",
      "Epoch 242  Train Loss: 0.5311  Val Loss: 0.5466\n",
      "Epoch 243  Train Loss: 0.5265  Val Loss: 0.5469\n",
      "Epoch 244  Train Loss: 0.5315  Val Loss: 0.5450\n",
      "Epoch 245  Train Loss: 0.5351  Val Loss: 0.5444\n",
      "Epoch 246  Train Loss: 0.5373  Val Loss: 0.5470\n",
      "Epoch 247  Train Loss: 0.5249  Val Loss: 0.5421\n",
      "Epoch 248  Train Loss: 0.5285  Val Loss: 0.5442\n",
      "Epoch 249  Train Loss: 0.5258  Val Loss: 0.5486\n",
      "Epoch 250  Train Loss: 0.5286  Val Loss: 0.5474\n",
      "Epoch 251  Train Loss: 0.5278  Val Loss: 0.5450\n",
      "Epoch 252  Train Loss: 0.5292  Val Loss: 0.5471\n",
      "Epoch 253  Train Loss: 0.5222  Val Loss: 0.5463\n",
      "Epoch 254  Train Loss: 0.5273  Val Loss: 0.5471\n",
      "Epoch 255  Train Loss: 0.5242  Val Loss: 0.5483\n",
      "Epoch 256  Train Loss: 0.5299  Val Loss: 0.5464\n",
      "Epoch 257  Train Loss: 0.5299  Val Loss: 0.5464\n",
      "Epoch 258  Train Loss: 0.5309  Val Loss: 0.5454\n",
      "Epoch 259  Train Loss: 0.5282  Val Loss: 0.5454\n",
      "Epoch 260  Train Loss: 0.5260  Val Loss: 0.5467\n",
      "Epoch 261  Train Loss: 0.5296  Val Loss: 0.5460\n",
      "Epoch 262  Train Loss: 0.5290  Val Loss: 0.5461\n",
      "Epoch 263  Train Loss: 0.5282  Val Loss: 0.5435\n",
      "Epoch 264  Train Loss: 0.5267  Val Loss: 0.5497\n",
      "Epoch 265  Train Loss: 0.5285  Val Loss: 0.5469\n",
      "Epoch 266  Train Loss: 0.5255  Val Loss: 0.5463\n",
      "Epoch 267  Train Loss: 0.5286  Val Loss: 0.5440\n",
      "Epoch 268  Train Loss: 0.5267  Val Loss: 0.5443\n",
      "Epoch 269  Train Loss: 0.5230  Val Loss: 0.5454\n",
      "Epoch 270  Train Loss: 0.5277  Val Loss: 0.5464\n",
      "Epoch 271  Train Loss: 0.5242  Val Loss: 0.5453\n",
      "Epoch 272  Train Loss: 0.5297  Val Loss: 0.5473\n",
      "Epoch 273  Train Loss: 0.5251  Val Loss: 0.5475\n",
      "Epoch 274  Train Loss: 0.5299  Val Loss: 0.5464\n",
      "Epoch 275  Train Loss: 0.5272  Val Loss: 0.5452\n",
      "Epoch 276  Train Loss: 0.5251  Val Loss: 0.5438\n",
      "Epoch 277  Train Loss: 0.5259  Val Loss: 0.5454\n",
      "Epoch 278  Train Loss: 0.5239  Val Loss: 0.5466\n",
      "Epoch 279  Train Loss: 0.5288  Val Loss: 0.5459\n",
      "Epoch 280  Train Loss: 0.5259  Val Loss: 0.5449\n",
      "Epoch 281  Train Loss: 0.5250  Val Loss: 0.5422\n",
      "Epoch 282  Train Loss: 0.5298  Val Loss: 0.5423\n",
      "Epoch 283  Train Loss: 0.5288  Val Loss: 0.5453\n",
      "Epoch 284  Train Loss: 0.5241  Val Loss: 0.5428\n",
      "Epoch 285  Train Loss: 0.5263  Val Loss: 0.5460\n",
      "Epoch 286  Train Loss: 0.5231  Val Loss: 0.5412\n",
      "Epoch 287  Train Loss: 0.5230  Val Loss: 0.5463\n",
      "Epoch 288  Train Loss: 0.5332  Val Loss: 0.5447\n",
      "Epoch 289  Train Loss: 0.5267  Val Loss: 0.5428\n",
      "Epoch 290  Train Loss: 0.5266  Val Loss: 0.5437\n",
      "Epoch 291  Train Loss: 0.5247  Val Loss: 0.5468\n",
      "Epoch 292  Train Loss: 0.5255  Val Loss: 0.5431\n",
      "Epoch 293  Train Loss: 0.5254  Val Loss: 0.5421\n",
      "Epoch 294  Train Loss: 0.5301  Val Loss: 0.5420\n",
      "Epoch 295  Train Loss: 0.5224  Val Loss: 0.5443\n",
      "Epoch 296  Train Loss: 0.5287  Val Loss: 0.5428\n",
      "Epoch 297  Train Loss: 0.5289  Val Loss: 0.5435\n",
      "Epoch 298  Train Loss: 0.5246  Val Loss: 0.5428\n",
      "Epoch 299  Train Loss: 0.5268  Val Loss: 0.5428\n",
      "Epoch 300  Train Loss: 0.5261  Val Loss: 0.5416\n",
      "Epoch 301  Train Loss: 0.5229  Val Loss: 0.5441\n",
      "Epoch 302  Train Loss: 0.5258  Val Loss: 0.5440\n",
      "Epoch 303  Train Loss: 0.5247  Val Loss: 0.5476\n",
      "Epoch 304  Train Loss: 0.5245  Val Loss: 0.5420\n",
      "Epoch 305  Train Loss: 0.5224  Val Loss: 0.5437\n",
      "Epoch 306  Train Loss: 0.5217  Val Loss: 0.5448\n",
      "Epoch 307  Train Loss: 0.5265  Val Loss: 0.5439\n",
      "Epoch 308  Train Loss: 0.5263  Val Loss: 0.5428\n",
      "Epoch 309  Train Loss: 0.5218  Val Loss: 0.5423\n",
      "Epoch 310  Train Loss: 0.5254  Val Loss: 0.5433\n",
      "Epoch 311  Train Loss: 0.5240  Val Loss: 0.5448\n",
      "Epoch 312  Train Loss: 0.5231  Val Loss: 0.5406\n",
      "Epoch 313  Train Loss: 0.5210  Val Loss: 0.5439\n",
      "Epoch 314  Train Loss: 0.5239  Val Loss: 0.5457\n",
      "Epoch 315  Train Loss: 0.5215  Val Loss: 0.5447\n",
      "Epoch 316  Train Loss: 0.5236  Val Loss: 0.5423\n",
      "Epoch 317  Train Loss: 0.5222  Val Loss: 0.5470\n",
      "Epoch 318  Train Loss: 0.5232  Val Loss: 0.5466\n",
      "Epoch 319  Train Loss: 0.5259  Val Loss: 0.5411\n",
      "Epoch 320  Train Loss: 0.5226  Val Loss: 0.5458\n",
      "Epoch 321  Train Loss: 0.5261  Val Loss: 0.5411\n",
      "Epoch 322  Train Loss: 0.5189  Val Loss: 0.5424\n",
      "Epoch 323  Train Loss: 0.5236  Val Loss: 0.5410\n",
      "Epoch 324  Train Loss: 0.5235  Val Loss: 0.5418\n",
      "Epoch 325  Train Loss: 0.5258  Val Loss: 0.5439\n",
      "Epoch 326  Train Loss: 0.5168  Val Loss: 0.5412\n",
      "Epoch 327  Train Loss: 0.5250  Val Loss: 0.5440\n",
      "Epoch 328  Train Loss: 0.5201  Val Loss: 0.5465\n",
      "Epoch 329  Train Loss: 0.5247  Val Loss: 0.5427\n",
      "Epoch 330  Train Loss: 0.5233  Val Loss: 0.5394\n",
      "Epoch 331  Train Loss: 0.5255  Val Loss: 0.5421\n",
      "Epoch 332  Train Loss: 0.5254  Val Loss: 0.5435\n",
      "Epoch 333  Train Loss: 0.5202  Val Loss: 0.5410\n",
      "Epoch 334  Train Loss: 0.5199  Val Loss: 0.5426\n",
      "Epoch 335  Train Loss: 0.5224  Val Loss: 0.5432\n",
      "Epoch 336  Train Loss: 0.5247  Val Loss: 0.5417\n",
      "Epoch 337  Train Loss: 0.5267  Val Loss: 0.5446\n",
      "Epoch 338  Train Loss: 0.5243  Val Loss: 0.5395\n",
      "Epoch 339  Train Loss: 0.5233  Val Loss: 0.5425\n",
      "Epoch 340  Train Loss: 0.5201  Val Loss: 0.5433\n",
      "Epoch 341  Train Loss: 0.5208  Val Loss: 0.5450\n",
      "Epoch 342  Train Loss: 0.5215  Val Loss: 0.5453\n",
      "Epoch 343  Train Loss: 0.5207  Val Loss: 0.5385\n",
      "Epoch 344  Train Loss: 0.5258  Val Loss: 0.5395\n",
      "Epoch 345  Train Loss: 0.5242  Val Loss: 0.5416\n",
      "Epoch 346  Train Loss: 0.5215  Val Loss: 0.5415\n",
      "Epoch 347  Train Loss: 0.5242  Val Loss: 0.5437\n",
      "Epoch 348  Train Loss: 0.5178  Val Loss: 0.5393\n",
      "Epoch 349  Train Loss: 0.5176  Val Loss: 0.5401\n",
      "Epoch 350  Train Loss: 0.5188  Val Loss: 0.5419\n",
      "Epoch 351  Train Loss: 0.5255  Val Loss: 0.5393\n",
      "Epoch 352  Train Loss: 0.5200  Val Loss: 0.5399\n",
      "Epoch 353  Train Loss: 0.5246  Val Loss: 0.5425\n",
      "Epoch 354  Train Loss: 0.5219  Val Loss: 0.5408\n",
      "Epoch 355  Train Loss: 0.5233  Val Loss: 0.5431\n",
      "Epoch 356  Train Loss: 0.5184  Val Loss: 0.5431\n",
      "Epoch 357  Train Loss: 0.5246  Val Loss: 0.5436\n",
      "Epoch 358  Train Loss: 0.5154  Val Loss: 0.5420\n",
      "Epoch 359  Train Loss: 0.5329  Val Loss: 0.5438\n",
      "Epoch 360  Train Loss: 0.5247  Val Loss: 0.5422\n",
      "Epoch 361  Train Loss: 0.5152  Val Loss: 0.5422\n",
      "Epoch 362  Train Loss: 0.5216  Val Loss: 0.5464\n",
      "Epoch 363  Train Loss: 0.5244  Val Loss: 0.5415\n",
      "Epoch 364  Train Loss: 0.5210  Val Loss: 0.5422\n",
      "Epoch 365  Train Loss: 0.5204  Val Loss: 0.5420\n",
      "Epoch 366  Train Loss: 0.5202  Val Loss: 0.5425\n",
      "Epoch 367  Train Loss: 0.5286  Val Loss: 0.5460\n",
      "Epoch 368  Train Loss: 0.5256  Val Loss: 0.5416\n",
      "Epoch 369  Train Loss: 0.5247  Val Loss: 0.5417\n",
      "Epoch 370  Train Loss: 0.5198  Val Loss: 0.5419\n",
      "Epoch 371  Train Loss: 0.5183  Val Loss: 0.5452\n",
      "Epoch 372  Train Loss: 0.5153  Val Loss: 0.5437\n",
      "Epoch 373  Train Loss: 0.5168  Val Loss: 0.5444\n",
      "Epoch 374  Train Loss: 0.5195  Val Loss: 0.5429\n",
      "Epoch 375  Train Loss: 0.5162  Val Loss: 0.5429\n",
      "Epoch 376  Train Loss: 0.5239  Val Loss: 0.5412\n",
      "Epoch 377  Train Loss: 0.5217  Val Loss: 0.5414\n",
      "Epoch 378  Train Loss: 0.5193  Val Loss: 0.5414\n",
      "Epoch 379  Train Loss: 0.5154  Val Loss: 0.5421\n",
      "Epoch 380  Train Loss: 0.5142  Val Loss: 0.5445\n",
      "Epoch 381  Train Loss: 0.5219  Val Loss: 0.5410\n",
      "Epoch 382  Train Loss: 0.5214  Val Loss: 0.5421\n",
      "Epoch 383  Train Loss: 0.5206  Val Loss: 0.5414\n",
      "Epoch 384  Train Loss: 0.5189  Val Loss: 0.5452\n",
      "Epoch 385  Train Loss: 0.5218  Val Loss: 0.5378\n",
      "Epoch 386  Train Loss: 0.5219  Val Loss: 0.5414\n",
      "Epoch 387  Train Loss: 0.5157  Val Loss: 0.5419\n",
      "Epoch 388  Train Loss: 0.5199  Val Loss: 0.5445\n",
      "Epoch 389  Train Loss: 0.5184  Val Loss: 0.5415\n",
      "Epoch 390  Train Loss: 0.5202  Val Loss: 0.5423\n",
      "Epoch 391  Train Loss: 0.5091  Val Loss: 0.5396\n",
      "Epoch 392  Train Loss: 0.5157  Val Loss: 0.5422\n",
      "Epoch 393  Train Loss: 0.5201  Val Loss: 0.5431\n",
      "Epoch 394  Train Loss: 0.5218  Val Loss: 0.5441\n",
      "Epoch 395  Train Loss: 0.5188  Val Loss: 0.5413\n",
      "Epoch 396  Train Loss: 0.5187  Val Loss: 0.5429\n",
      "Epoch 397  Train Loss: 0.5166  Val Loss: 0.5438\n",
      "Epoch 398  Train Loss: 0.5191  Val Loss: 0.5398\n",
      "Epoch 399  Train Loss: 0.5214  Val Loss: 0.5399\n",
      "Epoch 400  Train Loss: 0.5193  Val Loss: 0.5410\n",
      "Epoch 401  Train Loss: 0.5186  Val Loss: 0.5424\n",
      "Epoch 402  Train Loss: 0.5128  Val Loss: 0.5417\n",
      "Epoch 403  Train Loss: 0.5201  Val Loss: 0.5424\n",
      "Epoch 404  Train Loss: 0.5203  Val Loss: 0.5403\n",
      "Epoch 405  Train Loss: 0.5184  Val Loss: 0.5417\n",
      "Epoch 406  Train Loss: 0.5208  Val Loss: 0.5387\n",
      "Epoch 407  Train Loss: 0.5154  Val Loss: 0.5399\n",
      "Epoch 408  Train Loss: 0.5217  Val Loss: 0.5428\n",
      "Epoch 409  Train Loss: 0.5148  Val Loss: 0.5415\n",
      "Epoch 410  Train Loss: 0.5198  Val Loss: 0.5417\n",
      "Epoch 411  Train Loss: 0.5213  Val Loss: 0.5417\n",
      "Epoch 412  Train Loss: 0.5194  Val Loss: 0.5421\n",
      "Epoch 413  Train Loss: 0.5188  Val Loss: 0.5431\n",
      "Epoch 414  Train Loss: 0.5159  Val Loss: 0.5385\n",
      "Epoch 415  Train Loss: 0.5180  Val Loss: 0.5380\n",
      "Epoch 416  Train Loss: 0.5183  Val Loss: 0.5400\n",
      "Epoch 417  Train Loss: 0.5175  Val Loss: 0.5409\n",
      "Epoch 418  Train Loss: 0.5189  Val Loss: 0.5396\n",
      "Epoch 419  Train Loss: 0.5194  Val Loss: 0.5406\n",
      "Epoch 420  Train Loss: 0.5171  Val Loss: 0.5437\n",
      "Epoch 421  Train Loss: 0.5204  Val Loss: 0.5415\n",
      "Epoch 422  Train Loss: 0.5152  Val Loss: 0.5383\n",
      "Epoch 423  Train Loss: 0.5185  Val Loss: 0.5397\n",
      "Epoch 424  Train Loss: 0.5182  Val Loss: 0.5434\n",
      "Epoch 425  Train Loss: 0.5142  Val Loss: 0.5408\n",
      "Epoch 426  Train Loss: 0.5206  Val Loss: 0.5391\n",
      "Epoch 427  Train Loss: 0.5174  Val Loss: 0.5396\n",
      "Epoch 428  Train Loss: 0.5196  Val Loss: 0.5401\n",
      "Epoch 429  Train Loss: 0.5179  Val Loss: 0.5429\n",
      "Epoch 430  Train Loss: 0.5114  Val Loss: 0.5406\n",
      "Epoch 431  Train Loss: 0.5209  Val Loss: 0.5383\n",
      "Epoch 432  Train Loss: 0.5199  Val Loss: 0.5415\n",
      "Epoch 433  Train Loss: 0.5196  Val Loss: 0.5401\n",
      "Epoch 434  Train Loss: 0.5126  Val Loss: 0.5384\n",
      "Epoch 435  Train Loss: 0.5184  Val Loss: 0.5369\n",
      "Epoch 436  Train Loss: 0.5163  Val Loss: 0.5408\n",
      "Epoch 437  Train Loss: 0.5193  Val Loss: 0.5411\n",
      "Epoch 438  Train Loss: 0.5161  Val Loss: 0.5449\n",
      "Epoch 439  Train Loss: 0.5173  Val Loss: 0.5406\n",
      "Epoch 440  Train Loss: 0.5117  Val Loss: 0.5403\n",
      "Epoch 441  Train Loss: 0.5186  Val Loss: 0.5420\n",
      "Epoch 442  Train Loss: 0.5153  Val Loss: 0.5388\n",
      "Epoch 443  Train Loss: 0.5140  Val Loss: 0.5433\n",
      "Epoch 444  Train Loss: 0.5162  Val Loss: 0.5437\n",
      "Epoch 445  Train Loss: 0.5125  Val Loss: 0.5384\n",
      "Epoch 446  Train Loss: 0.5183  Val Loss: 0.5431\n",
      "Epoch 447  Train Loss: 0.5207  Val Loss: 0.5411\n",
      "Epoch 448  Train Loss: 0.5167  Val Loss: 0.5408\n",
      "Epoch 449  Train Loss: 0.5158  Val Loss: 0.5423\n",
      "Epoch 450  Train Loss: 0.5127  Val Loss: 0.5407\n",
      "Epoch 451  Train Loss: 0.5148  Val Loss: 0.5369\n",
      "Epoch 452  Train Loss: 0.5125  Val Loss: 0.5428\n",
      "Epoch 453  Train Loss: 0.5149  Val Loss: 0.5411\n",
      "Epoch 454  Train Loss: 0.5200  Val Loss: 0.5380\n",
      "Epoch 455  Train Loss: 0.5131  Val Loss: 0.5404\n",
      "Epoch 456  Train Loss: 0.5207  Val Loss: 0.5431\n",
      "Epoch 457  Train Loss: 0.5164  Val Loss: 0.5397\n",
      "Epoch 458  Train Loss: 0.5115  Val Loss: 0.5412\n",
      "Epoch 459  Train Loss: 0.5159  Val Loss: 0.5421\n",
      "Epoch 460  Train Loss: 0.5116  Val Loss: 0.5375\n",
      "Epoch 461  Train Loss: 0.5218  Val Loss: 0.5389\n",
      "Epoch 462  Train Loss: 0.5154  Val Loss: 0.5391\n",
      "Epoch 463  Train Loss: 0.5128  Val Loss: 0.5418\n",
      "Epoch 464  Train Loss: 0.5156  Val Loss: 0.5399\n",
      "Epoch 465  Train Loss: 0.5218  Val Loss: 0.5386\n",
      "Epoch 466  Train Loss: 0.5143  Val Loss: 0.5400\n",
      "Epoch 467  Train Loss: 0.5153  Val Loss: 0.5424\n",
      "Epoch 468  Train Loss: 0.5128  Val Loss: 0.5400\n",
      "Epoch 469  Train Loss: 0.5174  Val Loss: 0.5390\n",
      "Epoch 470  Train Loss: 0.5156  Val Loss: 0.5407\n",
      "Epoch 471  Train Loss: 0.5185  Val Loss: 0.5380\n",
      "Epoch 472  Train Loss: 0.5141  Val Loss: 0.5410\n",
      "Epoch 473  Train Loss: 0.5158  Val Loss: 0.5396\n",
      "Epoch 474  Train Loss: 0.5148  Val Loss: 0.5404\n",
      "Epoch 475  Train Loss: 0.5172  Val Loss: 0.5425\n",
      "Epoch 476  Train Loss: 0.5188  Val Loss: 0.5462\n",
      "Epoch 477  Train Loss: 0.5162  Val Loss: 0.5451\n",
      "Epoch 478  Train Loss: 0.5154  Val Loss: 0.5390\n",
      "Epoch 479  Train Loss: 0.5126  Val Loss: 0.5385\n",
      "Epoch 480  Train Loss: 0.5155  Val Loss: 0.5408\n",
      "Epoch 481  Train Loss: 0.5182  Val Loss: 0.5393\n",
      "Epoch 482  Train Loss: 0.5187  Val Loss: 0.5429\n",
      "Epoch 483  Train Loss: 0.5153  Val Loss: 0.5412\n",
      "Epoch 484  Train Loss: 0.5169  Val Loss: 0.5410\n",
      "Epoch 485  Train Loss: 0.5150  Val Loss: 0.5412\n",
      "Epoch 486  Train Loss: 0.5109  Val Loss: 0.5425\n",
      "Epoch 487  Train Loss: 0.5127  Val Loss: 0.5422\n",
      "Epoch 488  Train Loss: 0.5140  Val Loss: 0.5393\n",
      "Epoch 489  Train Loss: 0.5101  Val Loss: 0.5415\n",
      "Epoch 490  Train Loss: 0.5157  Val Loss: 0.5409\n",
      "Epoch 491  Train Loss: 0.5117  Val Loss: 0.5374\n",
      "Epoch 492  Train Loss: 0.5111  Val Loss: 0.5437\n",
      "Epoch 493  Train Loss: 0.5123  Val Loss: 0.5417\n",
      "Epoch 494  Train Loss: 0.5188  Val Loss: 0.5371\n",
      "Epoch 495  Train Loss: 0.5173  Val Loss: 0.5429\n",
      "Epoch 496  Train Loss: 0.5155  Val Loss: 0.5428\n",
      "Epoch 497  Train Loss: 0.5143  Val Loss: 0.5396\n",
      "Epoch 498  Train Loss: 0.5118  Val Loss: 0.5412\n",
      "Epoch 499  Train Loss: 0.5170  Val Loss: 0.5425\n",
      "Epoch 500  Train Loss: 0.5151  Val Loss: 0.5402\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.30      0.16      0.20       249\n",
      "         1.0       0.81      0.91      0.86      1005\n",
      "\n",
      "    accuracy                           0.76      1254\n",
      "   macro avg       0.55      0.53      0.53      1254\n",
      "weighted avg       0.71      0.76      0.73      1254\n",
      "\n",
      "Test ROC AUC: 0.6035285420288118\n"
     ]
    }
   ],
   "source": [
    "# 3 layer mlp\n",
    "\n",
    "def to_tensor_dataset(X, y):\n",
    "    Xt = torch.from_numpy(X).float().to(device)\n",
    "    yt = torch.from_numpy(y).float().unsqueeze(1).to(device)\n",
    "    return TensorDataset(Xt, yt)\n",
    "\n",
    "train_ds = to_tensor_dataset(X_train, y_train)\n",
    "val_ds   = to_tensor_dataset(X_val, y_val)\n",
    "test_ds  = to_tensor_dataset(X_test, y_test)\n",
    "\n",
    "batch_size = 32\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 3) Define the 3-layer MLP\n",
    "class ThreeLayerMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = ThreeLayerMLP(input_dim=X_train.shape[1]).to(device)\n",
    "\n",
    "# 4) Optimizer and loss\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-6, weight_decay=1e-5)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 5) Training & Validation Loop\n",
    "n_epochs = 500\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # -- Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for xb, yb in train_dl:\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * xb.size(0)\n",
    "    train_loss /= len(train_dl.dataset)\n",
    "\n",
    "    # -- Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_dl:\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            val_loss += loss.item() * xb.size(0)\n",
    "    val_loss /= len(val_dl.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch:2d}  Train Loss: {train_loss:.4f}  Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Optional: save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "# 6) Load best model and test evaluation\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "y_probs = []\n",
    "y_true  = []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_dl:\n",
    "        probs = model(xb)\n",
    "        y_probs.extend(probs.cpu().numpy().flatten().tolist())\n",
    "        y_true .extend(yb.cpu().numpy().flatten().tolist())\n",
    "\n",
    "y_pred = (np.array(y_probs) >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(\"Test ROC AUC:\", roc_auc_score(y_true, y_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83c251fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/airlay88/surprise_sae/venv/lib/python3.10/site-packages/xgboost/data.py:78: UserWarning: `missing` is not used for current input data type:<class 'str'>\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.86449\teval-auc:0.48788\n",
      "[50]\ttrain-auc:1.00000\teval-auc:0.58003\n",
      "[74]\ttrain-auc:1.00000\teval-auc:0.57466\n",
      "Test Accuracy : 0.5279\n",
      "Test ROC AUC  : 0.5431\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.52      0.53       358\n",
      "           1       0.53      0.53      0.53       358\n",
      "\n",
      "    accuracy                           0.53       716\n",
      "   macro avg       0.53      0.53      0.53       716\n",
      "weighted avg       0.53      0.53      0.53       716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[187 171]\n",
      " [167 191]]\n"
     ]
    }
   ],
   "source": [
    "X_train_csr = sparse.csr_matrix(X_train)  # compress zeros\n",
    "X_val_csr   = sparse.csr_matrix(X_val)\n",
    "X_test_csr  = sparse.csr_matrix(X_test)\n",
    "\n",
    "dump_svmlight_file(X_train_csr, y_train, \"train.svm\")\n",
    "dump_svmlight_file(X_val_csr,   y_val,   \"val.svm\")\n",
    "dump_svmlight_file(X_test_csr,  y_test,  \"test.svm\")\n",
    "\n",
    "\n",
    "# --- 2. Build DMatrix (treat 0.0 as missing) ---\n",
    "dtrain = xgb.DMatrix(\"train.svm?format=libsvm#train.cache\", missing=0.0)\n",
    "dval   = xgb.DMatrix(\"val.svm?format=libsvm#val.cache\",     missing=0.0)\n",
    "dtest  = xgb.DMatrix(\"test.svm?format=libsvm#test.cache\",   missing=0.0)  \n",
    "\n",
    "params = {\n",
    "    'objective':        'binary:logistic',\n",
    "    'eval_metric':      'auc',\n",
    "    'tree_method':      'hist',\n",
    "    'max_depth':        8,\n",
    "    'eta':              0.1,\n",
    "    'subsample':        0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'lambda':           1.0,\n",
    "    'alpha':            0.5,\n",
    "    'nthread':          4      \n",
    "}\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "\n",
    "bst = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=watchlist,\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=50\n",
    ")\n",
    "\n",
    "# --- 4. Predict & evaluate on test set ---\n",
    "y_proba = bst.predict(dtest)               # shape (n_test,)\n",
    "y_pred  = (y_proba > 0.5).astype(int)\n",
    "\n",
    "acc    = accuracy_score(y_test, y_pred)\n",
    "auc    = roc_auc_score(y_test, y_proba)\n",
    "report = classification_report(y_test, y_pred)\n",
    "cm     = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy : {acc:.4f}\")\n",
    "print(f\"Test ROC AUC  : {auc:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
